,name,title,link,abstract,date
0,Mohamed Abdelshafy,Cross-Layer Multipath Multichannel MAC protocol for MANETs,https://pureportal.coventry.ac.uk/en/publications/cross-layer-multipath-multichannel-mac-protocol-for-manets,"Utilising multiple disjoint paths in multiple channels can improve network performance by enabling a node to reroute data along discovered paths seamlessly when link failure is detected. However, depending on a stale/invalid route to recover from a broken link could increase the delay to recover fromthe broken link and degrade the network performance. In this paper, we propose a new MAC protocol (RIVC-MB) to enhance communication reliability in the multipath multichannel routing protocol. The reliability of transmitting/re-routing the data packet in multipath multichannel routing protocol is improved by providing early route invalidity detection and early switchover. Waiting time to access the medium is also improved, when a node is attempting to access a busy medium, by re-routing the data packet via the alternative route. The RIVC-MB protocol uses the cross-layer interaction between MAC and routing protocols to achieve these goals. The proposed protocol is implemented and extensively evaluated using the NS-2 simulator. Simulation results show that the new proposed protocol improves the endto- end delay, and reduces both the number of route error control packets and the number of dropped data packets in the routing layer. It also reduces reduces the collision rate in the MAC layer in a dense network.",Jun 2018
1,Mohamed Abdelshafy,Performance evaluation of Receiver Directed Transmission protocol with a single transceiver in MANETs,https://pureportal.coventry.ac.uk/en/publications/performance-evaluation-of-receiver-directed-transmission-protocol,"Utilising multiple channels can increase the wireless ad hoc network capacity. Receiver Directed Transmission protocol (RDT) is designed to provide multichannel access using a single radio interface. RDT introduces a clever approach to support channel assignment and negotiation without relying on a control channel or time synchronisation. Protocols based on the RDT scheme normally use an extra radio interface, dual home channel or time synchronisation to overcome the expected issues in RDT, such as, hidden terminal and deafness problems. This paper demonstrates that using RDT with a single radio and single home channel it is still possible to increase the network capacity. Additionally, the paper investigates the effect of node density, mobility and number of available channels on RDT performance. NS-2 simulator is used to evaluate the proposed scheme. Simulation results confirm that using multichannel RDT scheme can effectively increase the throughput, the packet delivery ratio and reduce the delay compared to single channel protocol.",4 May 2017
2,Mohamed Abdelshafy,Reliable Multipath Multi-channel Route Migration over Multi Link-Failure in Wireless Ad Hoc Networks,https://pureportal.coventry.ac.uk/en/publications/reliable-multipath-multi-channel-route-migration-over-multi-link-,"The route recovery algorithm is a crucial part of an ad hoc routing protocol. Designing an efficient and fast route recovery mechanism scheme without incurring extra overheads or delays to repair the broken link is a desirable goal for any routing protocol. The route recovery algorithm in reactive routing protocols like AODV occurs only after a link failure is detected. However, we propose a new route discovery mechanism called Route Migration over Multiple link failure in Multi-Channel (RMMMC), which combines multiple paths and channels to provide a disjointed alternative route. When link failure is detected, the RMMMC reroutes the data packet through the alternative route in alternative channels that have been previously discovered. Furthermore, the RMMMC is resilient to multiple link failures. Unlike other route recovery approaches, nodes in RMMMC are considered to be equipped with a single transceiver. The RMMMC scheme is implemented and extensively evaluated by using an ns-2 simulator. Simulation results show that the proposed scheme achieves a better packet delivery ratio, throughput and reduces the routing overhead and end-to-end delay in a dense network.",23 Nov 2017
3,Mohamed Abdelshafy,Resisting blackhole attacks on MANETs,https://pureportal.coventry.ac.uk/en/publications/resisting-blackhole-attacks-on-manets,"MANET routing protocols are designed based on the assumption that all nodes cooperate without maliciously disrupting the operation of the routing protocol. AODV is a reactive MANET routing protocol that is vulnerable to a dramatic collapse of network performance in the presence of blackhole attack. The paper introduces a new concept of Self-Protocol Trustiness (SPT) in which detecting a malicious intruder is accomplished by complying with the normal protocol behavior and lures the malicious node to give an implicit avowal of its malicious behavior. We present a Blackhole Resisting Mechanism (BRM) to resist such attacks that can be incorporated into any reactive routing protocol. It does not require expensive cryptography or authentication mechanisms, but relies on locally applied timers and thresholds to classify nodes as malicious. No modifications to the packet formats are needed, so the overhead is a small amount of calculation at nodes, and no extra communication. Using NS2 simulation, we compare the performance of networks using AODV under blackhole attacks with and without our mechanism to SAODV, showing that it significantly reduces the effect of a blackhole attack.",Jan 2016
4,Mohamed Abdelshafy,Dynamic Source Routing under Attacks,https://pureportal.coventry.ac.uk/en/publications/dynamic-source-routing-under-attacks,"MANET routing protocols are designed based on the assumption that all nodes cooperate without maliciously disrupting the operation of the routing protocol. A large number of attack types of varying severity are threatening MANET. Dynamic Source Routing (DSR) is a well-known reactive MANET routing protocol that does not support security of routing messages. In this paper, we study the performance of both DSR and its flow-state extension routing protocols in the presence of blackhole, grayhole, selfish and flooding attacks. We conclude that the performance of flow-state DSR is better than DSR in the presence of all attacks. Flooding attacks are found to dramatically impact all the standard performance metrics. Blackhole attacks significantly worse the packet delivery ratio in a static network using unmodified DSR. All the attacks greatly increase the end-to-end delay; an effect particularly marked in a static network.",12 Oct 2015
5,Mohamed Abdelshafy,AODV & SAODV under Attack: Performance Comparison,https://pureportal.coventry.ac.uk/en/publications/aodv-amp-saodv-under-attack-performance-comparison,"AODV is a reactive MANET routing protocol that does not support security of routing messages. SAODV is an extension of the AODV routing protocol that is designed to fulfil security features of the routing messages. In this paper, we study the performance of both AODV and SAODV routing protocols under the presence of blackhole, grayhole, selfish and flooding attacks. We conclude that the performance of SAODV is better than AODV in the presence of blackhole, grayhole and selfish attacks while its performance is worse than AODV in the presence of flooding attack. The blackhole and flooding attacks have a severe impact on the AODV and SAODV performance while the grayhole and selfish attacks have less significant effect on it.",Jun 2014
6,Mohamed Abdelshafy,AODV Routing Protocol Performance Analysis under MANET Attacks,https://pureportal.coventry.ac.uk/en/publications/aodv-routing-protocol-performance-analysis-under-manet-attacks,"AODV is a well-known reactive protocol designed for MANET routing. All MANET routing protocols are designed based on the assumption that all nodes cooperate without maliciously disrupting the operation of the routing protocol. In this paper, we study the performance of AODV routing protocol in the presence of some of the well-deﬁned attacks in MANET. We use NS-2 network simulator to analyse the impacts of blackhole, grayhole, selﬁsh and ﬂooding attacks on AODV protocol performance. While the blackhole and ﬂooding attacks have a severe impact on the AODV performance, the selﬁsh and grayhole attacks have less signiﬁcant effect on it.",Jun 2014
7,Mohamed Abdelshafy,Resisting flooding attacks on AODV,https://pureportal.coventry.ac.uk/en/publications/resisting-flooding-attacks-on-aodv,"AODV is a reactive MANET routing protocol that is vulnerable to a dramatic collapse of throughput when malicious intruders flood the network with bogus route requests. We introduce a simple mechanism to resist such attacks that canbe incorporated into any reactive routing protocol. It does not require expensive cryptography or authentication mechanisms, but relies on locally applied timers and thresholds to classify nodes as malicious. No modifications to the packet formats are needed, so the overhead is a small amount of calculation at nodes,and no extra communication. Using NS2 simulation, we compare the performance of networks using AODV under flooding attacks with and without our mechanism, showing that it significantly reduces the effect of a flooding attack.",Nov 2014
8,Mohamed Abdelshafy,Analysis of security attacks on AODV routing,https://pureportal.coventry.ac.uk/en/publications/analysis-of-security-attacks-on-aodv-routing,"MANET routing protocols have many vulnerabilities that may be exploited by malicious nodes to disrupt the normal routing behavior. In this paper, we present a vulnerability analysis of AODV. We simulate four routing attacks to analyse their impacts on AODV protocol using NS-2 network simulator. These attacks are blackhole, grayhole, selfish and flooding attacks. The blackhole and flooding attacks have a severe impact on the network performance while the selfish and grayhole attacks have less significant effect on the network performance.",Dec 2013
9,Mohamed Abdelshafy,Analysis and Evaluations of Wireless LANs Security Protocols,https://pureportal.coventry.ac.uk/en/publications/analysis-and-evaluations-of-wireless-lans-security-protocols,,Nov 2002
10,Mohamed Abdelshafy,An Active Attack on Token-Based Security Protocol,https://pureportal.coventry.ac.uk/en/publications/an-active-attack-on-token-based-security-protocol,"In this paper, we analyzed the token-based security protocol [1] using the GNY logic to determine the security flaws of the protocol. We found out that the token-based protocol has two security flaws. The first one leads to an active attack which enables the intruder to get sensitive information whereas the second may result in gumming up the network and thus reducing the efficiency of its operation. Therefore, this protocol can not be approved for authentication. We conclude our paper by proposing a modification to the token-based protocol that overcomes these attacks.",Apr 2001
11,Mohamed Abdelshafy,A New Attack on Aziz-Diffie Security Protocol,https://pureportal.coventry.ac.uk/en/publications/a-new-attack-on-aziz-diffie-security-protocol,,Mar 2001
12,Reda Al-Bodour,QoS within Business Grid Quality of Service (BGQoS),https://pureportal.coventry.ac.uk/en/publications/qos-within-business-grid-quality-of-service-bgqos-2,"Differences in domain QoS requirements have been an obstacle to utilising Grid Computing for main stream applications. While the resource could potentially provide potentially vital services as well as providing significant computing and storage capabilities, the lack of high level QoS specification capabilities has proven to be a hindrance. Business Grid Quality of Service (BGQoS) is a QoS model for business-oriented applications on Grid computing systems. BGQoS defines QoS at a high level facilitating an easier request model for the Grid Resource Consumer (GRC) and eliminates confusion for the Grid Resource Provider in supplying the appropriate resources to meet the GRC requirements. It offers high level QoS specification within multi-domain environments in a flexible manner. Employing component separation and dynamic QoS calculation, it provides the necessary tools and execution environment for a scalable set of requirements tailoring to specific domain demands and requirements. Moreover, through reallocation, the model provides the insurance that all QoS requirements are met throughout the execution period, including migrating tasks to different resources if necessary. This process is not random and adheres to a set of conditions which ensures that task execution and resource allocation happen when and in accordance with execution requirements. This paper focuses on BGQoS' flexibility and QoS capability. More specifically, the concentration is on core operations within BGQoS and the methods used in order to deliver a sustained level of QoS which meets the GRC's requirements while being versatile and flexible such that it can be tailored to specific domains. This paper also presents an experimental evaluation of BGQoS. The evaluation investigates the behaviour and performance of the separate operations and components within BGQoS, and moreover, it presents an investigation and comparison between the different operations and their effect on the full model.",Sept 2015
13,Reda Al-Bodour,High level QoS-driven model for Grid applications in a simulated environment,https://pureportal.coventry.ac.uk/en/publications/high-level-qos-driven-model-for-grid-applications-in-a-simulated--2,"This paper presents a model for high-level Quality of Service (QoS) maintenance within business-context domains and associated simulation results achieved via an expansion of the GridSim toolkit. Grid Computing traditionally has been linked with scientific environments, where heterogeneous resources were networked and employed for carrying out compute-intensive and data-intensive scientific experiments or applications that may have not been possible before. The natural progression is that business-oriented applications will build on this success and utilise the large number of heterogeneous Grid resources, potentially available. The success of introducing these applications into the mainstream is directly related to whether Grid Resource Providers can deliver a suitable level of QoS to the Grid Resource Consumer (GRC) and the ability of the GRC to request high level QoS such as the numbers of CPUs required or the RAM required, on demand. Moreover, we present dynamically calculated metrics for measuring QoS such as reliability, using up-to-date information on resources. We introduce a novel model, Business Grid Quality of Service (BGQoS), for a new generation of commercial and business-oriented Grid applications which may wish to make use of Grid environments. BGQoS allows GRCs to specify varying types of high level QoS requirements which are delivered via querying up-to-date resource information, matchmaking and monitoring operations. In addition, testing is required and this has posed a problem where testing on physical Grid test-beds is either impractical or not viable economically. Simulation is therefore important.",Jul 2012
14,Reda Al-Bodour,An extension of GridSim for quality of service,https://pureportal.coventry.ac.uk/en/publications/an-extension-of-gridsim-for-quality-of-service,GridSim is a well known and useful open software product through which users can simulate a Grid environment. At present Qualities of Service are not modeled in GridSim. When utilising a Grid a user may wish to make decisions about type of service to be contracted. For instance performance and security are two levels of service upon which different decisions may be made. Subsequently during operation a grid may not be able to fulfill its contractual obligations. In this case renegotiation is necessary. This paper describes an extension to GridSim that enables various Qualities of Service to be modeled together with Service Level Agreements and renegotiation of contract with associated costs. The extension is useful as it will allow users to make better estimates of potential costs and will also enable grid service suppliers to more accurately predict costs and thus provide better service to users.,14 Apr 2010
15,Rachid Anane,Institutional Data Analysis and Machine Learning Prediction of Student Performance,https://pureportal.coventry.ac.uk/en/publications/institutional-data-analysis-and-machine-learning-prediction-of-st,"Concern over student progression and retention is driving the systematic analysis of the vast amount of student data recorded in institutional data sets and in learning management systems (LMS) data sets. This is motivated by the belief that student analytics will help uncover patterns of behaviour and predict student performance, and thus facilitate the deployment of supportive educational interventions. This paper is concerned with the investigation of the institutional data of a Nigerian university, and the predictive impact of its attributes on student performance, measured in terms of cumulative grade point average (CGPA). The statistical analysis of the data set reveals that age and marital status have no significant relationship with final CGPA, whereas gender and pre-entry score have a weak relationship but are not good predictors. The application of four representative machine learning methods, namely linear regression, support vector regression, decision tree and random forests indicate that the third year CGPA is a good predictor of final year CGPA. A higher accuracy is achieved by using the aggregate value of the CGPAs of three previous years. Support vector regression has the best performance in predicting the final CGPA, whereas decision tree is the least performing model.",20 May 2022
16,Rachid Anane,An Empirical Evaluation of Learning Style and Knowledge Level Adaptation,https://pureportal.coventry.ac.uk/en/publications/an-empirical-evaluation-of-learning-style-and-knowledge-level-ada-2,"This paper presents an initial evaluation of different forms of
adaptation based on learning style and knowledge level, which were implemented
in an adaptive e-learning system. An experiment conducted in a learning
context with 174 participants produced significant results in terms of learning
gain. They indicate that adaptation based on both learning style and knowledge
level yields significantly better learning gain than adaptation based on learning
style only, and better than adaptation based on knowledge level only.",2016
17,Rachid Anane,Usability and Effectiveness Evaluation of Adaptivity in E-Learning Systems,https://pureportal.coventry.ac.uk/en/publications/usability-and-effectiveness-evaluation-of-adaptivity-in-e-learnin-2,"Designing effective and usable adaptive e-learning systems represents a challenge because of the complexity which arises when meeting the needs of learners. This is compounded by the lack of well-designed experimental evaluations of adaptive e-learning systems in general, and of their usability and effectiveness in particular. This paper offers an experimental evaluation of the effect of adaptation, taking into account both the perceived usability level and learning effectiveness. A controlled experiment was conducted with 75 participants and produced significant results. They indicate that an adaptive version has a significantly higher level of perceived usability and of learning effectiveness than a non-adaptive version.

",2016
18,Rachid Anane,An E-Learning Investigation into Learning Style Adaptivity,https://pureportal.coventry.ac.uk/en/publications/an-e-learning-investigation-into-learning-style-adaptivity,"Traditional e-learning systems are typically designed for generic learners irrespective of individual requirements. In contrast, adaptive e-learning systems take into account learner characteristics such as learning style and level of knowledge in order to provide more personalised learning. The contribution of this paper is threefold. First, a generic adaptive framework aimed at enhancing learning is proposed. Second, a specific approach to adaptivity based on learning style is put forward within the framework. Third, the framework is validated and the approach is evaluated in order to determine their effectiveness in learning provision in an adaptive e-learning system. An experiment conducted with 60 participants produced positive results. They indicate that adapting instructional material according to learning style yields significantly better learning outcome and learner satisfaction than without adaptation.",5 Jan 2015
19,Rachid Anane,Design and Usability Evaluation of Adaptive e-learning Systems Based on Learner Knowledge and Learning Style,https://pureportal.coventry.ac.uk/en/publications/design-and-usability-evaluation-of-adaptive-e-learning-systems-ba-2,"Designing effective adaptive e-learning systems, from a usability perspective, represents a challenge because of the complexity of adaptivity in order to meet the diverse requirements of learners. Furthermore, there is a lack of well-designed experimental evaluation of adaptive e-learning systems in general, and of their usability in particular. The aim of this paper is the presentation of an adaptive e-learning system based on learner knowledge and learning style, and of the results of an initial experimental evaluation of the usability of its two modes of operation. This involves comparing the usability of an adaptive version of the system with the usability of a non-adaptive version, in a learning environment with 75 participants. The experiment produced significant results; they indicate that an adaptive e-learning system based on learner knowledge and learning style has a higher level of perceived usability than a non-adaptive e-learning system. This may also increase the level of satisfaction, engagement and motivation of learners and therefore enhance their learning.",Aug 2015
20,Rachid Anane,Students' Satisfaction in Learning Style-Based Adaptation,https://pureportal.coventry.ac.uk/en/publications/students-satisfaction-in-learning-style-based-adaptation-2,"Initiatives based on learning style adaptation are often marked by a lack of experimental evaluation of their efficacy in general and of student satisfaction in particular. A high level of satisfaction can increase the motivation of students, their engagement and experience, and therefore improve their learning. This paper is concerned with the investigation of the effect of adaptation based on learning style on students' satisfaction. An adaptive approach, which involves the construction of personalised learning paths based on learning style, was implemented in an adaptive e-learning system. A controlled experiment in this learning environment was conducted with sixty undergraduate students to evaluate their level of satisfaction with the system. The results indicate that the students were generally satisfied with their learning experience. It can be concluded that adaptation of learning content according to learning style can improve student satisfaction and enhance their experience and motivation.

",2015
21,Rachid Anane,The Impact of Learning Style Adaptivity in Teaching Computer Security,https://pureportal.coventry.ac.uk/en/publications/the-impact-of-learning-style-adaptivity-in-teaching-computer-secu-2,"Teaching computer security is one of the most challenging tasks in computer science, because of the need to successfully integrate abstract concepts and practical applications. Several e-learning systems have been developed to address this issue. However, they usually provide the same material in the same sequence irrespective of the characteristics of the students, such as their knowledge level and learning style. In this paper, an approach to learning style adaptivity is proposed for the teaching of computer security. An e-learning system was developed to provide more personalised and adaptive learning, based on the information perception style of the Felder-Silverman model. This is the dimension of learning style, which has received the least attention in published research. In the approach, a personalised sequence of learning material is generated based on an individual learning style. The approach is evaluated in order to determine its effectiveness in learning provision. An experiment conducted with sixty subjects produced significant results. They indicate that matching computer security learning material, according to the learning style of the students, yields significantly better learning gain and student satisfaction than without matching

",2015
22,Rachid Anane,Adaptivity in E-learning systems,https://pureportal.coventry.ac.uk/en/publications/adaptivity-in-e-learning-systems-2,"Traditional e-learning systems have been, typically, designed for a generic learner, irrespective of individual knowledge, skills and learning styles. In contrast, adaptive e-learning systems can enhance learning by taking into account different learner characteristics and by personalising learning material. Although a large number of systems incorporating learning style have been deployed, there is a lack of comprehensive, comparative evaluations. This paper attempts to bridge this gap by comparing a number of adaptive e-learning systems. It considers three main perspectives: the learner model, the domain model and the adaptation model. A set of criteria is generated for each perspective, and applied to a representative sample of adaptive e-learning systems.

",Oct 2014
23,Rachid Anane,Social Network Enhancement for Non-formal Learning,https://pureportal.coventry.ac.uk/en/publications/social-network-enhancement-for-non-formal-learning-2,"Concern over student engagement has highlighted the inability of learning management systems (LMS) to accommodate the social side of learning. The emergence of social networks and their widespread adoption by students has opened new avenues for mediating different modes of learning. This work seeks to capitalise on the informal interactions of social networks, the structure of learning programmes and the multiple facets of collaborative approaches, in order to enhance student engagement. These are integrated into a framework which supports non-formal learning and facilitates knowledge creation and sharing through socialisation, externalisation and combination. A programme element - defined by a curriculum structure- and a collaborative element - identified by collaborative activities - are grafted onto the social fabric of Facebook. The aim of the framework is to promote engagement through a community of practice. Learners are encouraged to share tacit knowledge and co-construct explicit knowledge through social media and a dedicated collaborative tool.

",2014
24,Rachid Anane,The Learning Object Triangle,https://pureportal.coventry.ac.uk/en/publications/the-learning-object-triangle-2,"One critical factor in the effective deployment of learning objects (LOs) is the availability of relevant metadata categories. This work is motivated by the view that metadata identification is enhanced by a clear definition of a learning object. The aim of this paper is to offer a holistic approach to LOs and to introduce a definitional framework informed by the LO lifecycle. A LO is defined in terms of three main facets: mediation (potential for facilitating learning), transition (ability to be used in different learning environments) and specification (description of LO characteristics, as metadata). Unlike most evaluation instruments, the framework integrates explicitly information on learner experiences such as annotation, evaluation and attention metadata.

",17 Sept 2014
25,Rachid Anane,Agent-based interaction protocols and topologies for manufacturing task allocation,https://pureportal.coventry.ac.uk/en/publications/agent-based-interaction-protocols-and-topologies-for-manufacturin-2,,2013
26,Rachid Anane,A Recommendation Cascade for e-learning,https://pureportal.coventry.ac.uk/en/publications/a-recommendation-cascade-for-e-learning,"This  paper  is  concerned  with  the  presentation  of  a collaborative  recommendation  system  that  implementsa cascade of strategies in order to support the learning process.  Similarities  between  learners  are  determined by   taking   advantage   of  the   underlying  implicit  or explicit  personalisation  and  of  the  non-personalised modes  of  interaction.  In  the  personalised  approach implicit profiles are based on the patterns of behaviour of  learners,  while  explicit  profiles  are  generated from the  results  of  a  questionnaire  on  learning  style.  The non-personalisation approach relies on the cumulative intervention of a community of learners implied by the recorded frequency of the usage of objects by learners, and   by   the   expert   rating   of   objects   by   teachers. Content-based    and    collaborative    approaches    are combined into a hybrid model that widens the range of objects to which a learner may be exposed. The quality of  service  of  the  recommendation  system  is  evaluated by considering the accuracy of its predictive capability on a publicly available data set.  ",25 Mar 2013
27,Rachid Anane,Hybrid P2P Architecture for Transaction Management,https://pureportal.coventry.ac.uk/en/publications/hybrid-p2p-architecture-for-transaction-management,"In contrast with many centralised schemes P2P systems are flexible, scalable and highly dynamic. They offer an attractive distributed platform despite concerns over security. This work is motivated by the need to address explicitly the main issues that arise in the deployment of P2P systems in a business environment. A systematic approach is proposed in the development of a secure and trusted system to support authentication, non-repudiation and trust in business transactions.  This involves two stages. Firstly, the identification of the functional components designed to facilitate security through authentication and nonrepudiation, and those aimed at insuring trust; secondly, their implementation and integration into a hybrid P2P architecture, where the entry point server plays a central role. This integration is facilitated by the layering of functional components. Secure and trusted file transactions are further enhanced by a community management layer. ",19 Dec 2013
28,Rachid Anane,Hybrid Profiling in Information Retrieval,https://pureportal.coventry.ac.uk/en/publications/hybrid-profiling-in-information-retrieval,"One  of  the  main  challenges  in  search  engine quality of service is how to satisfy the needs and the interests of individualusers. This raises the fundamental issue of how to  identify  and  select  the  information  that  is  relevant  to  a specific  user.  This  concern  over  generic  provision and  the lack  of  search  precision  have  provided  the  impetus for  the research  into  Web  Search  personalisation.  In  this  paper  a hybrid user profiling system is  proposed – a combination of explicit  and  implicit  user  profiles  for  improving  the  web search  effectiveness  in  terms  of  precision  and  recall.  The proposed system is content-based and implements the Vector Space     Model.     Experimental     results,     supported     by significance   tests,   indicate   that   the   system   offers   better precision  and  recall  in  comparison  to  traditional  search engines.  ",11 Jun 2013
29,Rachid Anane,A new agents-based model for dynamic job allocation in manufacturing shopfloors,https://pureportal.coventry.ac.uk/en/publications/a-new-agents-based-model-for-dynamic-job-allocation-in-manufactur-2,"Market-based mechanisms such as the contract net protocol (CNP) are very popular for dynamic job allocation in distributed manufacturing control and scheduling. The CNP can be deployed with different configurations of the system elements. Every configuration corresponds to a basic or a hybrid topology. The subject of topology is generally discussed in the field of “distributed systems.” Inspired from the notion of topology in the distributed systems, this paper proposes a ring-like model as a competitor for the web-like CNP-based job allocation within the concept of holonic manufacturing systems. Details of the algorithm for scheduling and assignment of jobs to resources in the ring structure is presented and its performance is compared with both CNP-based distributed model, and the centralized conventional scheduling of a real manufacturing case study involving a major turbine production plant. Comparison of performance indicators such as time and cost of operations shows that the distributed models clearly outperform the conventional practice with meaningful impact on the production economy. As a possible implementation strategy, a hybrid switching model, composed of both competing models, is proposed.",4 May 2012
30,Rachid Anane,An optimized approach for storing and accessing small files on cloud storage,https://pureportal.coventry.ac.uk/en/publications/an-optimized-approach-for-storing-and-accessing-small-files-on-cl-2,"Hadoop distributed file system (HDFS) is widely adopted to support Internet services. Unfortunately, native HDFS does not perform well for large numbers but small size files, which has attracted significant attention. This paper firstly analyzes and points out the reasons of small file problem of HDFS: (1) large numbers of small files impose heavy burden on NameNode of HDFS; (2) correlations between small files are not considered for data placement; and (3) no optimization mechanism, such as prefetching, is provided to improve I/O performance. Secondly, in the context of HDFS, the clear cut-off point between large and small files is determined through experimentation, which helps determine ‘how small is small’. Thirdly, according to file correlation features, files are classified into three types: structurally-related files, logically-related files, and independent files. Finally, based on the above three steps, an optimized approach is designed to improve the storage and access efficiencies of small files on HDFS. File merging and prefetching scheme is applied for structurally-related small files, while file grouping and prefetching scheme is used for managing logically-related small files. Experimental results demonstrate that the proposed schemes effectively improve the storage and access efficiencies of small files, compared with native HDFS and a Hadoop file archiving facility.",Nov 2012
31,Rachid Anane,A service-oriented architecture for robust e-voting,https://pureportal.coventry.ac.uk/en/publications/a-service-oriented-architecture-for-robust-e-voting-2,,2012
32,Rachid Anane,File management in a mobile DHT-based P2P environment,https://pureportal.coventry.ac.uk/en/publications/file-management-in-a-mobile-dht-based-p2p-environment-4,"The emergence of mobile P2P systems is largely due to theevolution of mobile devices into powerful informationprocessing units. The relatively structured context thatresults from the mapping of mobile patterns of behaviouronto P2P models is however constrained by thevulnerabilities of P2P networks and the inherent limitationsof mobile devices. Whilst the implementation of P2Pmodels gives rise to security and reliability issues, thedeployment of mobile devices is subject to efficiencyconstraints. This paper presents the development anddeployment of a mobile P2P system based on distributedhash tables (DHT). The secure, reliable and efficientdispersal of files is taken as an application. Reliability wasaddressed by providing two methods for file dispersal:replication and erasure coding. Security constraints werecatered for by incorporating an authentication mechanismand three encryption schemes. Lightweight versions ofvarious algorithms were selected in order to attend toefficiency requirements.",2012
33,Rachid Anane,The Impact of Modes of Mediation on the Web Retrieval Process,https://pureportal.coventry.ac.uk/en/publications/the-impact-of-modes-of-mediation-on-the-web-retrieval-process,"This paper is concerned with the investigation of mediation between users  and  Web  search  engines  and  the  impact  of  different  modes  of  mediation on  the  Web  search  effectiveness.  This  involves  the integration  of  explicit, implicit  and  hybrid  modes  of  mediation  within  a  content-based  framework, facilitated  by  the  adoption  of  the  Vector  Space  Model.  The  work  is  supported by  an  experimental  evaluation  of  the  impact  of  different  mediation  modes  on documents retrieval process in terms of recall and precision. The results of the experiments indicate that the mediation framework improves the  quality of the retrieval  process,  and  that  the  difference  in  the  quality  of  the  results  is statistically significant. ",Sept 2012
34,Rachid Anane,Model interoperability via model driven development,https://pureportal.coventry.ac.uk/en/publications/model-interoperability-via-model-driven-development-2,,Mar 2011
35,Rachid Anane,Robust e-Voting Composition,https://pureportal.coventry.ac.uk/en/publications/robust-e-voting-composition,"This paper is concerned with the presentation of a perspective on robustness in e-voting systems. It is argued that the effective design of an e-voting system and its viability can be enhanced by a two-pronged approach to robustness. First, it requires a clear distinction between two forms of robustness: robustness at protocol level and robustness at system level. Second, selected technologies should be integrated into an appropriate architecture in order to address robustness simultaneously at the two levels. The proposed approach is illustrated by the design and implementation of an e-voting system based on the FOO92 protocol. A service-oriented architecture supported by onion routing forms the basis of the system. It facilitates the distribution of tasks and state, the dynamic path configuration and the just-in-time (JIT) composition of the election system. The system conforms to most e-voting requirements.",Dec 2011
36,Rachid Anane,An architecture for grid-enabled distributed simulation,https://pureportal.coventry.ac.uk/en/publications/an-architecture-for-grid-enabled-distributed-simulation-2,,2009
37,Rachid Anane,Stateless data concealment for distributed systems,https://pureportal.coventry.ac.uk/en/publications/stateless-data-concealment-for-distributed-systems-2,,Mar 2008
38,Rachid Anane,A timed automata approach to QoS resolution,https://pureportal.coventry.ac.uk/en/publications/a-timed-automata-approach-to-qos-resolution-2,"Concern over the accurate evaluation of QoS requirements has been one of driving forces in thedevelopment of QoS management architectures. This paper presents an architectural approach to QoS evaluationand admission control, based on the modelling of both system behaviour and QoS requirements. Two aspects areconsidered. The first refers to QoS management, and to a component-based architecture for QoS evaluation. Thesecond illustrates the approach with the help of a case study based on a Personal Area Network. The proposedapproach is model-based and makes use of models representing both behaviour and QoS aspects of the system viaTimed Automata. The compatibility of the mechanism with architectures, which promote QoS management in itsown right, such as ITSUMO, is also highlighted",Jan 2006
39,Rachid Anane,eLearning content provision,https://pureportal.coventry.ac.uk/en/publications/elearning-content-provision-2,"It is widely acknowledged that the acceptance of eLearning frameworks requires the adoption of, and compliance with standards. This requirement is especially relevant to the design and delivery of courseware. We are concerned with learning content provision mediated by a learning management system (LMS), which complies with instructional management system (IMS) standards. The requirements for the LMS, as a tool for course management, are specified through different perspectives. Issues related to content creation and delivery are identified and addressed from the perspectives of the instructor, the learner, as well as the requirements of specific learning content. The learning management system is put in context by considering ways of enhancing content mediation in eLearning. The system is part of a research programme aimed at providing a framework for agent-supported eLearning.",2004
40,Rachid Anane,Implementation of a proactive load sharing scheme,https://pureportal.coventry.ac.uk/en/publications/implementation-of-a-proactive-load-sharing-scheme-2,"This paper presents a proactive approach to load sharing and describes the architecture of a scheme, Concert, based on this approach. A proactive approach is characterized by a shift of emphasis from reacting to load imbalance to avoiding its occurrence. In contrast, in a reactive load sharing scheme, activity is triggered when a processing node is either overloaded or underloaded. The main drawback of this approach is that a load imbalance is allowed to develop before costly corrective action is taken. Concert is a load sharing scheme for loosely-coupled distributed systems. Under this scheme, load and task behaviour information is collected and cached in advance of when it is needed. Concert uses Linux as a platform for development. Implemented partially in kernel space and partially in user space, it achieves transparency to users and applications whilst keeping the extent of kernel modifications to a minimum. Non-preemptive task transfers are used exclusively, motivated by lower complexity, lower overheads and faster transfers. The goal is to minimize the average response-time of tasks. Concert is compared with other schemes by considering the level of transparency it provides with respect to users, tasks and the underlying operating system. ",2003
41,Rachid Anane,Multiple evolutionary agents for decision support,https://pureportal.coventry.ac.uk/en/publications/multiple-evolutionary-agents-for-decision-support-2,,2003
42,Rachid Anane,Transaction oriented engineering design and formal specification: a multi-agent approach,https://pureportal.coventry.ac.uk/en/publications/transaction-oriented-engineering-design-and-formal-specification--2,"Engineering design activities in distributed environments like the Web require fault tolerance and concurrent access to shared resources such as databases and Web servers. Such activities are generally dynamic, cooperative, long-lived, interactive and non-prescriptive. We propose a new multi-agent transaction model, which is based on extended transactions and multi-agent technologies. The novelty of this model is that it automatically customises transactions to the requirements of design activities. In addition, this model is believed to improve concurrency, fault tolerance, facilitate interaction between and co-operation among the participating systems involved in design activities. The proposed model is formally specified using CCS (Calculus of Communicating Systems) language. Formalisation is crucial in ensuring the correctness, reliability, and recovery of multi-agents transactions, given the complex and unreliable nature of the distributed design activities.

",2003
43,Rachid Anane,An agent-based approach to engineering design,https://pureportal.coventry.ac.uk/en/publications/an-agent-based-approach-to-engineering-design-2,"Among the features of concurrent engineering is the notion of distributed design, and the ability to communicate design changes to multidisciplinary teams. Engineering design is a complex activity. Differences in system architectures and information structures, and co-ordination requirements tend to reduce the effectiveness of distributed design. Current thinking indicates that multi-agent systems (MAS) can alleviate some of the complex engineering design problems. In this paper, it is argued that agent attributes such as proactiveness and autonomy can overcome these limitations. Agents provide a flexible and dynamic approach to distributed/multidisciplinary design team which can reduce redundant design activities, and improve co-ordination.",May 2002
44,Rachid Anane,Data mining and serial documents,https://pureportal.coventry.ac.uk/en/publications/data-mining-and-serial-documents-2,,Aug 2001
45,Rachid Anane,HiSQL: A front-end Query System for Historical Databases,https://pureportal.coventry.ac.uk/en/publications/hisql-a-front-end-query-system-for-historical-databases,"The paper describes a prototype system called HiSQL (Historical SQL) which extends the functionality of SQL in manipulating historical data, by providing functions for spatial and temporal processing. Conceptually the paper is divided into three parts: the ﬁrst part deals with the design and architecture of the system; the second part introduces a case study (the defters); and the third part describes speciﬁc functions for spatial and temporal processing of serial documents. The paper concludes with a comparison between HiSQL and SQL and suggestions for further work.",Nov 1997
46,Farzana Aslam,The Scientific Approach of The Indonesian 2013 Curriculum: A Comparison with Other Active Learning Strategies in Mathematics,https://pureportal.coventry.ac.uk/en/publications/the-scientific-approach-of-the-indonesian-2013-curriculum-a-compa,"The Indonesian 2013 curriculum is an improvement on the previous curriculum, namely the Education Unit Level Curriculum (KTSP). The implementation of the 2013 curriculum strongly emphasizes a Scientific Approach with student-centred learning to prepare Indonesian citizens to have the ability to live as individuals and citizens who are productive, creative, and innovative. The Scientific Approach is a learning process designed so that students actively construct concepts and principles through the stages of observing, asking, exploring, associating, and communicating. The purpose of this study is to compare the principles of the Scientific Approach of the 2013 curriculum with four different active learning strategies, namely Discovery Learning (DL); Inquiry-Based Learning (IBL); Problem-Based Learning (PBL) and Realistic Mathematics Education (RME). The result of this study is the recommendation of a dynamic modification of the Scientific Approach in the 2013 curriculum.",15 May 2022
47,Farzana Aslam,Exploring differential engagement with mathematics support from an engineering student focus,https://pureportal.coventry.ac.uk/en/publications/exploring-differential-engagement-with-mathematics-support-from-a,"This paper explores the differential engagement of engineering students with mathematics support at Coventry University. Mathematics support is additional help in mathematics which is offered to all students at the University, and engagement with such support is voluntary. Attendance records show that whilst many students do engage with mathematics support, there are others who do not, even though their results indicate that they might benefit from so doing. Previous studies of engagement with mathematics support have either treated the student cohort as a whole or explored the effect of a single demographic factor such as age or gender. This paper investigates the effect of a range of demographic factors on the engagement of engineering students with mathematics support.",23 Dec 2021
48,Farzana Aslam,STEM outreach activities: an approach to teachers' professional development,https://pureportal.coventry.ac.uk/en/publications/stem-outreach-activities-an-approach-to-teachers-professional-dev-3,,29 May 2019
49,Farzana Aslam,STEM outreach activities: an approach to teachers’ professional development: STEM outreach activities,https://pureportal.coventry.ac.uk/en/publications/stem-outreach-activities-an-approach-to-teachers-professional-dev,"STEM outreach programmes in secondary schools are mediated by STEM teachers who are responsible for organising, implementing and evaluating the activities with a view to promoting STEM subjects. However, research investigating teachers' STEM roles and professional development through participation in outreach activities is limited. This paper explores teachers' views of STEM activities, how they understand their role as primary facilitators and the impact of their STEM engagement on their professional development. STEM outreach provides distinct opportunities for situated and dialogic learning. STEM teachers' effectiveness in engaging students by demonstrating the importance and relevance of STEM subjects in the real world and engaging captivating STEM outreach partners not only supports students learning but also enhances their opportunities to develop their knowledge and skills. Semi structured interviews were conducted with eleven teachers from six different schools in the West Midlands, United Kingdom. The data reveals STEM facilitators become the 'face' of STEM to their pupils. The expertise, knowledge and partnerships STEM facilitators develop, broadens their capacity to deliver teaching imbued with real world applications and improve students' understanding of the range of new and upcoming careers available. Most importantly, participating in STEM outreach activities help teachers maintain and reinforce their own sense of identity as STEM professionals. Outreach activities provide opportunities for teachers to interact with leading scientists and obtain exposure to cutting-edge research. [ABSTRACT FROM AUTHOR]",10 Jan 2018
50,Farzana Aslam,Computational characterisation of absorption properties of CdSe nanostructure,https://pureportal.coventry.ac.uk/en/publications/computational-characterisation-of-absorption-properties-of-cdse-n-2,,15 Mar 2013
51,Kamal Bentahar,Generic constructions of identity-based and certificateless KEMs,https://pureportal.coventry.ac.uk/en/publications/generic-constructions-of-identity-based-and-certificateless-kems,"We extend the concept of key encapsulation to the primitives of identity-based and certificateless encryption. We show that the natural combination of ID-KEMs or CL-KEMs with data encapsulation mechanisms results in encryption schemes that are secure in a strong sense. In addition, we give generic constructions of ID-KEMs and CL-KEMs that are provably secure in the random oracle model.",Apr 2008
52,Kamal Bentahar,"Efficient 15,360-bit RSA using woop-optimised montgomery arithmetic",https://pureportal.coventry.ac.uk/en/publications/efficient-15360-bit-rsa-using-woop-optimised-montgomery-arithmeti,The US government has published recommended RSA key sizes to go with AES-256 bit keys. These are huge and it is not clear what is the best strategy to implement modular arithmetic. This paper aims to investigate a set of possibilities from straight Montgomery and Barrett arithmetic through to combining them with Karatsuba and Toom-Cook style techniques.,2007
53,Kamal Bentahar,Lash,https://pureportal.coventry.ac.uk/en/publications/lash,"We present a practical cryptographic hashfunction based on the Miyaguchi–Preneel construction,which instead of using a block cipher as the main componentuses a modular matrix multiplication. Thus as the corecomponent it uses a compression function which is closelyrelated to the theoretical lattice based hash function consideredby Goldreich, Goldwasser and Halevi. We show that bysuitable parameter choices we can produce a hash functionwhich is comparable in performance to existing deployedhash functions such as SHA-1 and SHA-2.",2006
54,Kamal Bentahar,"The equivalence between the DHP and DLP for elliptic curves used in practical applications, revisited",https://pureportal.coventry.ac.uk/en/publications/the-equivalence-between-the-dhp-and-dlp-for-elliptic-curves-used-,"The theoretical equivalence between the DLP and DHP problems was shown by Maurer in 1994. His work was then reexamined by Muzereau et al. [12] for the special case of elliptic curves used in practical cryptographic applications. This paper improves on the latter and tries to get the tightest possible reduction in terms of computational equivalence, using Maurer's method.",2005
55,Omid Chatrabgoun,Gaussian Process Emulation of Spatio-temporal Outputs of a 2D Inland Flood Model,https://pureportal.coventry.ac.uk/en/publications/gaussian-process-emulation-of-spatio-temporal-outputs-of-a-2d-inl,"The computational limitations of complex numerical models have led to adoption of statistical emulators across a variety of problems in science and engineering disciplines to circumvent the high computational costs associated with numerical simulations. In flood modelling, many hydraulic and hydrodynamic numerical models, especially when operating at high spatiotemporal resolutions, have prohibitively high computational costs for tasks requiring the instantaneous generation of very large numbers of simulation results. This study examines the appropriateness and robustness of Gaussian Process (GP) models to emulate the results from a hydraulic inundation model. The developed GPs produce real-time predictions based on the simulation output from LISFLOOD-FP numerical model. An efficient dimensionality reduction scheme is developed to tackle the high dimensionality of the output space and is combined with the GPs to investigate the predictive performance of the proposed emulator for estimation of the inundation depth. The developed GP-based framework is capable of robust and straightforward quantification of the uncertainty associated with the predictions, without requiring additional model evaluations and simulations. Further, this study explores the computational advantages of using a GP-based emulator over alternative methodologies such as neural networks, by undertaking a comparative analysis. For the case study data presented in this paper, the GP model was found to accurately reproduce water depths and inundation extent by classification and produce computational speedups of approximately 10,000 times compared with the original simulator, and 80 times for a neural network-based emulator.",15 Oct 2022
56,Omid Chatrabgoun,On the impact of prior distributions on efficiency of sparse Gaussian process regression,https://pureportal.coventry.ac.uk/en/publications/on-the-impact-of-prior-distributions-on-efficiency-of-sparse-gaus,"Gaussian process regression (GPR) is a kernel-based learning model, which unfortunately suffers from computational intractability for irregular domain and large datasets due to the full kernel matrix. In this paper, we propose a novel method to produce a sparse kernel matrix using the compact support radial kernels (CSRKs) to efficiently learn the GPR from large datasets. The CSRKs can effectively avoid the ill-conditioned and full kernel matrix during GPR training and prediction, consequently reducing computational costs and memory requirements. In practice, the interest in CSRKs waned slightly as it became evident that, there is a trade-off principle (conflict between accuracy and sparsity) for compactly supported kernels. Hence, when using kernels with compact support, during GPR training, the main focus will be on providing a high level of accuracy. In this case, the advantage of achieving a sparse covariance matrix for CSRKs will almost disappear, as we will see in the numerical results. This trade-off has led authors to search for an “optimal” value of the scale parameter. Accordingly, by selecting the suitable priors on the kernel hyperparameters, and simply estimating the hyperparameters using a modified version of the maximum likelihood estimation (MLE), the GPR model derived from the CSRKs yields maximal accuracy while still maintaining a sparse covariance matrix. In fact, in GPR training, modified version of the MLE will be proportional to the product of MLE and a given suitable prior distribution for the hyperparameters that provides an efficient method for learning. The misspecification of prior distributions and their impact on the predictability of the sparse GPR models are also comprehensively investigated using several empirical studies. The proposed new approach is applied to some irregular domains with noisy test functions in 2D data sets in a comparative study. We finally investigate the effect of prior on the predictability of GPR models based on the real dataset. The derived results suggest the proposed method leads to more sparsity and well-conditioned kernel matrices in all cases.",26 Jun 2022
57,Omid Chatrabgoun,Predicting Primary Sequence-Based Protein-Protein Interactions Using a Mercer Series Representation of Nonlinear Support Vector Machine,https://pureportal.coventry.ac.uk/en/publications/predicting-primary-sequence-based-protein-protein-interactions-us,"The prediction of protein-protein interactions (PPIs) is essential to understand the cellular processes from a medical perspective. Among the various machine learning techniques, kernel-based Support Vector Machine (SVM) has been commonly employed to discriminate between interacting and non-interacting protein pairs. The main drawback of employing the kernel-based SVM to datasets with many features, such as the primary sequence-based protein-protein dataset, is the significant increase in computational time of training stage. This increase in computational time is mainly due to the presence of the kernel in solving the quadratic optimisation problem (QOP) involved in nonlinear SVM. In order to fix this issue, we propose a novel and efficient computational algorithm by approximating the kernel-based SVM using a low-rank truncated Mercer series as well as desired. As a result, the QOP for the approximated kernel-based SVM will be very tractable in the sense that there is a significant reduction in computational time of training and validating stages. We illustrate the novelty of the proposed method by predicting the PPIs of ""S. Cerevisiae” where the protein features extracted using the multiscale local descriptor (MLD), and then we compare the predictive performance of the proposed low-rank approximation with the existing methods. Finally, the new method results in significant reduction in computational time for predicting PPIs with almost as accuracy as kernel-based SVM",1 Dec 2022
58,Omid Chatrabgoun,Stable likelihood computation for machine learning of linear differential operators with Gaussian processes,https://pureportal.coventry.ac.uk/en/publications/stable-likelihood-computation-for-machine-learning-of-linear-diff,"In many applied sciences, the main aim is to learn the parameters in the operational equations which best fit the observed data. A framework for solving such problems is to employ Gaussian process (GP) emulators which are well-known as nonparametric Bayesian machine learning techniques. GPs are among a class of methods known as kernel machines which can be used to approximate rather complex problems by tuning their hyperparameters. The maximum likelihood estimation (MLE) has widely been used to estimate the parameters of the operators and kernels. However, the MLE-based and Bayesian inference in the standard form are usually involved in setting up a covariance matrix which is generally ill-conditioned. As a result, constructing and inverting the covariance matrix using the standard form will become unstable to learn the parameters in the operational equations. In this paper, we propose a novel approach to tackle these computational complexities and also resolve the ill-conditioning problem by forming the covariance matrix using alternative bases via the Hilbert−Schmidt SVD (HS-SVD) approach. Applying this approach yields a novel matrix factorization of the block-structured covariance matrix which can be implemented stably by isolating the main source of the ill-conditioning. In contrast to standard matrix decompositions which start with a matrix and produce the resulting factors, the HS-SVD is constructed from the Hilbert−Schmidt eigenvalues and eigenvectors without the need to ever form the potentially ill-conditioned matrix. We also provide stable MLE and Bayesian inference to adaptively estimate hyperparameters, and the corresponding operators can then be efficiently predicted at some new points using the proposed HS-SVD bases. The efficiency and stability of the proposed HS-SVD method will be compared with the existing methods by several illustrations of the parametric linear equations, such as ordinary and partial differential equations, and integro-differential and fractional order operators.",20 Apr 2022
59,Omid Chatrabgoun,A low cost and highly accurate technique for big data spatial-temporal interpolation,https://pureportal.coventry.ac.uk/en/publications/a-low-cost-and-highly-accurate-technique-for-big-data-spatial-tem,"The high velocity, variety and volume of data generation by today's systems have necessitated Big Data (BD) analytic techniques. This has penetrated a wide range of industries; BD as a notion has various types and characteristics, and therefore a variety of analytic techniques would be required. The traditional analysis methods are typically unable to analyse spatial-temporal BD. Interpolation is required to approximate the values between the already existing data points, yet since there exist both location and time dimensions, only a multivariate interpolation would be appropriate. Nevertheless, existing software are unable to perform such complex interpolations. To overcome this challenge, this paper presents a layer by layer interpolation approach for spatial-temporal BD. Developing this layered structure provides the opportunity for working with much smaller linear system of equations. Consequently, this structure increases the accuracy and stability of numerical structure of the considered BD interpolation. To construct this layer by layer interpolation, we have used the good properties of Radial Basis Functions (RBFs). The proposed new approach is applied to numerical examples in spatial-temporal big data and the obtained results confirm the high accuracy and low computational cost. Finally, our approach is applied to explore one of the air pollution indices, i.e. daily PM2.5 concentration, based on different stations in the contiguous United States, and it is evaluated by leave-one-out cross validation.",1 Jul 2020
60,Omid Chatrabgoun,Constructing gene regulatory networks from microarray data using non-Gaussian pair-copula Bayesian networks,https://pureportal.coventry.ac.uk/en/publications/constructing-gene-regulatory-networks-from-microarray-data-using-,"Many biological and biomedical research areas such as drug design require analyzing the Gene Regulatory Networks (GRNs) to provide clear insight and understanding of the cellular processes in live cells. Under normality assumption for the genes, GRNs can be constructed by assessing the nonzero elements of the inverse covariance matrix. Nevertheless, such techniques are unable to deal with non-normality, multi-modality and heavy tailedness that are commonly seen in current massive genetic data. To relax this limitative constraint, one can apply copula function which is a multivariate cumulative distribution function with uniform marginal distribution. However, since the dependency structures of different pairs of genes in a multivariate problem are very different, the regular multivariate copula will not allow for the construction of an appropriate model. The solution to this problem is using Pair-Copula Constructions (PCCs) which are decompositions of a multivariate density into a cascade of bivariate copula, and therefore, assign different bivariate copula function for each local term. In fact, in this paper, we have constructed inverse covariance matrix based on the use of PCCs when the normality assumption can be moderately or severely violated for capturing a wide range of distributional features and complex dependency structure. To learn the non-Gaussian model for the considered GRN with non-Gaussian genomic data, we apply modified version of copula-based PC algorithm in which normality assumption of marginal densities is dropped. This paper also considers the Dynamic Time Warping (DTW) algorithm to determine the existence of a time delay relation between two genes. Breast cancer is one of the most common diseases in the world where GRN analysis of its subtypes is considerably important; Since by revealing the differences in the GRNs of these subtypes, new therapies and drugs can be found. The findings of our research are used to construct GRNs with high performance, for various subtypes of breast cancer rather than simply using previous models.",24 Jul 2020
61,Omid Chatrabgoun,Copula-based probabilistic assessment of intensity and duration of cold episodes: A case study of Malayer vineyard region,https://pureportal.coventry.ac.uk/en/publications/copula-based-probabilistic-assessment-of-intensity-and-duration-o,"Frost, particularly during the spring, is one of the most damaging weather phenomena for vineyards, causing significant economic losses to vineyards around the world each year. The risk of tardive frost damage in vineyards due to changing climate is considered as an important threat to the sustainable production of grapes. Therefore, the cold monitoring strategies is one of the criteria with significant impacts on the yields and prosperity of horticulture and raisin factories. Frost events can be characterized by duration and severity. This paper investigates the risk and impacts of frost phenomenon in the vineyards by modeling the joint distribution of duration and severity factors and analyzing the influential parameter’s dependency structure using capabilities of copula functions. A novel mathematical framework is developed within this study to understand the risk and uncertainties associate with frost events and the impacts on yields of vineyards by analyzing the non-linear dependency structure using copula functions as an efficient tool. The developed model was successfully validated for the case study of vineyard in Malayer city of Iran. The copula model developed in this study was shown to be a robust tool for predicting the return period of the frost events.",15 Dec 2020
62,Omid Chatrabgoun,An efficient method based on RBFs for multilayer data interpolation with application in air pollution data analysis,https://pureportal.coventry.ac.uk/en/publications/an-efficient-method-based-on-rbfs-for-multilayer-data-interpolati,"Multivariate interpolation is a fundamental and long-studied problem, which has numerous applications in mathematics, engineering, computer science, and the natural sciences. A basic tool for solving the problem of high-dimensional interpolation is through the usage of radial basis functions (RBFs). In fact, the combination of interpolation and RBFs can lead to very good properties in high dimensions. Unfortunately, the linear system of equations derived from the approximations of RBFs with a high order of convergence is ill-conditioned and unstable, and usually includes a full interpolation matrix. To solve such a system of equations, we face a very high computational cost if the dimension of the problems or the number of data points is increased. This can also lead to intense instability in the considered problem, and the condition number of the system of equations, as a measure of the ill-conditioning criterion, will be very large. To overcome these problems, this paper presents a layer-by-layer interpolation approach for solving scattered data approximation of an unknown multivariate function, where the information of this approximation problem has been given in certain layers. In this approach, by creating a layered structure, the computational cost is reduced and decreasing the condition number is also possible. This structure provides a possibility for encountering a much smaller linear system of equations. In other words, it increases the accuracy and the stability of the numerical structure of the considered interpolation. The new method can ensure the existence and the uniqueness of the solution for the multilayer interpolation problem. We also find that the layer-by-layer approach provides more numerically stable calculations than the traditional interpolation method. The new approach is applied for certain numerical examples in high dimensions and the obtained results confirm the high accuracy and the low computational cost of the proposed method. Finally, our approach is applied to explore one of the air pollution indexes, i.e., ozone concentration, which has been based on different stations in Tehran, Iran.",1 Oct 2019
63,Omid Chatrabgoun,Exact Reliability for a Consecutive Circular k-out-of-r-from-n: F System with Equal and Unequal Component Probabilities,https://pureportal.coventry.ac.uk/en/publications/exact-reliability-for-a-consecutive-circular-k-out-of-r-from-n-f-,"A consecutive linear (circular) k-out-of-r-from-n: F system consists of n linear (circular)-ordered components such that the system fails if and only if there exists a set of r consecutive linear (circular) component that contains at least k failed components. Consecutive linear (circular) k-out-of-r-from-n: F systems attract tremendous attention for researchers of reliability analysis. Recent efforts in this area have focused on simple situations or approximation bands for their reliability but closed form and exact amount not gained. In this paper, we designed an innovative algorithm and an innovative program to obtain the exact reliability for an extensive class of consecutive circular k-out-of-r-from-n: F system with particular emphasis for equal and unequal component probabilities. Finally, we reviewed an applied example and applied comparative and numerical results and calculated the exact reliability of this strategic system.",26 Jul 2019
64,Omid Chatrabgoun,Numerical solution of time-dependent stochastic partial differential equations using RBF partition of unity collocation method based on finite difference,https://pureportal.coventry.ac.uk/en/publications/numerical-solution-of-time-dependent-stochastic-partial-different,"Meshfree methods based on radial basis functions (RBFs) are popular tools for the numerical solution of stochastic partial differential equations (SPDEs) due to their nice properties. However, the RBF collocation methods in global view have some disadvantages for the numerical solution of time-dependent SPDEs. Calculation of matrix condition number in the resulting dense linear systems indicates that the meshless method using global RBFs may be unstable at each realization to solve SPDEs. In order to avoid numerical instabilities in global RBF methods, we are interested in the use of RBF methods in local view for the numerical solution of time-dependent SPDEs. In this paper, the RBF partition of unity collocation method based on a finite difference scheme for the Gaussian random field (RBF-PU-FD) as a localized RBF approximation presented to deal with these issues. For this purpose, we simulate the Gaussian field with spatial covariance structure at a finite collection of predetermined collocation points. The matrices formed during the RBF-PU-FD method will be sparse and, hence, will not suffer from ill-conditioning and high computational cost. We will show that the method is viable through analyzing its numerical accuracy, CPU time, stability and sparsity structure. For the test problems, we perform 1000 realizations and statistical criterions such as mean, standard deviation, lower bound and upper bound of prediction are computed and evaluated using the Monte-Carlo method.",Jul 2019
65,Omid Chatrabgoun,Optimizing minimum information pair-copula using genetic algorithm to select optimal basis functions,https://pureportal.coventry.ac.uk/en/publications/optimizing-minimum-information-pair-copula-using-genetic-algorith,"Constructing pair-copula using the minimum information approach is an appropriate and flexible way to survey the dependency structure between variables of interest. Minimum information pair-copula method approximates multivariate copula by applying some constraints between desired variables that are elicited from the data itself or experts’ judgment. In minimum information pair-copula, selecting basis constraints is a challenge. In this article, we apply genetic algorithms as a heuristic way to select basis constraints to optimize approximated pair-copula. The results gained show that our method optimizes model selection criteria and lead to better pair-copula approximation. Finally, we apply our proposed method to approximate pair-copula density in real dataset.",7 Feb 2019
66,Omid Chatrabgoun,The Role of Hilbert–Schmidt SVD basis in Hermite–Birkhoff interpolation in fractional sense,https://pureportal.coventry.ac.uk/en/publications/the-role-of-hilbertschmidt-svd-basis-in-hermitebirkhoff-interpola,"The Hermite–Birkhoff (HB) interpolation is an extension of polynomial interpolation that appears when observation gives operational information. Additional capabilities in HB interpolation by considering fractional operators are created, as it occur in many applied systems. Due to the nice properties in kernel-based approximation, we intend to apply it to solve the HB interpolation in the fractional sense. We show the standard basis in kernel-based approximation is often insufficient for computing a stable solution in fractional HB interpolation. Because of the inherent ill-condition of kernel-based methods, we investigate the fractional HB interpolation using alternate Hilbert–Schmidt SVD (HS–SVD) bases, since it provides a linear transformation which can be applied analytically, and therefore, is able to remove a significant portion of the ill-conditioning. Also, the convergence and stability of the fractional HB interpolation using HS–SVD method are discussed. Numerical results show that in solving fractional HB interpolation, although the standard basis for many positive definite kernels is ill-conditioned in the flat limit, the HS–SVD basis solves the existing problem.",1 Apr 2019
67,Omid Chatrabgoun,Using Low-Rank Approximation In Order To Improve the Efficiency of the Support Vector Machine and Applications,https://pureportal.coventry.ac.uk/en/publications/using-low-rank-approximation-in-order-to-improve-the-efficiency-o,"Support vector machine is one of the most powerful tools in the field of supervised machine learning to classify the existed data. In the data that the linear support vector machine does not have the required efficiency in their classification, using the kernel-based support vector machine which is based on the use of feature space instead of the original data is considered. As a result of this structure, nonlinear classification can be provided. One of the challenges in this approach is to increase the computational complexity and ultimately increase in the required time for classification. As such, it is not particularly useful for large datasets. This increase in computational time is mainly due to the appearance of the kernel in solving the quadratic optimization problem, which we will be able to overcome this problem using the presented low-rank approximation in this paper. In this technique, using a truncated Mercer series of the kernel, the quadratic optimization problem in the kernel-based support vector machine is replaced with a much simpler optimization problem. In the new presented approach, the required vector computations and matrix decompositions will be much faster such that these changes lead to faster resolution of the quadratic optimization problem and increase efficiency. Finally, the results of experiments show that using a low-rank kernel-based approximation of support vector machine, while keeping the classification performance in an acceptable range, the computational time has been significantly reduced.",Oct 2019
68,Omid Chatrabgoun,Approximating non-Gaussian Bayesian networks using minimum information vine model with applications in financial modelling,https://pureportal.coventry.ac.uk/en/publications/approximating-non-gaussian-bayesian-networks-using-minimum-inform,"Many financial modeling applications require to jointly model multiple uncertain quantities to present more accurate, near future probabilistic predictions. Informed decision making would certainly benefit from such predictions. Bayesian networks (BNs) and copulas are widely used for modeling numerous uncertain scenarios. Copulas, in particular, have attracted more interest due to their nice property of approximating the probability distribution of the data with heavy tail. Heavy tail data is frequently observed in financial applications. The standard multivariate copula suffer from serious limitations which made them unsuitable for modeling the financial data. An alternative copula model called the pair-copula construction (PCC) model is more flexible and efficient for modeling the complex dependence of financial data. The only restriction of PCC model is the challenge of selecting the best model structure. This issue can be tackled by capturing conditional independence using the Bayesian network PCC (BN-PCC). The flexible structure of this model can be derived from conditional independences statements learned from data. Additionally, the difficulty of computing conditional distributions in graphical models for non-Gaussian distributions can be eased using pair-copulas. In this paper, we extend this approach further using the minimum information vine model which results in a more flexible and efficient approach in understanding the complex dependence between multiple variables with heavy tail dependence and asymmetric features which appear widely in the financial applications.",Jan 2018
69,Omid Chatrabgoun,Discrete Weighted Exponential Distribution of the Second Type: Properties and Applications,https://pureportal.coventry.ac.uk/en/publications/discrete-weighted-exponential-distribution-of-the-second-type-pro,"In this paper, we propose a new lifetime model as a discrete version of the continuous weighted exponential distribution which is called discrete weighted exponential distribution (DWED). This model is a generalization of the discrete exponential distribution which is originally introduced by Chakraborty (2015). We present various statistical indices/properties of this distribution including reliability indices, moment generating function, probability generating function, survival and hazard rate functions, index of dispersion, and stress-strength parameter. We rst present a numerical method to compute the maximum likelihood estima-tions (MLEs) of the models parameters, and then conduct a simulation study to further analyze these estimations. The advantages of the DWED are shown in practice by applying it on two real world applications and compare it with some other well-known lifetime distributions.",2018
70,Omid Chatrabgoun,"Effects of morphine on the biomass and development rate of Chrysomya albiceps (Diptera: Calliphoridae), a forensically important species",https://pureportal.coventry.ac.uk/en/publications/effects-of-morphine-on-the-biomass-and-development-rate-of-chryso,"The aim of this study was to determine the effects of morphine on the biomass and development rate of Chrysomya albiceps (Diptera: Calliphoridae). C. albiceps, a well-known forensically important species which is among the first wave of faunal succession on human cadavers, which makes it a valuable source of information for the estimation of postmortem interval (PMI). Antemortem exposure to substances such as drugs and toxins may have an effect on the biomass and/or on the development rate of insects that feed on carcass, which may directly affect PMI estimation. In this study, three rabbits were administered 12.5, 25 or 50 mg/ml of morphine sulfate via ear perfusion over a period of 3 hours, and a fourth rabbit, which did not receive morphine, was used as a control. The rabbits were sacrificed using chloroform 30 minutes after morphine administration. The tissues were analyzed for the presence of morphine using HPLC-UV. Morphine was detected in all tissues of rabbits that received morphine, except in the bile and spleen of the rabbit which received 12.5 mg/ml dose of morphine. The presence of morphine in rabbit tissues retarded larval development rate, but accelerated the puparial development rate. The rate of development of C. albiceps larvae that fed on rabbits which received 25 and 50 mg/ml dosages of morphine was 9 days each. However, the rate of larval development was similar in the 12.5 mg/ml morphine group and the control; 6 days. Results of this study show that an underestimation of the postmortem interval of 72 h based on larval development and an overestimation of 24 to 48 h based on puparial development is possible if the presence of morphine in tissues is not considered. Moreover, the decreased larval development rate caused an increase larval length and weight compared with the control group. In this study, we found a strong correlation between the concentration of morphine administered and concentrations in rabbit tissues. In the estimation of PMI, it is recommended that effects of drugs such as morphine on the development of carcass colonizers be considered.",1 Jun 2018
71,Omid Chatrabgoun,Evaluation of Insect Succession Patterns and Carcass Weight Loss for the Estimation of Postmortem Interval,https://pureportal.coventry.ac.uk/en/publications/evaluation-of-insect-succession-patterns-and-carcass-weight-loss-,"This study assesses the succession of insects on rabbit carcass. The study was conducted in sunny and shaded sites in the west of Iran during four seasons in 2016 and 2017. Based on the results of this study, various factors such as body size, carcass location, and carcass injury could affect the pattern of insect succession on carcass. In this study, we estimated the elapsed time since death (R2 > 0.98, P = 0.00) based on carcass weight loss during the stages of decomposition and the cubic method. Jaccard analysis was performed to determine the similarity of insect taxa during decomposition of rabbit carrion in two different sites during a period of four seasons. Succession pattern analysis for necrophagous insects in both habitats showed a similarity between bloat and decay stages for each habitat. On the other hand, pairwise similarities in taxa were low at the fresh and dry stages, however increased at bloat and decay stages of decomposition. This study shows that succession has some limitations in determining the elapsed time of death. Therefore, the use of source of information such as a weight loss model seems to be essential.",6 Jul 2018
72,Omid Chatrabgoun,Fractional Hermite Interpolation using RBFs in High Dimensions over irregular domains with application,https://pureportal.coventry.ac.uk/en/publications/fractional-hermite-interpolation-using-rbfs-in-high-dimensions-ov,"In the interpolation method, in some cases, one often has a number of data points and its derivatives, which are obtained by sampling or experimentation. In this case, the problem of finding an approximating function passing through these points and coinciding with given values of its derivatives at these points is generally known as “Hermite interpolation”. The Hermite interpolation is mostly a method of interpolating data points as a polynomial function that is faced with some challenges in high dimensions and on irregular domains. Radial basis functions take advantage of being flexible with respect to geometry, easy to implement in higher dimensions, and can also provide high order convergence. So, they can be applied as a suitable tool to high dimensional Hermite interpolation problem on irregular domains. In many applied systems, commonly available derivatives information is presented using fractional order derivatives instead of integer ones. For this purpose, in this paper, we assume that the values of an unknown function and its fractional derivatives at some distinct points are presented. Therefore, we intend to apply a new approach, which we call it as “fractional Hermite interpolation” with radial basis functions in high dimensions. Optimal recovery conditions for the fractional Hermite interpolant are investigated. Then, the existence and uniqueness of the solution in this type of generalized interpolation are proved. In order to increase the accuracy and stability of the method, Hilbert Schmidt's theory has also been used. The main advantages of the used method are its simplicity and efficiency in high dimensions, and over irregular domains. Finally, numerical results in one, two and three dimensions and a real-world problem are presented to support our theoretical analysis.",15 Dec 2018
73,Omid Chatrabgoun,Toxicological analysis of insects on the corpse: a valuable source of information in forensic investigations,https://pureportal.coventry.ac.uk/en/publications/toxicological-analysis-of-insects-on-the-corpse-a-valuable-source,"Entomotoxicology as a subset of forensic entomology can be used by analysis of carcass feeding in­sects to detecting of drugs or toxins, as well as the cause and manner of death in cases of ante-mortem drugs intoxi­cation. Morphine is one of the deacetylate metabolites of heroin. The aim of this study was to determine the presence and quantity of morphine in insects on the carcass and compare them with decomposing carcass. Methods: Field of this study was in Chalabeh District and toxicological tests were carried out at the Department of Forensic Toxicology, Legal Medicine Center, Kermanshah, Iran in 2017. Morphine was inoculated into live rabbit as experimental model at concentrations of 12.5, 25, 50mg/ml, similar to those normally encountered in human over­doses, then quality and quantity of morphine were determined in insects such as Chrysomya albiceps (as the first wave of insect succession on human cadavers) fed on carcass. Results: Quantitative assessment at larvae showed that morphine was detected in all larvae (feeding and post feeding stage) fed on tissues from carcasses administered morphine, except for post-feeding larvae from R1 which received 12.5mg/ml dosage of morphine. Conclusions: Necrophagous insects are an indicator on the scene of crime and a potential source of information about the antemortem situation. Detection of drug in insects which is actually a reflection of the cause of death is possible.",2018
74,Omid Chatrabgoun,A Legendre multiwavelets approach to copula density estimation,https://pureportal.coventry.ac.uk/en/publications/a-legendre-multiwavelets-approach-to-copula-density-estimation,"In this paper, a novel method for copula density estimation using Legendremultiwavelet is proposed. In general, copula density estimation methods based on the multiwavelet benefit from some useful properties, including they are symmetric, orthogonal and have compact support. In particular, the Legendre multiwavelet as a more general and vector-valued polynomial type of wavelets would results a more flexible and accurate approximation for the given copula density. In addition to high ability and nice properties of Legendre multiwavelet in approximation, its support is defined on unit interval, [0,1], as copulas that are normalized to have the support on the unit square and uniform marginal. We further make this approximation method more accurate by using multiresolution techniques. The comparative study reveals that the approximation proposed in this paper is more accurate than a scalar wavelet bases approximation. We eventually apply presented method to approximate multivariate distribution using pair-copula as a flexible multivariate copula to model a dataset of Norwegian financial data.",Sept 2017
75,Omid Chatrabgoun,Scattered data fitting of Hermite type by a weighted meshless method,https://pureportal.coventry.ac.uk/en/publications/scattered-data-fitting-of-hermite-type-by-a-weighted-meshless-met,"In many practical problems, it is often desirable to interpolate not only the function values but also the values of derivatives up to certain order, as in the Hermite interpolation. The Hermite interpolation method by radial basis functions is used widely for solving scattered Hermite data approximation problems. However, sometimes it makes more sense to approximate the solution by a least squares fit. This is particularly true when the data are contaminated with noise. In this paper, a weighted meshless method is presented to solve least squares problems with noise. The weighted meshless method by Gaussian radial basis functions is proposed to fit scattered Hermite data with noise in certain local regions of the problem’s domain. Existence and uniqueness of the solution is proved. This approach has one parameter which can adjust the accuracy according to the size of the noise. Another advantage of the weighted meshless method is that it can be used for problems in high dimensions with nonregular domains. The numerical experiments show that our weighted meshless method has better performance than the traditional least squares method in the case of noisy Hermite data.",6 Sept 2017
76,Omid Chatrabgoun,Approximation Multivariate Distribution with Pair Copula Using the Orthonormal Polynomial and Legendre Multiwavelets Basis Functions,https://pureportal.coventry.ac.uk/en/publications/approximation-multivariate-distribution-with-pair-copula-using-th,"We concentrate on constructing higher dimensional distributions using a fast growing graphical model called Vine/ pair-copula model which has been introduced and developed by Joe, Cooke, Bedford, Kurowica, Daneshkhah, and others. They first construct a n-dimensional copula density by stacking together n(n − 1)/2 bivariate copula density, and they then approximate arbitrarily well these bivariate copulas and the corresponding multivariate distribution using a semi-parametric method. One constructive approach involves the use of minimum information copulas that can be specified to any required degree of precision based on the available data (or possibly based on the experts’ judgments). By using this method, one is able to use a fixed finite dimensional family of copulas to be employed in terms of a vine construction, with the promise of a uniform level of approximation.The basic idea behind this method is to use a two-dimensional ordinary polynomial series to approximate any log-density of a bivariate copula function by truncating the series at an appropriate point. We make this approximation method more accurate and computationally faster by using the orthonormal polynomial and Legendre multiwavelets (LMW) series as the basis functions. We show the derived approximations are more precise and computationally faster with better properties than the one proposed previous method in the literature. We then apply our method to modeling a dataset of Norwegian financial data that was previously analyzed in the series of articles, and finally compare our results by them. At the end, we present a method to simulate from the approximated models, and validate our approximation using the simulation results to recover the same dependency structure of the original data.",2016
77,Omid Chatrabgoun,Inference for exponential parameter under progressive Type-II censoring from imprecise lifetime,https://pureportal.coventry.ac.uk/en/publications/inference-for-exponential-parameter-under-progressive-type-ii-cen,"Progressively Type-II censored sampling is an important method of obtaining data in lifetime studies. Statistical analysis of lifetime distributions under this censoring scheme is based on precise lifetime data. However, in real situations all observations and measurements of progressive Type-II censoring scheme are not precise numbers but more or less non-precise, also called fuzzy. In this paper, we consider the estimation of exponential mean parameter under progressive Type-II censoring scheme, when the lifetime observations are fuzzy and are assumed to be related to underlying crisp realization of a random sample. We propose a new method to determine the maximum likelihood estimate of the unknown mean parameter. In addition, a new numerical method for parameter estimation based on fuzzy data is provided. Using the parametric bootstrap method, we then discuss the construction of confidence intervals for the mean parameter. Monte Carlo simulations are performed to investigate the performance of all the different proposed methods. Finally, an illustrative example is also included.",26 Apr 2016
78,Omid Chatrabgoun,"Knowledge, attitude and practice of healthcare workers concerning Crimean-Congo hemorrhagic fever in Western Iran",https://pureportal.coventry.ac.uk/en/publications/knowledge-attitude-and-practice-of-healthcare-workers-concerning-,"ObjectiveTo determine the knowledge, attitude and practice of healthcare workers in Kermanshah Province about Crimean-Congo hemorrhagic fever (CCHF).MethodsThis study was conducted in 2014 on healthcare personnel in different job categories including physicians, nurses, midwives, laboratory staff and network health staff of Kermanshah Province by direct interview.ResultsA total of 367 respondents who had more than 5 years of experience in their jobs were interviewed. Among them 91% of physicians and nurses, 97% of midwives and health workers and 96% of laboratory staff stated that they had not been confronted with CCHF patients so far. Regarding knowledge, 76% of physicians, 78% of nurses, 77% of midwives and 58% of laboratory staff believed that the disease is remediable. Most of the interviewed participants stated that the disease pertains to people who are in close contact with domestic animals, but they did not consider their own occupations as one of the risk factors. More than 70% of the respondents believed that the disease may exist in the province or their work field. Generally, the knowledge about CCHF was inadequate, with nurses having the lowest level of knowledge.ConclusionsKnowledge of Kermanshah healthcare staff about CCHF was poor, especially nurses in a high risk job category. Therefore, it is necessary to conduct specific training programs for the disease identification, transmission, prevention, and treatment as well as the use of personal protection and safety devices.",Jun 2016
79,Omid Chatrabgoun,Probabilistic modeling of flood characterizations with parametric and minimum information pair-copula model,https://pureportal.coventry.ac.uk/en/publications/probabilistic-modeling-of-flood-characterizations-with-parametric,"This paper highlights the usefulness of the minimum information and parametric pair-copula construction (PCC) to model the joint distribution of flood event properties. Both of these models outperform other standard multivariate copula in modeling multivariate flood data that exhibiting complex patterns of dependence, particularly in the tails. In particular, the minimum information pair-copula model shows greater flexibility and produces better approximation of the joint probability density and corresponding measures have capability for effective hazard assessments. The study demonstrates that any multivariate density can be approximated to any degree of desired precision using minimum information pair-copula model and can be practically used for probabilistic flood hazard assessment.",Sept 2016
80,Long Chen,Quality-Gauranteed Traditionally-sensed Areas Selection in Compressive Population Health,https://pureportal.coventry.ac.uk/en/publications/quality-gauranteed-traditionally-sensed-areas-selection-in-compre,,2021
81,Long Chen,Short-Term Prediction of Demand for Ride-Hailing Services: A Deep Learning Approach,https://pureportal.coventry.ac.uk/en/publications/short-term-prediction-of-demand-for-ride-hailing-services-a-deep-,"As ride-hailing services become increasingly popular, being able to accurately predict demand for such services can help operators efficiently allocate drivers to customers, and reduce idle time, improve traffic congestion, and enhance the passenger experience. This paper proposes UBERNET, a deep learning convolutional neural network for short-time prediction of demand for ride-hailing services. Exploiting traditional time series approaches for this problem is challenging due to strong surges and declines in pickups, as well as spatial concentrations of demand. This leads to pickup patterns that are unevenly distributed over time and space. UBERNET employs a multivariate framework that utilises a number of temporal and spatial features that have been found in the literature to explain demand for ride-hailing services. Specifically, the proposed model includes two sub-networks that aim to encode the source series of various features and decode the predicting series, respectively. To assess the performance and effectiveness of UBERNET, we use 9 months of Uber pickup data in 2014 and 28 spatial and temporal features from New York City. We use a number of features suggested by the transport operations and travel behaviour research areas as being relevant to passenger demand prediction, e.g., weather, temporal factors, socioeconomic and demographics characteristics, as well as travel-to-work, built environment and social factors such as crime level, within a multivariate framework, that leads to operational and policy insights for multiple communities: the ride-hailing operator, passengers, third-part location-based service providers and revenue opportunities to drivers, and transport operators such as road traffic authorities, and public transport agencies. By comparing the performance of UBERNET with several other approaches, we show that the prediction quality of the model is highly competitive. Further, UBERNET’s prediction performance is better when using economic, social and built environment features. This suggests that UBERNET is more naturally suited to including complex motivators of travel behavior in making real-time demand predictions for ride-hailing services.",Aug 2021
82,Long Chen,Topic detection and tracking on heterogeneous information,https://pureportal.coventry.ac.uk/en/publications/topic-detection-and-tracking-on-heterogeneous-information,"Given the proliferation of social media and the abundance of news feeds, a substantial amount of real-time content is distributed through disparate sources, which makes it increasingly difficult to glean and distill useful information. Although combining heterogeneous sources for topic detection has gained attention from several research communities, most of them fail to consider the interaction among different sources and their intertwined temporal dynamics. To address this concern, we studied the dynamics of topics from heterogeneous sources by exploiting both their individual properties (including temporal features) and their inter-relationships. We first implemented a heterogeneous topic model that enables topic–topic correspondence between the sources by iteratively updating its topic–word distribution. To capture temporal dynamics, the topics are then correlated with a time-dependent function that can characterise its social response and popularity over time. We extensively evaluate the proposed approach and compare to the state-of-the-art techniques on heterogeneous collection. Experimental results demonstrate that our approach can significantly outperform the existing ones.",Aug 2018
83,Alireza Daneshkhah,Artificial Intelligence for skeleton-based physical rehabilitation action evaluation: A systematic review,https://pureportal.coventry.ac.uk/en/publications/artificial-intelligence-for-skeleton-based-physical-rehabilitatio,"Performing prescribed physical exercises during home-based rehabilitation programs plays an important role in regaining muscle strength and improving balance for people with different physical disabilities. However, patients attending these programs are not able to assess their action performance in the absence of a medical expert. Recently, vision-based sensors have been deployed in the activity monitoring domain. They are capable of capturing accurate skeleton data. Furthermore, there have been significant advancements in Computer Vision (CV) and Deep Learning (DL) methodologies. These factors have promoted the solutions for designing automatic patient's activity monitoring models. Then, improving such systems’ performance to assist patients and physiotherapists has attracted wide interest of the research community. This paper provides a comprehensive and up-to-date literature review on different stages of skeleton data acquisition processes for the aim of physio exercise monitoring. Then, the previously reported Artificial Intelligence (AI) - based methodologies for skeleton data analysis will be reviewed. In particular, feature learning from skeleton data, evaluation, and feedback generation for the purpose of rehabilitation monitoring will be studied. Furthermore, the associated challenges to these processes will be reviewed. Finally, the paper puts forward several suggestions for future research directions in this area.",May 2023
84,Alireza Daneshkhah,Challenges and prospects of climate change impact assessment on mangrove environments through mathematical models,https://pureportal.coventry.ac.uk/en/publications/challenges-and-prospects-of-climate-change-impact-assessment-on-m,"The impacts of climate change, especially sea-level rise, are an increasing threat to the world’s coastal regions. Following recommendations made by the United Nations about the preservation of mangrove environments, particularly given their potential for effective natural defence against wave-driven hazards, a series of experiments have been conducted to quantify the ability of mangroves to counter climate change impacts. To date, these experiments have been limited by computational cost and inability to model multiple scenarios. With improved data quality and availability, machine learning has enormous potential to supplement, or even replace, existing numerical methods. This article presents both an outline of the importance of protecting mangrove environments and a review of methods currently used to quantify the capacity of mangroves to adapt to climate change impacts. In view of the limitations of existing numerical methods, the article also discusses the potential of machine learning as an efficient and effective alternative.",Apr 2023
85,Alireza Daneshkhah,Hydro-morphodynamic modelling of mangroves imposed by tidal waves using finite element discontinuous Galerkin method,https://pureportal.coventry.ac.uk/en/publications/hydro-morphodynamic-modelling-of-mangroves-imposed-by-tidal-waves,"Modelling the hydro-morphodynamics of mangrove environments is key for implementing successful protection and restoration projects in a climatically vulnerable region. Nevertheless, simulating such dynamics is faced with computational and time complexities, given the nonlinear and complex nature of the problem, which could become a bottleneck for large-scale applications. This study investigates the effect of mangrove environments on the hydro-morphodynamics of its region. A depth-averaged model was built using a novel finite element model for simulating coastal models, within Thetis. The Sundarbans, the largest mangrove forest in the world located between India and Bangladesh, is taken as a case study. The Sundarbans is regularly subjected to tropical cyclones, the impacts of which endanger the lives of the region’s four million people. This is a first-time application of a coupled hydro-morphodyamic model using discontinuous Galerkin finite element discretisation for modelling mangrove environments in a real-world application. A wetting drying scheme was implemented in the models in order to avoid numerical instabilities. The effect of mangrove environments is demonstrated ,by imposing a periodic tidal boundary, conditions using TPXO tidal solver, using experiments with and without mangroves. The model is validated against the results of another study on the same region and tidal gauge data. Mangrove environments are able to decrease water elevations and velocities by more than 97%, and prevent almost any sediment erosion when compared with the experiment with no mangroves.",28 Mar 2023
86,Alireza Daneshkhah,Measuring local sensitivity in Bayesian inference using a new class of metrics,https://pureportal.coventry.ac.uk/en/publications/measuring-local-sensitivity-in-bayesian-inference-using-a-new-cla,"The local sensitivity analysis is recognized for its computational simplicity, and potential use in multi-dimensional and complex problems. Unfortunately, its major drawback is its asymptotic behavior where the prior to posterior convergence in terms of the standard metrics (and also computed by Fréchet derivative) used as a local sensitivity measure is not appropriate. The constructed local sensitivity measures do not converge to zero, and even diverge for the most multidimensional classes of prior distributions. Restricting the classes of priors or using other (Formula presented.) -divergence metrics have been proposed as the ways to resolve this issue which were not successful. We overcome this issue, by proposing a new flexible class of metrics so-called credible metrics whose asymptotic behavior is far more promising and no restrictions are required to impose. Using these metrics, the stability of Bayesian inference to the structure of the prior distribution will be then investigated. Under appropriate condition, we present a uniform bound in a sense that a close credible metric a priori will give a close credible metric a posteriori. As a result, we do not get the sort of divergence based on other metrics. We finally show that the posterior predictive distributions are more stable and robust.",2023
87,Alireza Daneshkhah,Parameters influencing pedestrian injury and severity: A systematic review and meta-analysis,https://pureportal.coventry.ac.uk/en/publications/parameters-influencing-pedestrian-injury-and-severity-a-systemati,"Pedestrians account for 26% of all traffic fatalities worldwide. According to in-depth collision databases, around 3500 temporal variables can affect the outcome of a collision, making it crucial to establish the relationship between each variable and the outcome. To-date, there is no method defined to assess these temporal variables' relevance other than a statistical correlation, which can sometimes lead to reasonable conclusions, but only under specific circumstances. This article addresses this issue by first conducting a literature review to determine all relevant variables, followed by developing a variable selection criterion to select crucial variables, and then conducting a meta-analysis to combine statistical results. Epidemiological studies published between 1990 and 2022 were examined, including 93 papers from 19 different nations, considering 904,655 pedestrian collisions. Of the 204 variables that were extracted from these studies, 152 were examined using the variable selection criterion, and 68 were found to be significant. Of these, 31 were included in the meta-analysis, which combined odds ratio to aggregate the effect of a variable across various studies, thus removing study-specific conclusions. This study is innovative as it proves that statistical correlation alone is insufficient to determine the importance of a variable. The proposed method is an objective way to distinguish the variables for stakeholders and identify the relevant variables. This study provides for the first time the definitive list of the 68 variables that must be included in any pedestrian-to-vehicle accident databases, allowing appropriate actions for safer roads.",Mar 2023
88,Alireza Daneshkhah,Stakeholders’ impact on the reuse potential of structural elements at the end-of-life of a building: A machine learning approach,https://pureportal.coventry.ac.uk/en/publications/stakeholders-impact-on-the-reuse-potential-of-structural-elements,"The construction industry, and at its core the building sector, is the largest consumer of non-renewable resources, which produces the highest amount of waste and greenhouse gas emissions worldwide. Since most of the embodied energy and CO2 emissions during the construction and demolition phases of a building are related to its structure, measures to extend the service life of these components should be prioritised. This study develops a set of easy-to-understand instructions to facilitate the practitioners in assessing the social sustainability and responsibility of reusing the load-bearing structural components within the building sector. The results derived by developing and then employing advanced machine learning techniques indicate that the most significant social factor is the perception of the regulatory authorities. The second and third ranks among the social reusability factors belong to risks. Since there is a strong correlation between perception and risk, the potential risks associated with reusing structural elements affect the stakeholders’ perception of reuse. The Bayesian network developed in this study unveil the complex and non-linear correlation between variables, which means none of the factors could alone determine the reusability of an element. This paper shows that by using the basics of probability theory and combining them with advanced supervised machine learning techniques, it is possible to develop tools that reliably estimate the social reusability of these elements based on influencing variables. Therefore, the authors propose using the developed approach in this study to promote materials' circularity in different construction industry sub-sectors.",1 Jul 2023
89,Alireza Daneshkhah,Assessing Risks in Dairy Supply Chain Systems: A System Dynamics Approach,https://pureportal.coventry.ac.uk/en/publications/assessing-risks-in-dairy-supply-chain-systems-a-system-dynamics-a,"Due to the dynamic nature of the food supply chain system, food supply management could suffer because of, and be interrupted by, unforeseen events. Considering the perishable nature of fresh food products and their short life cycle, fresh food companies feel immense pressure to adopt an efficient and proactive risk management system. The risk management aspects within the food supply chains have been addressed in several studies. However, only a few studies focus on the complex interactions between the various types of risks impacting food supply chain functionality and dynamic feedback effects, which can generate a reliable risk management system. This paper strives to contribute to this evident research gap by adopting a system dynamics modelling approach to generate a systemic risk management model. The system dynamics model serves as the basis for the simulation of risk index values and can be explored in future work to further analyse the dynamic risk’s effect on the food supply chain system’s behaviour. According to a literature review of published research from 2017 to 2021, nine different risks across the food supply chain were identified as a subsection of the major risk categories: macro-level and operational risks. Following this stage, two of the risk groups identified first were integrated with a developed system dynamics model to conduct this research and to evaluate the interaction between the risks and the functionality of the three main dairy supply chain processes: production, logistics, and retailing. The key findings drawn from this paper can be beneficial for enhancing managerial discernment regarding the critical role of system dynamics models for analysing various types of risks across the food supply chain process and improving its efficiency.",4 Aug 2022
90,Alireza Daneshkhah,Comparing the Behaviour of Two Topic-Modelling Algorithms in COVID-19 Vaccination Tweets,https://pureportal.coventry.ac.uk/en/publications/comparing-the-behaviour-of-two-topic-modelling-algorithms-in-covi,"Coronavirus is a newly developed infectious disease that has triggered a pandemic due to its ease of transmission as of early 2020. Several groups from various countries have been working on a vaccine to prevent and avoid the spread of the virus in this outbreak. In this article, the main objective is to compare LDA against LSA to gain a better understanding of the Tweets and which Topic Modelling technique fits best for this task, additionally if the feedback of the Tweets were positive or negative sentiment. It was concluded that LDA was a better-unsupervised technique for categorizing the raw text in 12 topics.",Jan 2022
91,Alireza Daneshkhah,Detection of sleep apnea using Machine learning algorithms based on ECG Signals: A comprehensive systematic review,https://pureportal.coventry.ac.uk/en/publications/detection-of-sleep-apnea-using-machine-learning-algorithms-based-,"Sleep apnea (SA) is a common sleep disorder that is not easy to detect. Recent studies have highlighted ECG analysis as an effective method of diagnosing SA. Because the changes caused by SA on the ECG are imperceptible, the need for new methods in diagnosing this disease is required more than ever. Machine Learning (ML) is recognized as one of the most successful methods of computer aided diagnosis. ML uses new methods to diagnose diseases using past clinical results. The purpose of this study is to evaluate studies using ML algorithms based on ECG characteristics to assess people suffering from SA. In this study, systematically-reviewed articles written in English before October 2020 and indexed in PubMed, Scopus, Web of Science, and IEEE databases were searched with no lower time limit. From these articles, 48 were selected for further review. The selected articles adopteddifferent ML methods for classification. All of these studies were binary where SA was detected from the normal state based on a full ECG stripe (per record), or based on one-minute segments (per segment). Our analysis show that the most common features used in the studies were frequency, time series, and statistical features. Support-Vector Machine (SVM) and deep learning-based neural network (i.e. CNN, DNN) performed best in full record data detection. The highest accuracy, sensitivity, and specificity reported among the selected studies were 100%, which was obtained by an SVM. In another study, the classification was conducted based on ECG segments, and accordingly, the highest classification accuracy was observed in the residual neural network algorithm (RNN). The accuracy, sensitivity, and specificity of this algorithm were reported to be 99%. In general, it can be stated that ML techniques based on ECG characteristics have a high capability in diagnosing SA. These techniques can increase the diagnosis of patients with SA or the detection of SA episodes on ECG record, and can potentially prevent complications of the disease at later stages.",Jan 2022
92,Alireza Daneshkhah,Developing Graph Convolutional Networks and Mutual Information for Arrhythmic Diagnosis Based on Multichannel ECG Signals,https://pureportal.coventry.ac.uk/en/publications/developing-graph-convolutional-networks-and-mutual-information-fo,"Cardiovascular diseases, like arrhythmia, as the leading causes of death in the world, can be automatically diagnosed using an electrocardiogram (ECG). The ECG-based diagnostic has notably resulted in reducing human errors. The main aim of this study is to increase the accuracy of arrhythmia diagnosis and classify various types of arrhythmias in individuals (suffering from cardiovascular diseases) using a novel graph convolutional network (GCN) benefitting from mutual information (MI) indices extracted from the ECG leads. In this research, for the first time, the relationships of 12 ECG leads measured using MI as an adjacency matrix were illustrated by the developed GCN and included in the ECG-based diagnostic method. Cross-validation methods were applied to select both training and testing groups. The proposed methodology was validated in practice by applying it to the large ECG database, recently published by Chapman University. The GCN-MI structure with 15 layers was selected as the best model for the selected database, which illustrates a very high accuracy in classifying different types of rhythms. The classification indicators of sensitivity, precision, specificity, and accuracy for classifying heart rhythm type, using GCN-MI, were computed as 98.45%, 97.89%, 99.85%, and 99.71%, respectively. The results of the present study and its comparison with other studies showed that considering the MI index to measure the relationship between cardiac leads has led to the improvement of GCN performance for detecting and classifying the type of arrhythmias, in comparison to the existing methods. For example, the above classification indicators for the GCN with the identity adjacency matrix (or GCN-Id) were reported to be 68.24%, 72.83%, 95.24%, and 92.68%, respectively.",28 Aug 2022
93,Alireza Daneshkhah,Efficacy of COVID-19 vaccines by race and ethnicity,https://pureportal.coventry.ac.uk/en/publications/efficacy-of-covid-19-vaccines-by-race-and-ethnicity,"Objectives: Vaccine uptake amongst ethnic minority populations has been persistently lower, which may be because of socio-economic factors such as health literacy and health insurance status. This review aimed to assess to what extent COVID-19 clinical trials have considered the impact of race and ethnicity on COVID-19 vaccine safety and efficacy. Study design: This was a systematic review. Methods: Data regarding ethnicity in COVID-19 vaccine clinical trials were systematically reviewed according to Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines in this systematic review, which ran from inception until June 2021. Three international databases, PubMed, Scopus and Web of Science, were used to conduct systematic article searches. Only two studies reported vaccine efficacy among ethnic minority groups. Results: The efficacy of the mRNA-1273 vaccine was confirmed to be 95% in Caucasians and 97.5% in ‘people of colour’ in a study by Baden et al. In another study by Polack et al., BNT162b2 mRNA vaccine efficacy was reported to be 95.2% in Caucasians, 100% in Afro-Caribbean or African Americans, 94.2% in Hispanic or Latinx and 95.4% in non-Hispanic, non-Latinx people. Conclusions: Given the highly differing effect of COVID-19 on the Afro-Caribbean, Hispanic and South Asian populations, it is imperative for COVID-19 vaccine clinical trials to thoroughly assess the safety and efficacy of vaccines in different ethnicities and, if necessary, develop ethnicity-specific protocols, which can minimise the disproportionate effect of COVID-19 on ethnic minority populations.",5 May 2022
94,Alireza Daneshkhah,Examining Type 1 Diabetes Mathematical Models Using Experimental Data,https://pureportal.coventry.ac.uk/en/publications/examining-type-1-diabetes-mathematical-models-using-experimental-,"Type 1 diabetes requires treatment with insulin injections and monitoring glucose levels in affected individuals. We explored the utility of two mathematical models in predicting glucose concentration levels in type 1 diabetic mice and determined disease pathways. We adapted two mathematical models, one with β-cells and the other with no β-cell component to determine their ca-pability in predicting glucose concentration and determine type 1 diabetes pathways using published glucose concentration data for four groups of experimental mice. The groups of mice were numbered Mice Group 1–4, depending on the diabetes severity of each group, with severity increasing from group 1–4. A Markov Chain Monte Carlo method based on a Bayesian framework was used to fit the model to determine the best model structure. Akaike information criteria (AIC) and Bayesian information criteria (BIC) approaches were used to assess the best model structure for type 1 diabetes. In fitting the model with no β-cells to glucose level data, we varied insulin absorption rate and insulin clearance rate. However, the model with β-cells required more parameters to match the data and we fitted the β-cell glucose tolerance factor, whole body insulin clearance rate, glucose production rate, and glucose clearance rate. Fitting the models to the blood glucose concentration level gave the least difference in AIC of 1.2, and a difference in BIC of 0.12 for Mice Group 4. The estimated AIC and BIC values were highest for Mice Group 1 than all other mice groups. The models gave substantial differences in AIC and BIC values for Mice Groups 1–3 ranging from 2.10 to 4.05. Our results suggest that the model without β-cells provides a more suitable structure for modelling type 1 diabetes and predicting blood glucose concentration for hypoglycaemic episodes.",10 Jan 2022
95,Alireza Daneshkhah,Exploring dynamical properties of a Type 1 diabetes model using sensitivity approaches,https://pureportal.coventry.ac.uk/en/publications/exploring-dynamical-properties-of-a-type-1-diabetes-model-using-s,"The high global prevalence of diabetes, and the extortionate costs imposed on healthcare providers necessitate further research to understand different perspectives of the disease. In this paper, a mathematical model for Type 1 diabetes glucose homeostasis system was developed to better understand disease pathways. Type 1 diabetes pathological state is shown to be globally asymptomatically stable when the model threshold , and exchanges stability with the managed diabetes equilibrium state i.e. globally asymptotically stable when . Sensitivity analysis was conducted using partial rank correlation coefficient (PRCC) and Sobol method to determine influential model parameters. Sensitivity analysis was performed at different significant time points relevant to diabetes dynamics. Our sensitivity analysis was focused on the model parameters for glucose homeostasis system, at 3 to 4 hour time interval, when the system returns to homeostasis after food uptake. PRCC and Sobol method showed that insulin clearance and absorption rates were influential parameters in determining the model response variables at all time points at which sensitivity analysis was performed. PRCC method also showed the model subcutaneous bolus injection term to be important, thus identified all parameters in  as influential in determining diabetes model dynamics. Sobol method complemented the sensitivity analysis by identifying relationships between parameters. Sensitivity analysis methods concurred in identifying some of the influential parameters and demonstrated that parameters which are influential remain so at every time point. The concurrence of both PRCC and Sobol methods in identifying influential parameters (in ) and their dynamic relationships highlight the importance of statistical and mathematical analytic approaches in understanding the processes modelled by the parameters in the glucose homeostasis system.",Nov 2022
96,Alireza Daneshkhah,Gaussian Process Emulation of Spatio-temporal Outputs of a 2D Inland Flood Model,https://pureportal.coventry.ac.uk/en/publications/gaussian-process-emulation-of-spatio-temporal-outputs-of-a-2d-inl,"The computational limitations of complex numerical models have led to adoption of statistical emulators across a variety of problems in science and engineering disciplines to circumvent the high computational costs associated with numerical simulations. In flood modelling, many hydraulic and hydrodynamic numerical models, especially when operating at high spatiotemporal resolutions, have prohibitively high computational costs for tasks requiring the instantaneous generation of very large numbers of simulation results. This study examines the appropriateness and robustness of Gaussian Process (GP) models to emulate the results from a hydraulic inundation model. The developed GPs produce real-time predictions based on the simulation output from LISFLOOD-FP numerical model. An efficient dimensionality reduction scheme is developed to tackle the high dimensionality of the output space and is combined with the GPs to investigate the predictive performance of the proposed emulator for estimation of the inundation depth. The developed GP-based framework is capable of robust and straightforward quantification of the uncertainty associated with the predictions, without requiring additional model evaluations and simulations. Further, this study explores the computational advantages of using a GP-based emulator over alternative methodologies such as neural networks, by undertaking a comparative analysis. For the case study data presented in this paper, the GP model was found to accurately reproduce water depths and inundation extent by classification and produce computational speedups of approximately 10,000 times compared with the original simulator, and 80 times for a neural network-based emulator.",15 Oct 2022
97,Alireza Daneshkhah,Markov Chain Monte Carlo-Based Estimation of Stress–Strength Reliability Parameter for Generalized Linear Failure Rate Distributions,https://pureportal.coventry.ac.uk/en/publications/markov-chain-monte-carlo-based-estimation-of-stressstrength-relia,"This paper provides Bayesian and classical inference of Stress–Strength reliability parameter, [Formula: see text], where both [Formula: see text] and [Formula: see text] are independently distributed as 3-parameter generalized linear failure rate (GLFR) random variables with different parameters. Due to importance of stress–strength models in various fields of engineering, we here address the maximum likelihood estimator (MLE) of [Formula: see text] and the corresponding interval estimate using some efficient numerical methods. The Bayes estimates of R are derived, considering squared error loss functions. Because the Bayes estimates could not be expressed in closed forms, we employ a Markov Chain Monte Carlo procedure to calculate approximate Bayes estimates. To evaluate the performances of different estimators, extensive simulations are implemented and also real datasets are analyzed.",2022
98,Alireza Daneshkhah,On the impact of prior distributions on efficiency of sparse Gaussian process regression,https://pureportal.coventry.ac.uk/en/publications/on-the-impact-of-prior-distributions-on-efficiency-of-sparse-gaus,"Gaussian process regression (GPR) is a kernel-based learning model, which unfortunately suffers from computational intractability for irregular domain and large datasets due to the full kernel matrix. In this paper, we propose a novel method to produce a sparse kernel matrix using the compact support radial kernels (CSRKs) to efficiently learn the GPR from large datasets. The CSRKs can effectively avoid the ill-conditioned and full kernel matrix during GPR training and prediction, consequently reducing computational costs and memory requirements. In practice, the interest in CSRKs waned slightly as it became evident that, there is a trade-off principle (conflict between accuracy and sparsity) for compactly supported kernels. Hence, when using kernels with compact support, during GPR training, the main focus will be on providing a high level of accuracy. In this case, the advantage of achieving a sparse covariance matrix for CSRKs will almost disappear, as we will see in the numerical results. This trade-off has led authors to search for an “optimal” value of the scale parameter. Accordingly, by selecting the suitable priors on the kernel hyperparameters, and simply estimating the hyperparameters using a modified version of the maximum likelihood estimation (MLE), the GPR model derived from the CSRKs yields maximal accuracy while still maintaining a sparse covariance matrix. In fact, in GPR training, modified version of the MLE will be proportional to the product of MLE and a given suitable prior distribution for the hyperparameters that provides an efficient method for learning. The misspecification of prior distributions and their impact on the predictability of the sparse GPR models are also comprehensively investigated using several empirical studies. The proposed new approach is applied to some irregular domains with noisy test functions in 2D data sets in a comparative study. We finally investigate the effect of prior on the predictability of GPR models based on the real dataset. The derived results suggest the proposed method leads to more sparsity and well-conditioned kernel matrices in all cases.",26 Jun 2022
99,Alireza Daneshkhah,Predicting Primary Sequence-Based Protein-Protein Interactions Using a Mercer Series Representation of Nonlinear Support Vector Machine,https://pureportal.coventry.ac.uk/en/publications/predicting-primary-sequence-based-protein-protein-interactions-us,"The prediction of protein-protein interactions (PPIs) is essential to understand the cellular processes from a medical perspective. Among the various machine learning techniques, kernel-based Support Vector Machine (SVM) has been commonly employed to discriminate between interacting and non-interacting protein pairs. The main drawback of employing the kernel-based SVM to datasets with many features, such as the primary sequence-based protein-protein dataset, is the significant increase in computational time of training stage. This increase in computational time is mainly due to the presence of the kernel in solving the quadratic optimisation problem (QOP) involved in nonlinear SVM. In order to fix this issue, we propose a novel and efficient computational algorithm by approximating the kernel-based SVM using a low-rank truncated Mercer series as well as desired. As a result, the QOP for the approximated kernel-based SVM will be very tractable in the sense that there is a significant reduction in computational time of training and validating stages. We illustrate the novelty of the proposed method by predicting the PPIs of ""S. Cerevisiae” where the protein features extracted using the multiscale local descriptor (MLD), and then we compare the predictive performance of the proposed low-rank approximation with the existing methods. Finally, the new method results in significant reduction in computational time for predicting PPIs with almost as accuracy as kernel-based SVM",1 Dec 2022
100,Alireza Daneshkhah,Stable likelihood computation for machine learning of linear differential operators with Gaussian processes,https://pureportal.coventry.ac.uk/en/publications/stable-likelihood-computation-for-machine-learning-of-linear-diff,"In many applied sciences, the main aim is to learn the parameters in the operational equations which best fit the observed data. A framework for solving such problems is to employ Gaussian process (GP) emulators which are well-known as nonparametric Bayesian machine learning techniques. GPs are among a class of methods known as kernel machines which can be used to approximate rather complex problems by tuning their hyperparameters. The maximum likelihood estimation (MLE) has widely been used to estimate the parameters of the operators and kernels. However, the MLE-based and Bayesian inference in the standard form are usually involved in setting up a covariance matrix which is generally ill-conditioned. As a result, constructing and inverting the covariance matrix using the standard form will become unstable to learn the parameters in the operational equations. In this paper, we propose a novel approach to tackle these computational complexities and also resolve the ill-conditioning problem by forming the covariance matrix using alternative bases via the Hilbert−Schmidt SVD (HS-SVD) approach. Applying this approach yields a novel matrix factorization of the block-structured covariance matrix which can be implemented stably by isolating the main source of the ill-conditioning. In contrast to standard matrix decompositions which start with a matrix and produce the resulting factors, the HS-SVD is constructed from the Hilbert−Schmidt eigenvalues and eigenvectors without the need to ever form the potentially ill-conditioned matrix. We also provide stable MLE and Bayesian inference to adaptively estimate hyperparameters, and the corresponding operators can then be efficiently predicted at some new points using the proposed HS-SVD bases. The efficiency and stability of the proposed HS-SVD method will be compared with the existing methods by several illustrations of the parametric linear equations, such as ordinary and partial differential equations, and integro-differential and fractional order operators.",20 Apr 2022
101,Alireza Daneshkhah,The performance of various machine learning methods for Parkinson’s disease recognition: a systematic review,https://pureportal.coventry.ac.uk/en/publications/the-performance-of-various-machine-learning-methods-for-parkinson,"Parkinson’s disease (PD) is a common neurodegenerative disorder that causes degeneration of dopaminergic neurons in the Nigrostriatal pathway and the discharge of Dopamine in the striatum. Machine learning algorithms have been used as a tool to predict and diagnose diseases. Some of these algorithms got the popularity due to their high recognition performance. In the recognition of PD, studies demonstrated various recognition performances and this systematic review study the performance of machine learning algorithms. This systematic review is based on the cochrane’s proposed seven phases of review. After identifying the question of research and inclusion/exclusion criteria, we searched different related databases (SID, MagIran, PubMed, ProQuest, ScienceDirect, WoS, Scopus, and Google Scholar) with the help of combination of keywords. After selection of the studies we extract information and summarize the results. From 10,980 found-studies, and removing them based on inclusion/exclustion criteria, we selected 82 studies. To diagnose PD, 59 studies used clinical indicators, 2 studies used genetic characteristics, 12 used MRI, two used PET, 5 used SPECT and 2 used Laboratory markers. In most of these studies RF, SVM, LR have performed the best. The accuracies of RF, SVM, and LR are reported between 58.9%-99.42%, 65.2%-99.99%, and 43.9%-96%. The results show that the performance of RF, SVM, and LR are high for PD diagnosis. Therefore, they can be used for PD diagnosis as a help for doctors and specialist.",27 Feb 2022
102,Alireza Daneshkhah,A probabilistic predictive model for assessing the economic reusability of load-bearing building components: Developing a Circular Economy framework,https://pureportal.coventry.ac.uk/en/publications/a-probabilistic-predictive-model-for-assessing-the-economic-reusa,"The reuse of load-bearing building components has the potential to promote the circular economy in the building sector. One recent aspect of the efforts to improve reuse rates in buildings is estimating the reusability of the structural elements. This study develops a probabilistic predictive model using advanced supervised machine learning methods to evaluate the economic reusability of the load-bearing building elements. The results of sensitivity analysis and visualization techniques used in this study reveal that the most important economic factor is the need to purchase reused elements early in a project, which could have cash flow implications. The other most important factors are the potential financial risks, the procurement process, and the labour cost. This study unveils that the relationship between variables is not linear, and none of the identified factors could alone determine if an element is reusable or not. This study concludes that the complex interdependencies of factors affecting reuse cause a high level of uncertainty about the feasibility of reusing the load-bearing building structural components from an economic aspect. Nonetheless, this paper reveals that by using the probability theory foundations and combining it with advanced supervised machine learning methods, it is possible to develop tools that could reliably estimate the economic reusability of these elements based on affecting variables. Therefore, the authors suggest utilizing the approach developed in this research to promote the circularity of materials in different subsectors of the construction industry.",Jul 2021
103,Alireza Daneshkhah,A systematic review and meta-analysis of prevalence of insomnia in the third trimester of pregnancy,https://pureportal.coventry.ac.uk/en/publications/a-systematic-review-and-meta-analysis-of-prevalence-of-insomnia-i,"Background: Sleep disorders, which are among the foremost important medical care issues, are prevalent in pregnancy. The present study is a meta-analysis of the prevalence of insomnia in the third trimester of pregnancy. This study aims to systematically review the overall prevalence of insomnia in the third trimester of pregnancy through conducting a meta-analysis. Method: The literature used in this meta-analysis for the topic discussed above were obtained through searching several databases, including SID, MagIran, IranDoc, Scopus, Embase, Web of Science (WoS), PubMed Science Direct and Google Scholar databases without time limitation until December 2020. Articles developed based on cross-sectional studies were included in the study. The heterogeneity of studies was investigated using the I2 index. Also, the possible effects of heterogeneity in the studied studies are investigated using meta-regression analysis. Result: In 10 articles and 8798 participants aged between11–40, the overall prevalence of insomnia in the third trimester of pregnancy based on meta-analysis was 42.4% (95% CI: 32.9–52.5%). It was reported that as the sample size increases, the prevalence of insomnia in the third trimester of pregnancy increases. Conversely, as the year of research increases, the prevalence of insomnia in the third trimester of pregnancy decreases. Both of these differences were statistically significant (P < 0.05). Conclusion: Insomnia was highly prevalent in the last trimester of pregnancy. Sleep disorders are neglected among pregnant women, and they are considered natural. While sleep disturbances can cause mental and physical problems in pregnant women, they can consequently cause problems for the fetus. As a result, maintaining the physical and mental health of pregnant mothers is very important. It is thus recommended that in addition to having regular visits during pregnancy, pregnant women should also be continuously monitored for sleep-related disorders.",9 Apr 2021
104,Alireza Daneshkhah,Economic Evaluation of Mental Health Effects of Flooding Using Bayesian Networks,https://pureportal.coventry.ac.uk/en/publications/economic-evaluation-of-mental-health-effects-of-flooding-using-ba,"The appraisal of appropriate levels of investment for devising flooding mitigation and to support recovery interventions is a complex and challenging task. Evaluation must account for social, political, environmental and other conditions, such as flood state expectations and local priorities. The evaluation method should be able to quickly identify evolving investment needs as the incidence and magnitude of flood events continue to grow. Quantification is essential and must consider multiple direct and indirect effects on flood related outcomes. The method proposed is this study is a Bayesian network, which may be used ex-post for evaluation, but also ex-ante for future assessment, and near real-time for the reallocation of investment into interventions. The particular case we study is the effect of flood interventions upon mental health, which is a gap in current investment analyses. Natural events such as floods expose people to negative mental health disorders including anxiety, distress and post-traumatic stress disorder. Such outcomes can be mitigated or exacerbated not only by state funded interventions, but by individual and community skills and experience. Success is also dampened when vulnerable and previously exposed victims are affected. Current measures evaluate solely the effectiveness of interventions to reduce physical damage to people and assets. This paper contributes a design for a Bayesian network that exposes causal pathways and conditional probabilities between interventions and mental health outcomes as well as providing a tool that can readily indicate the level of investment needed in alternative interventions based on desired mental health outcomes.",13 Jul 2021
105,Alireza Daneshkhah,Generation of Pedestrian Crossing Scenarios Using Ped-Cross Generative Adversarial Network,https://pureportal.coventry.ac.uk/en/publications/generation-of-pedestrian-crossing-scenarios-using-ped-cross-gener,"The safety of vulnerable road users is of paramount importance as transport moves towards fully automated driving. The richness of real-world data required for testing autonomous vehicles is limited and furthermore, available data do not present a fair representation of different scenarios and rare events. Before deploying autonomous vehicles publicly, their abilities must reach a safety threshold, not least with regards to vulnerable road users, such as pedestrians. In this paper, we present a novel Generative Adversarial Networks named the Ped-Cross GAN. Ped-Cross GAN is able to generate crossing sequences of pedestrians in the form of human pose sequences. The Ped-Cross GAN is trained with the Pedestrian Scenario dataset. The novel Pedestrian Scenario dataset, derived from existing datasets, enables training on richer pedestrian scenarios. We demonstrate an example of its use through training and testing the Ped-Cross GAN. The results show that the Ped-Cross GAN is able to generate new crossing scenarios that are of the same distribution from those contained in the Pedestrian Scenario dataset. Having a method with these capabilities is important for the future of transport, as it will allow for the adequate testing of Connected and Autonomous Vehicles on how they correctly perceive the intention of pedestrians crossing the street, ultimately leading to fewer pedestrian casualties on our roads. ",6 Jan 2021
106,Alireza Daneshkhah,"Predicting mortality, duration of treatment, pulmonary embolism and required ceiling of ventilatory support for COVID-19 inpatients: A Machine-Learning Approach",https://pureportal.coventry.ac.uk/en/publications/predicting-mortality-duration-of-treatment-pulmonary-embolism-and,"Introduction Within the UK, COVID-19 has contributed towards over 103,000 deaths. Multiple risk factors for COVID-19 have been identified including various demographics, co-morbidities, biochemical parameters, and physical assessment findings. However, using this vast data to improve clinical care has proven challenging.
Aims to develop a reliable, multivariable predictive model for COVID-19 in-patient outcomes, to aid risk-stratification and earlier clinical decision-making.
Methods Anonymized data regarding 44 independent predictor variables of 355 adults diagnosed with COVID-19, at a UK hospital, was manually extracted from electronic patient records for retrospective, case-controlled analysis. Primary outcomes included inpatient mortality, level of ventilatory support and oxygen therapy required, and duration of inpatient treatment. Secondary pulmonary embolism was the only secondary outcome. After balancing data, key variables were feature selected for each outcome using random forests. Predictive models were created using Bayesian Networks, and cross-validated.

Results Our multivariable models were able to predict, using feature selected risk factors, the probability of inpatient mortality (F1 score 83.7%, PPV 82%, NPV 67.9%); level of ventilatory support required (F1 score varies from 55.8% “High-flow Oxygen level” to 71.5% “ITU-Admission level”); duration of inpatient treatment (varies from 46.7% for “≥ 2 days but < 3 days” to 69.8% “≤ 1 day”); and risk of pulmonary embolism sequelae (F1 score 85.8%, PPV of 83.7%, and NPV of 80.9%).
Conclusion Overall, our findings demonstrate reliable, multivariable predictive models for 4 outcomes, that utilize readily available clinical information for COVID-19 adult inpatients. Further research is required to externally validate our models and demonstrate their utility as clinical decision-making tools.",20 Feb 2021
107,Alireza Daneshkhah,Predicting the technical reusability of load-bearing building components: A probabilistic approach towards developing a Circular Economy framework,https://pureportal.coventry.ac.uk/en/publications/predicting-the-technical-reusability-of-load-bearing-building-com,"The construction sector is the largest consumer of raw materials and accounts for 25%–40% of the total CO2 emissions globally. Besides, construction activities produce the highest amount of waste among all other sectors. According to the waste hierarchies, reuse is preferred to recycling; however, most of the recovery of construction and demolition wastes happens in the form of recycling and not reuse. Part of the recent efforts to promote the reuse rates includes estimating the reusability of the load-bearing building components to assist the stakeholders in making sound judgements of the reuse potentials at the end-of-life of a building and alleviate the uncertainties and perceived risks. This study aims to develop a probabilistic model using advanced supervised machine learning techniques (including random forest, K-Nearest Neighbours algorithm, Gaussian process, and support vector machine) to predict the reuse potential of structural elements at the end-of-life of a building. For this purpose, using an online questionnaire, this paper seeks the experts’ opinions with actual reuse experience in the building sector to assess the identified barriers by the authors in an earlier study. Furthermore, the results of the survey are used to develop an easy-to-understand learner for assessing the technical reusability of the structural elements at the end-of-life of a building. The results indicate that the most significant factors affecting the reuse of building structural components are design-related including, matching the design of the new building with the strength of the recovered element.",1 Oct 2021
108,Alireza Daneshkhah,Scenario Optimisation and Sensitivity Analysis for Safe Automated Driving Using Gaussian Processes,https://pureportal.coventry.ac.uk/en/publications/scenario-optimisation-and-sensitivity-analysis-for-safe-automated,"Assuring the safety of automated vehicles is essential for their timely introduction and acceptance by policymakers and the public. To assess their safe design and robust decision making in response to all possible scenarios, new methods that use a scenario-based testing approach are needed, as testing on public roads in normal traffic would require driving millions of kilometres. We make use of the scenario-based testing approach and propose a method to model simulated scenarios using Gaussian Process based models to predict untested scenario outcomes. This enables us to efficiently determine the performance boundary, where the safe and unsafe scenarios can be evidently distinguished from each other. We present an iterative method that optimises the parameter space of a logical scenario towards the most critical scenarios on this performance boundary. Additionally, we conduct a novel probabilistic sensitivity analysis by efficiently computing several variance-based sensitivity indices using the Gaussian Process models and evaluate the relative importance of the scenario input parameters on the scenario outcome. We critically evaluate and investigate the usefulness of the proposed Gaussian Process based approach as a very efficient surrogate model, which can model the logical scenarios effectively in the presence of uncertainty. The proposed approach is applied on an exemplary logical scenario and shows viability in finding concrete critical scenarios. The reported results, derived from the proposed approach, could pave the way to more efficient testing of automated vehicles and instruct further physical tests on the determined critical scenarios.",15 Jan 2021
109,Alireza Daneshkhah,Topic modelling in precision medicine with its applications in personalized diabetes management,https://pureportal.coventry.ac.uk/en/publications/topic-modelling-in-precision-medicine-with-its-applications-in-pe,"Advances in Internet of Things (IoT) and analytic-based systems in the past decade have found several applications in medical informatics, and have significantly facilitated healthcare decision making. Patients' data are collected through a variety of means, including IoT sensory systems, and require efficient, and accurate processing. Topic Modelling is an unsupervised machine learning algorithm for Natural Language Processing (NLP) that identifies relationships and associations within textual data. The application of Topic Modelling has been widely used on raw text data, where meaningful clusters (topics) are generated by the model. The purpose of this paper is to explore the varying methods of Topic Modelling, mostly the Latent Dirichlet allocation (LDA) model, and its applicability on personalized diabetes management. The proposed study evaluates the possibility of applying topic modelling methods on diabetes literature and genomic data in order to achieve precision medicine.",18 Jul 2021
110,Alireza Daneshkhah,Using Machine Learning Algorithms to Develop a Clinical Decision-Making Tool for COVID-19 Inpatients,https://pureportal.coventry.ac.uk/en/publications/using-machine-learning-algorithms-to-develop-a-clinical-decision-,"Background: Within the UK, COVID-19 has contributed towards over 103,000 deaths. Although multiple risk factors for COVID-19 have been identified, using this data to improve clinical care has proven challenging. The main aim of this study is to develop a reliable, multivariable predictive model for COVID-19 in-patient outcomes, thus enabling risk-stratification and earlier clinical decision-making. Methods: Anonymised data consisting of 44 independent predictor variables from 355 adults diagnosed with COVID-19, at a UK hospital, was manually extracted from electronic patient records for retrospective, case–control analysis. Primary outcomes included inpatient mortality, required ventilatory support, and duration of inpatient treatment. Pulmonary embolism sequala was the only secondary outcome. After balancing data, key variables were feature selected for each outcome using random forests. Predictive models were then learned and constructed using Bayesian networks. Results: The proposed probabilistic models were able to predict, using feature selected risk factors, the probability of the mentioned outcomes. Overall, our findings demonstrate reliable, multivariable, quantitative predictive models for four outcomes, which utilise readily available clinical information for COVID-19 adult inpatients. Further research is required to externally validate our models and demonstrate their utility as risk stratification and clinical decision-making tools.",9 Jun 2021
111,Alireza Daneshkhah,A low cost and highly accurate technique for big data spatial-temporal interpolation,https://pureportal.coventry.ac.uk/en/publications/a-low-cost-and-highly-accurate-technique-for-big-data-spatial-tem,"The high velocity, variety and volume of data generation by today's systems have necessitated Big Data (BD) analytic techniques. This has penetrated a wide range of industries; BD as a notion has various types and characteristics, and therefore a variety of analytic techniques would be required. The traditional analysis methods are typically unable to analyse spatial-temporal BD. Interpolation is required to approximate the values between the already existing data points, yet since there exist both location and time dimensions, only a multivariate interpolation would be appropriate. Nevertheless, existing software are unable to perform such complex interpolations. To overcome this challenge, this paper presents a layer by layer interpolation approach for spatial-temporal BD. Developing this layered structure provides the opportunity for working with much smaller linear system of equations. Consequently, this structure increases the accuracy and stability of numerical structure of the considered BD interpolation. To construct this layer by layer interpolation, we have used the good properties of Radial Basis Functions (RBFs). The proposed new approach is applied to numerical examples in spatial-temporal big data and the obtained results confirm the high accuracy and low computational cost. Finally, our approach is applied to explore one of the air pollution indices, i.e. daily PM2.5 concentration, based on different stations in the contiguous United States, and it is evaluated by leave-one-out cross validation.",1 Jul 2020
112,Alireza Daneshkhah,Behavioural Analytics: A Preventative Means for the Future of Policing,https://pureportal.coventry.ac.uk/en/publications/behavioural-analytics-a-preventative-means-for-the-future-of-poli,"Without sufficient intelligence, police response to crimes occurs in the form a reactive retort. This is even more so in the case of cyberspace policing, as digital platforms increase the complexities involved in the overall police incident response development. In this paper, we briefly introduce cybercrime and the necessities that police forces have to deal with. We argue that there is an urgent need for development and adoption of proactive and preventive techniques to identify and curb cyber and cyber-enabled crimes. We then present topic modelling as one of effective preventive techniques for predicting behaviours that can potentially be linked to cybercrime activities on social media.",17 Jul 2020
113,Alireza Daneshkhah,Classification of a Pedestrian’s Behaviour Using Dual Deep Neural Networks,https://pureportal.coventry.ac.uk/en/publications/classification-of-a-pedestrians-behaviour-using-dual-deep-neural-,"Vulnerable road user safety is of paramount importance as transport moves towards fully autonomous driving. The research question posed by this research is of how can we train a computer to be able to see and perceive a pedestrian’s movement. This work presents a dual network architecture, trained in tandem, which is capable of classifying the behaviour of a pedestrian from a single image with no prior context. The results show that the most successful network was able to achieve a correct classification accuracy of 94.3% when classifying images based on their behaviour. This shows the use of a novel data fusion method for pedestrian images and human poses. Having a network with these capabilities is important for the future of transport, as it will allow vehicles to correctly perceive the intention of pedestrians crossing the street, and will ultimately lead to fewer pedestrian casualties on our roads.",4 Jul 2020
114,Alireza Daneshkhah,Constructing gene regulatory networks from microarray data using non-Gaussian pair-copula Bayesian networks,https://pureportal.coventry.ac.uk/en/publications/constructing-gene-regulatory-networks-from-microarray-data-using-,"Many biological and biomedical research areas such as drug design require analyzing the Gene Regulatory Networks (GRNs) to provide clear insight and understanding of the cellular processes in live cells. Under normality assumption for the genes, GRNs can be constructed by assessing the nonzero elements of the inverse covariance matrix. Nevertheless, such techniques are unable to deal with non-normality, multi-modality and heavy tailedness that are commonly seen in current massive genetic data. To relax this limitative constraint, one can apply copula function which is a multivariate cumulative distribution function with uniform marginal distribution. However, since the dependency structures of different pairs of genes in a multivariate problem are very different, the regular multivariate copula will not allow for the construction of an appropriate model. The solution to this problem is using Pair-Copula Constructions (PCCs) which are decompositions of a multivariate density into a cascade of bivariate copula, and therefore, assign different bivariate copula function for each local term. In fact, in this paper, we have constructed inverse covariance matrix based on the use of PCCs when the normality assumption can be moderately or severely violated for capturing a wide range of distributional features and complex dependency structure. To learn the non-Gaussian model for the considered GRN with non-Gaussian genomic data, we apply modified version of copula-based PC algorithm in which normality assumption of marginal densities is dropped. This paper also considers the Dynamic Time Warping (DTW) algorithm to determine the existence of a time delay relation between two genes. Breast cancer is one of the most common diseases in the world where GRN analysis of its subtypes is considerably important; Since by revealing the differences in the GRNs of these subtypes, new therapies and drugs can be found. The findings of our research are used to construct GRNs with high performance, for various subtypes of breast cancer rather than simply using previous models.",24 Jul 2020
115,Alireza Daneshkhah,Copula-based probabilistic assessment of intensity and duration of cold episodes: A case study of Malayer vineyard region,https://pureportal.coventry.ac.uk/en/publications/copula-based-probabilistic-assessment-of-intensity-and-duration-o,"Frost, particularly during the spring, is one of the most damaging weather phenomena for vineyards, causing significant economic losses to vineyards around the world each year. The risk of tardive frost damage in vineyards due to changing climate is considered as an important threat to the sustainable production of grapes. Therefore, the cold monitoring strategies is one of the criteria with significant impacts on the yields and prosperity of horticulture and raisin factories. Frost events can be characterized by duration and severity. This paper investigates the risk and impacts of frost phenomenon in the vineyards by modeling the joint distribution of duration and severity factors and analyzing the influential parameter’s dependency structure using capabilities of copula functions. A novel mathematical framework is developed within this study to understand the risk and uncertainties associate with frost events and the impacts on yields of vineyards by analyzing the non-linear dependency structure using copula functions as an efficient tool. The developed model was successfully validated for the case study of vineyard in Malayer city of Iran. The copula model developed in this study was shown to be a robust tool for predicting the return period of the frost events.",15 Dec 2020
116,Alireza Daneshkhah,Digital Twin Technologies and Smart Cities,https://pureportal.coventry.ac.uk/en/publications/digital-twin-technologies-and-smart-cities,"This book provides a holistic perspective on Digital Twin (DT) technologies, and presents cutting-edge research in the field. It assesses the opportunities that DT can offer for smart cities, and covers the requirements for ensuring secure, safe and sustainable smart cities. Further, the book demonstrates that DT and its benefits with regard to:  data visualisation, real-time data analytics, and learning leading to improved confidence in decision making; reasoning, monitoring and warning to support accurate diagnostics and prognostics; acting using edge control and what-ifanalysis; and connection with back-end business applications  hold significant potential for applications in smart cities, by employing a wide range of sensory and data-acquisition systems in various parts of the urban infrastructure. The contributing authors reveal how and why DT technologies that are used for monitoring, visualising, diagnosing and predicting in real-time are vital to cities’ sustainability and efficiency. The concepts outlined in the book represents a city together with all of its infrastructure elements, which communicate with each other in a complex manner. Moreover, securing Internet of Things (IoT) which is one of the key enablers of DT’s is discussed in details and from various perspectives. The book offers an outstanding reference guide for practitioners and researchers in manufacturing, operations research and communications, who are considering digitising some of their assets and related services. It is also a valuable asset for graduate students and academics who are looking to identify research gaps and develop their own proposals for further research.",2020
117,Alireza Daneshkhah,Generation of pedestrian pose structures using generative adversarial networks,https://pureportal.coventry.ac.uk/en/publications/generation-of-pedestrian-pose-structures-using-generative-adversa,"The safety of vulnerable road users is of paramount importance as transport moves towards fully automated driving. The richness of real-world data required for testing autonomous vehicles is limited, and furthermore, the available data does not have a fair representation of different scenarios and rare events. This work presents a novel approach for the generation of human pose structures, specifically the type of pose structures that would appear to be in pedestrian scenarios. The results show that the generated pedestrian structures are indistinguishable from the ground truth pose structures when classified using a suitably trained classifier. The paper demonstrates that the Generative Adversarial Network architecture can be used to create realistic new training samples, and, in future, new pedestrian events.",17 Feb 2020
118,Alireza Daneshkhah,On the functional central limit theorem for first passage time of nonlinear semi-Markov reward processes,https://pureportal.coventry.ac.uk/en/publications/on-the-functional-central-limit-theorem-for-first-passage-time-of,"In this article we examine the functional central limit theorem for the first passage time of reward processes defined over a finite state space semi-Markov process. In order to apply this process for a wider range of real-world applications, the reward functions, considered in this work, are assumed to have general forms instead of the constant rates reported in the other studies. We benefit from the martingale theory and Poisson equations to prove and establish the convergence of the first passage time of reward processes to a zero mean Brownian motion. Necessary conditions to derive the results presented in this article are the existence of variances for sojourn times in each state and second order integrability of reward functions with respect to the distribution of sojourn times. We finally verify the presented methodology through a numerical illustration.",1 Oct 2020
119,Alireza Daneshkhah,Some Computational Considerations for Kernel-Based Support Vector Machine,https://pureportal.coventry.ac.uk/en/publications/some-computational-considerations-for-kernel-based-support-vector,"Sometimes healthcare perspectives in communications technologies require data mining, especially classification as a supervised learning. Support vector machines (SVMs) are considered as efficient supervised learning approaches for classification due to their robustness against several types of model misspecifications and outliers. Kernel-based SVMs are known to be more flexible tools for a wide range of supervised learning tasks and can efficiently handle non-linear relationship between input variables and outputs (or labels). They are more robust with respect to the aforementioned model misspecifications, and also more accurate in the sense that the root-mean-square error computed by fitting the kernel-based SVMs is considerably smaller than the one computed by fitting the standard/linear SVMs. However, the choice of kernel type and particularity kernel’s parameters could have significant impact on the classification accuracy and other supervised learning tasks required in network security, Internet of things, cybersecurity, etc. One of the findings of this study is that larger kernel parameter(s) would encourage SVMs with more localities and vice versa. This chapter provides some results on the effect of the kernel parameter on the kernel-based SVM classification. We thus first examine the effect of these parameters on the classification results using the kernel-based SVM, and then specify the optimal value of these parameters using cross-validation (CV) technique.",2020
120,Alireza Daneshkhah,The impact of physical exercise on the fatigue symptoms in patients with multiple sclerosis: A systematic review and meta-analysis,https://pureportal.coventry.ac.uk/en/publications/the-impact-of-physical-exercise-on-the-fatigue-symptoms-in-patien,"Background: Despite many benefits of the physical activity on physical and mental health of patients with Multiple Sclerosis (MS), the activity level in these patients is still very limited, and they continue to suffer from impairment in functioning ability. The main aim of this study is thus to closely examine exercise's effect on fatigue of patients with MS worldwide, with particular interest on Iran based on a comprehensive systematic review and meta-analysis. Methods: The studies used in this systematic review were selected from the articles published from 1996 to 2019, in national and international databases including SID, Magiran, Iranmedex, Irandoc, Google Scholar, Cochrane, Embase, ScienceDirect, Scopus, PubMed and Web of Science (ISI). These databases were thoroughly searched, and the relevant ones were selected based on some plausible keywords to the aim of this study. Heterogeneity index between studies was determined using Cochran's test and I2. Due to heterogeneity in studies, the random effects model was used to estimate standardized mean difference. Results: From the systematic review, a meta-analysis was performed on 31 articles which were fulfilled the inclusion criteria. The sample including of 714 subjects was selected from the intervention group, and almost the same sample size of 720 individuals were selected in the control group. Based on the results derived from this meta-analysis, the standardized mean difference between the intervention group before and after the intervention was respectively estimated to be 23.8 ± 6.2 and 16.9 ± 3.2, which indicates that the physical exercise reduces fatigue in patients with MS. Conclusion: The results of this study extracted from a detailed meta-analysis reveal and confirm that physical exercise significantly reduces fatigue in patients with MS. As a results, a regular exercise program is strongly recommended to be part of a rehabilitation program for these patients.",13 Mar 2020
121,Alireza Daneshkhah,The prevalence of Restless Legs Syndrome/Willis-ekbom disease (RLS/WED) in the third trimester of pregnancy: a systematic review,https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-restless-legs-syndromewillis-ekbom-disease-rlsw,"BACKGROUND: RLS is known as one of the most common movement disorders during pregnancy, which is most aggravated in the third trimester of pregnancy and can affect up to one-third of pregnant women. This study intends to determine the total prevalence of RLS in the third trimester of pregnancy through a systematic review.METHODS: The present study was conducted via meta-analysis method up to 2019. The papers related to the subject of interest were obtained through searching in SID, MagIran, IranDoc, Scopus, Embase, Web of Science (ISI), PubMed, Science Direct, and Google Scholar databases. Heterogeneity of the studies was examined via I2 index, and the data were analyzed in Comprehensive meta-analysis software.RESULTS: In investigating 10 papers capturing 2431 subjects within the age range of 25-39 years, the total prevalence of RLS in the third trimester of pregnancy based on meta-analysis was obtained as 22.9% (95% CI: 14.7-33.8%). Further, as the sample size increased, the RLS prevalence diminished, while with increase in years, this prevalence increased, where this difference was statistically significant (P < 0.05).CONCLUSION: Prevalence of RLS in the third trimester of pregnancy is high, healthcare policymakers should organize educational classes to improve the life dimensions among this group of pregnant women.",13 Apr 2020
122,Alireza Daneshkhah,The prevalence of severe depression in Iranian older adult: a meta-analysis and meta-regression,https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-severe-depression-in-iranian-older-adult-a-meta,"Background: Depression is one of the most common psychiatric disorders in the older adult and one of the most common risk factors for suicide in the older adult. Studies show different and inconsistent prevalence rates in Iran. This study aims to determine the prevalence of severe depression in Iranian older adult through a meta-analysis approach. Methods: The present meta-analysis was conducted between January 2000-August 2019. Articles related to the subject matter were obtained by searching Scopus, Sciencedirect, SID, magiran, Barakat Knowledge Network System, Medline (PubMed), and Google Scholar databases. The heterogeneity of the studies was evaluated using I
              2 index and the data were analyzed in Comprehensive Meta-Analysis software. Results: In a study of 3948 individuals aged 50-90 years, the overall prevalence of severe depression in Iranian older adult was 8.2% (95% CI, 4.14-6.3%) based on meta-analysis. Also, in order to investigate the effects of potential factors (sample size and year of study) on the heterogeneity of severe depression in Iranian older adult, meta-regression was used. It was reported that the prevalence of severe depression in Iranian older adult decreased with increasing sample size and increasing years of the study, which is significantly different (P < 0.05). Conclusion: Considering the high prevalence of severe depression in Iranian older adult, it is necessary for health policy makers to take effective control measures and periodic care for the older adult.
            ",3 Feb 2020
123,Alireza Daneshkhah,The prevalence of sleep disturbances among physicians and nurses facing the COVID-19 patients: a systematic review and meta-analysis,https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-sleep-disturbances-among-physicians-and-nurses-,"Background: In all epidemics, healthcare staff are at the centre of risks and damages caused by pathogens. Today, nurses and physicians are faced with unprecedented work pressures in the face of the COVID-19 pandemic, resulting in several psychological disorders such as stress, anxiety and sleep disturbances. The aim of this study is to investigate the prevalence of sleep disturbances in hospital nurses and physicians facing the COVID-19 patients. Method: A systematic review and metanalysis was conducted in accordance with the PRISMA criteria. The PubMed, Scopus, Science direct, Web of science, CINHAL, Medline, and Google Scholar databases were searched with no lower time-limt and until 24 June 2020. The heterogeneity of the studies was measured using I2 test and the publication bias was assessed by the Egger's test at the significance level of 0.05. Results: The I2 test was used to evaluate the heterogeneity of the selected studies, based on the results of I2 test, the prevalence of sleep disturbances in nurses and physicians is I2: 97.4% and I2: 97.3% respectively. After following the systematic review processes, 7 cross-sectional studies were selected for meta-analysis. Six studies with the sample size of 3745 nurses were examined in and the prevalence of sleep disturbances was approximated to be 34.8% (95% CI: 24.8-46.4%). The prevalence of sleep disturbances in physicians was also measured in 5 studies with the sample size of 2123 physicians. According to the results, the prevalence of sleep disturbances in physicians caring for the COVID-19 patients was reported to be 41.6% (95% CI: 27.7-57%). Conclusion: Healthcare workers, as the front line of the fight against COVID-19, are more vulnerable to the harmful effects of this disease than other groups in society. Increasing workplace stress increases sleep disturbances in the medical staff, especially nurses and physicians. In other words, increased stress due to the exposure to COVID-19 increases the prevalence of sleep disturbances in nurses and physicians. Therefore, it is important for health policymakers to provide solutions and interventions to reduce the workplace stress and pressures on medical staff.",29 Sept 2020
124,Alireza Daneshkhah,"The prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients: a systematic review and meta-regression",https://pureportal.coventry.ac.uk/en/publications/the-prevalence-of-stress-anxiety-and-depression-within-front-line,"Background Stress, anxiety, and depression are some of the most important research and practice challenges for psychologists, psychiatrists, and behavioral scientists. Due to the importance of issue and the lack of general statistics on these disorders among the Hospital staff treating the COVID-19 patients, this study aims to systematically review and determine the prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients.Methods In this research work, the systematic review, meta-analysis and meta-regression approaches are used to approximate the prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients. The keywords of prevalence, anxiety, stress, depression, psychopathy, mental illness, mental disorder, doctor, physician, nurse, hospital staff, 2019-nCoV, COVID-19, SARS-CoV-2 and Coronaviruses were used for searching the SID, MagIran, IranMedex, IranDoc, ScienceDirect, Embase, Scopus, PubMed, Web of Science (ISI) and Google Scholar databases. The search process was conducted in December 2019 to June 2020. In order to amalgamate and analyze the reported results within the collected studies, the random effects model is used. The heterogeneity of the studies is assessed using the I2 index. Lastly, the data analysis is performed within the Comprehensive Meta-Analysis software.Results Of the 29 studies with a total sample size of 22,380, 21 papers have reported the prevalence of depression, 23 have reported the prevalence of anxiety, and 9 studies have reported the prevalence of stress. The prevalence of depression is 24.3% (18% CI 18.2–31.6%), the prevalence of anxiety is 25.8% (95% CI 20.5–31.9%), and the prevalence of stress is 45% (95% CI 24.3–67.5%) among the hospitals’ Hospital staff caring for the COVID-19 patients. According to the results of meta-regression analysis, with increasing the sample size, the prevalence of depression and anxiety decreased, and this was statistically significant (P < 0.05), however, the prevalence of stress increased with increasing the sample size, yet this was not statistically significant (P = 0.829).Conclusion The results of this study clearly demonstrate that the prevalence of stress, anxiety and depression within front-line healthcare workers caring for COVID-19 patients is high. Therefore, the health policy-makers should take measures to control and prevent mental disorders in the Hospital staff.",17 Dec 2020
125,Alireza Daneshkhah,Mass transpiration in magneto-hydrodynamic boundary layer flow over a superlinear stretching sheet embedded in porous medium with slip,https://pureportal.coventry.ac.uk/en/publications/mass-transpiration-in-magneto-hydrodynamic-boundary-layer-flow-ov,"We have studied mass transpiration of a magneto-hydrodynamic (MHD) flow of a Newtonian fluid over a superlinear stretching sheet embedded in a porous medium. A model was created of a nonlinear system of partial differential equations that are transformed into third-order nonlinear ordinary differential equations via similarity transformations and then solved analytically using differential transform method and Pade approximants. The main focus of the present study is on the effect of Navier’s slip boundary condition on flow behavior. A comprehensive study is presented on the effects of various parameters, such as Navier’s slip condition, mass transpiration (suction/injection), and Darcy number on the axial and transverse velocity profiles of the laminar boundary layer flow through the stretching sheet.",1 Jan 2019
126,Alireza Daneshkhah,Optimizing minimum information pair-copula using genetic algorithm to select optimal basis functions,https://pureportal.coventry.ac.uk/en/publications/optimizing-minimum-information-pair-copula-using-genetic-algorith,"Constructing pair-copula using the minimum information approach is an appropriate and flexible way to survey the dependency structure between variables of interest. Minimum information pair-copula method approximates multivariate copula by applying some constraints between desired variables that are elicited from the data itself or experts’ judgment. In minimum information pair-copula, selecting basis constraints is a challenge. In this article, we apply genetic algorithms as a heuristic way to select basis constraints to optimize approximated pair-copula. The results gained show that our method optimizes model selection criteria and lead to better pair-copula approximation. Finally, we apply our proposed method to approximate pair-copula density in real dataset.",7 Feb 2019
127,Alireza Daneshkhah,Performance Boundary Identification for the Evaluation of Automated Vehicles using Gaussian Process Classification,https://pureportal.coventry.ac.uk/en/publications/performance-boundary-identification-for-the-evaluation-of-automat,"Safety is an essential aspect in the facilitation of automated vehicle deployment. Current testing practices are not enough, and going beyond them leads to infeasible testing requirements, such as needing to drive billions of kilometres on public roads. Automated vehicles are exposed to an indefinite number of scenarios. Handling of the most challenging scenarios should be tested, which leads to the question of how such corner cases can be determined. We propose an approach to identify the performance boundary, where these corner cases are located, using Gaussian Process Classification. We also demonstrate the classification on an exemplary traffic jam approach scenario, showing that it is feasible and would lead to more efficient testing practices.",2019
128,Alireza Daneshkhah,Approximating non-Gaussian Bayesian networks using minimum information vine model with applications in financial modelling,https://pureportal.coventry.ac.uk/en/publications/approximating-non-gaussian-bayesian-networks-using-minimum-inform,"Many financial modeling applications require to jointly model multiple uncertain quantities to present more accurate, near future probabilistic predictions. Informed decision making would certainly benefit from such predictions. Bayesian networks (BNs) and copulas are widely used for modeling numerous uncertain scenarios. Copulas, in particular, have attracted more interest due to their nice property of approximating the probability distribution of the data with heavy tail. Heavy tail data is frequently observed in financial applications. The standard multivariate copula suffer from serious limitations which made them unsuitable for modeling the financial data. An alternative copula model called the pair-copula construction (PCC) model is more flexible and efficient for modeling the complex dependence of financial data. The only restriction of PCC model is the challenge of selecting the best model structure. This issue can be tackled by capturing conditional independence using the Bayesian network PCC (BN-PCC). The flexible structure of this model can be derived from conditional independences statements learned from data. Additionally, the difficulty of computing conditional distributions in graphical models for non-Gaussian distributions can be eased using pair-copulas. In this paper, we extend this approach further using the minimum information vine model which results in a more flexible and efficient approach in understanding the complex dependence between multiple variables with heavy tail dependence and asymmetric features which appear widely in the financial applications.",Jan 2018
129,Alireza Daneshkhah,"Crime Data Mining, Threat Analysis and Prediction",https://pureportal.coventry.ac.uk/en/publications/crime-data-mining-threat-analysis-and-prediction,"Cybercriminology as a subject area has numerous dimensions. Some studies in the field primarily focus on a corrective action to reduce the impact of an already committed crime. However, there are existing computational techniques which can assist in predicting and therefore preventing cyber-crimes. These quantitative techniques are capable of providing valuable holistic and strategic insights for law enforcement units and police forces to prevent the crimes from happening. Moreover, these techniques can be used to analyse crime patterns to provide a better understanding of the world of cyber-criminals. The main beneficiaries of such research works, are not only the law enforcement units, as in the era of Internet-connectivity, many business would also benefit from cyber attacks and crimes being committed in the cyber environment. This chapter provides an all-embracing overview of machine learning techniques for crime analysis followed by a detailed critical discussion of data mining and predictive analysis techniques within the context of cybercriminology.",2018
130,Alireza Daneshkhah,Discrete Weighted Exponential Distribution of the Second Type: Properties and Applications,https://pureportal.coventry.ac.uk/en/publications/discrete-weighted-exponential-distribution-of-the-second-type-pro,"In this paper, we propose a new lifetime model as a discrete version of the continuous weighted exponential distribution which is called discrete weighted exponential distribution (DWED). This model is a generalization of the discrete exponential distribution which is originally introduced by Chakraborty (2015). We present various statistical indices/properties of this distribution including reliability indices, moment generating function, probability generating function, survival and hazard rate functions, index of dispersion, and stress-strength parameter. We rst present a numerical method to compute the maximum likelihood estima-tions (MLEs) of the models parameters, and then conduct a simulation study to further analyze these estimations. The advantages of the DWED are shown in practice by applying it on two real world applications and compare it with some other well-known lifetime distributions.",2018
131,Alireza Daneshkhah,Early feeding and growth pattern in infants: Using a three-variate longitudinal model derived from Gaussian copula function,https://pureportal.coventry.ac.uk/en/publications/early-feeding-and-growth-pattern-in-infants-using-a-three-variate,"Background: The Gaussian copula model was used to generate joint distributions for continuous longitudinal variables on infant types of feeding and longitudinal measures of height, weight and head circumferenceMethods: The study was performed longitudinally in rural areas of southern part of Iran, on children from birth to 9 months of age. Out of 319 infants with serial anthropometric measurements from birth, and 2, 4, 6, 7 and 9 monthsold, 120 were included. Infants were divided into three groups (breast fed, formula fed and both milk types). A threevariate longitudinal model including Copula function was used to estimate the effect of feeding on growth pattern. Allthe analyses were performed using SAS version 9.4 (Proc NLmix).Results: Ninety infants (75%) were breastfed, sixteen (13.3%) were formula fed and fourteen (11.7%) had combined feeding. Copula model showed that, breast fed children had a better weight gain (β=0.627 95% CI 0.217-1.038 P = 0.003), height (β=2.603 95% CI 1.023-4.183 P = 0.001) and head circumference (β=0.8 95% CI 0.069-1.531 P = 0.0) as compared to formula fed children. R2 for Copula model was (wt=0.52, ht=0.96, hc=0.84).Conclusions: Implication of Copula model was easy to perform. Estimation of the parameters in copula model indicated that, breast milk consumption had a positive effect on the growth of infants.",2018
132,Alireza Daneshkhah,Probabilistic Modeling of Financial Uncertainties,https://pureportal.coventry.ac.uk/en/publications/probabilistic-modeling-of-financial-uncertainties,"Since the global financial crash, one of the main trends in the financial engineering discipline has been to enhance the efficiency and flexibility of financial probabilistic risk assessments. Creditors could immensely benefit from such improvements in analysis hoping to minimise potential monetary losses. Analysis of real world financial scenarios require modeling of multiple uncertain quantities with a view to present more accurate, near future probabilistic predictions. Such predictions are essential for an informed decision making. In this article, the authors extend Bayesian Networks Pair-Copula Construction (BN-PCC) further using the minimum information vine model which results in a more flexible and efficient approach in modeling multivariate dependencies of heavy-tailed distribution and tail dependence as observed in the financial data. The authors demonstrate that the extended model based on minimum information Pair-Copula Construction (PCC) can approximate any non-Gaussian BN to any degree of approximation. The proposed method has been applied to the portfolio data derived from a Brazilian case study. The results show that the fitting of the multivariate distribution approximated using the proposed model has been improved compared to other previously published approaches.",2018
133,Ian Dunwell,Efficacy of the 4F Feedback Model: A Game-Based Assessment in University Education,https://pureportal.coventry.ac.uk/en/publications/efficacy-of-the-4f-feedback-model-a-game-based-assessment-in-univ,"Feedback is a critical aspect of optimised learning design, but there are few, if any, feedback models that map different types of feedback and how they may assist students to increase performance and enhance their learning experience. This research paper outlines a feedback model as an extension of the four-dimensional framework which includes a consideration of the type, the content, the format, and the frequency of feedback, as well as the agent which delivers it. This model is based upon an understanding of learning in the context of designing learning experiences and utilises a game-based model of learning to understand the importance of motivation and autonomy in learners to enhance and accelerate learning. The framework is developed and reflected upon by analysing two cases: a medical triage case in which the timing and frequency of feedback proved critical, and a business simulation which illuminated the need for a range of types of feedback and to be aware of the possibility of different agents (instructor peer and game) that can deliver feedback. The extended model may help game and learning designers alike to discern different types of feedback, both in games and more generally, in more explicit and nuanced ways.",6 Feb 2023
134,Ian Dunwell,Science teachers’ experiences of inquiry-based learning through a serious game: a phenomenographic perspective,https://pureportal.coventry.ac.uk/en/publications/science-teachers-experiences-of-inquiry-based-learning-through-a-,"This study employed a phenomenographic approach to investigate science teachers’ conceptions of inquiry-based learning through a serious game. Simaula is a prototype game designed and used as a virtual practicum for eliciting understandings on how in-game inquiry was appeared to, or experienced by, the participating teachers. Group interviews with 20 secondary education science teachers revealed four qualitatively different ways of experiencing inquiry-based learning through Simaula: (a) as uncovering insights about student’s learning needs, interests and emotions; (b) as generating ideas and concepts for meaningful inquiry; (c) as a set of operations for designing and carrying out scientific research; and (d) as authentic inquiry for enabling knowledge building processes. Seven dimensions of variation have been identified viewed as contextual influences on conceptions of in-game inquiry constituting discernment of: epistemic inquiry-based learning modes; role of teacher; role of student; game-play focus; core mechanics focus; feedback and progress mechanics and game uncertainty. The results illuminated a partial in-game inquiry approach with distinct epistemic modes from developing empathy and meaning making to knowledge construction and knowledge building. The findings also indicated that game design elements played central role in shaping conceptions of in-game inquiry from focusing on rules and logic as means to completing the game’s level to understanding the complexity of core mechanics for developing and transferring in-game inquiry to the real classroom. This insinuates that distinct game design properties may be considered in terms of extending intrinsic in-game inquiry experiences to actual in-class inquiry practice.",12 May 2021
135,Ian Dunwell,The EN-Survival Game: An Environmental Game for Residential Accommodation,https://pureportal.coventry.ac.uk/en/publications/the-en-survival-game-an-environmental-game-for-residential-accomm,"The significance of using games for educational purposes is well documented in the literature. It has been argued that serious games can draw more engagement and user attention to topics when compared to conventional web or print media, including concepts around energy education. The Smarter Household project has deployed an energy indoor health monitoring system in 19 UK social housing units, utilizing internet technologies to connect the end-user through tablet devices to multiple interventions (dashboard visualization, application of gamification and serious game). The serious game aimed to help residents understand their energy consumption while stimulating energy-efficient behaviors toward managing indoor conditions via in-game decisions. This chapter presents our preliminary findings relating to the serious game as an intervention across the 19 households. The game demonstrates potential value to trial participants in terms of how to apply the lessons learned from the in-game scenarios to their everyday activities.",8 May 2021
136,Ian Dunwell,A Game for Entrepreneurship Training Supporting Dual-Career Paths,https://pureportal.coventry.ac.uk/en/publications/a-game-for-entrepreneurship-training-supporting-dual-career-paths,"This paper presents the early-stage user workshop findings and subsequent design of a game-based learning approach to entrepreneurship. The specific context is to address the dual-career training needs of athletes, as part of a large-scale European online course (MOOC). An interactive card-based activity was used within a small scale focus group, with the purpose of enabling dialogue between end-users (n = 11), as to elicit their experiences of using games for understanding athletes’ dual career training needs. Initial findings from this exercise was a suggestion that quantifiable performance indicators (scores, points, achievements) could be preferable to less quantifiable measures (e.g. narrative progression, or multiple scenario outcomes). Establishing meaning, sense-of-purpose, and identity within the game were also highlighted as desirable features by the focus group, when compared to other options as detailed in this paper. The subsequent prototype of the game is presented, with reference to these findings.",1 Jan 2020
137,Ian Dunwell,Board Games for Health: A Systematic Literature Review and Meta-Analysis,https://pureportal.coventry.ac.uk/en/publications/board-games-for-health-a-systematic-literature-review-and-meta-an,"Nondigital board games are being used to engage players and impact outcomes in health and medicine across diverse populations and contexts. This systematic review and meta-analysis describes and summarizes their impact based on randomized and nonrandomized controlled trials. An electronic search resulted in a review of n = 21 eligible studies. Sample sizes ranged from n = 17 to n = 3110 (n = 6554 total participants). A majority of the board game interventions focused on education to increase health-related knowledge and behaviors (76%, n = 16). Outcomes evaluated included self-efficacy, attitudes/beliefs, biological health indicators, social functioning, anxiety, and executive functioning, in addition to knowledge and behaviors. Using the Cochrane Collaboration tool for assessing bias, most studies (52%, n = 11) had an unclear risk of bias (33% [n = 7] had a high risk and 14% [n = 3] had a low risk). Statistical tests of publication bias were not significant. A random-effects meta-analysis showed a large average effect of board games on health-related knowledge (d* = 0.82, 95% confidence interval; CI [0.15–1.48]), a small-to-moderate effect on behaviors (d* = 0.33, 95% CI [0.16–0.51]), and a small-to-moderate effect on biological health indicators (d* = 0.37, 95% CI [0.21–0.52]). The findings contribute to the literature on games and gamified approaches in healthcare. Future research efforts should aim for more consistent high scientific standards in their evaluation protocols and reporting methodologies to provide a stronger evidence base.",8 Apr 2019
138,Ian Dunwell,Reinforcing rational decision making in a risk elicitation task through visual reasoning,https://pureportal.coventry.ac.uk/en/publications/reinforcing-rational-decision-making-in-a-risk-elicitation-task-t,"Metrics seeking to predict financial risk-taking behaviors typicallyexhibit limited validity. This is due to the fluid nature of anindividual’s risk taking, and the influence of the mode andmedium, which presents a decision. This paper presents twoexperiments that investigate how an existing risk elicitation task’spredictive capacity may be enhanced through the application of aninteractive model of visual reasoning in a digitized version. In thefirst experiment, 60 participants demonstrated their reasoningprocess. In the second experiment, 225 participants were randomlyassigned into three groups, with the validated risk elicitation taskcompared as a control to interactive digital and non-interactivedigital stimuli with pie charts. The experiments yielded significantresults, highlighting that when participants interact with a graph toreason their choices, it leads to consistent choices. The findingshave implications for improvement of the risk task's validity andthe deployment of digital interactive assessments beyondlaboratory settings.",2019
139,Ian Dunwell,Implementing Adaptive Game Difficulty Balancing in Serious Games,https://pureportal.coventry.ac.uk/en/publications/implementing-adaptive-game-difficulty-balancing-in-serious-games,"The ability to engage and retain players is perceived as a major factor in the success of games. However, the end-goal of retention differs between entertainment and serious contexts. For an entertainment game, engagement and retention is linked to monetization; for a serious game, this needs to persist for as long as is required for learning or behavioural objectives to be met. User engagement is strongest when a balance is achieved between difficulty and skill, leading to a state of “flow”. Hence adapting difficulty could lead to increased and sustained engagement. Implementing this requires the identification of variables linked to mechanics, manipulated based upon a player performance model. In some cases, this is possible by adjusting simple properties of objects, though more comprehensive solutions require extending or adapting content applying procedural techniques. This paper proposes a six step plan, validated against two case studies: an existing serious game, with easily-manipulated parameters, and a platformer game built from scratch, where additional content is required, showing the process for different mechanics. To explore limitations, the results of two small-scale user evaluations with 45 users in total, are reported, contributing to the understanding of how adaptive difficulty might be implemented and received.",15 Jan 2018
140,Ian Dunwell,Developing gamified elements to influence positive behavioural change towards organisational energy efficiency,https://pureportal.coventry.ac.uk/en/publications/developing-gamified-elements-to-influence-positive-behavioural-ch,"Demands for energy within public sector buildings, such as administrative offices, cultural heritage sites, and museums, represent a significant financial and environmental burden. With issues relating to climate change now more prominent than ever, energy efficiency is an important aspect for consideration at both organisational and occupant levels in public buildings. Occupant behaviour plays a key role in the process of saving energy, with the major areas of wastage being directly linked to the use of heating, lighting and electrical devices. Automating these devices can provide a partial, if costly, solution; however, the influence of personal preferences on comfort levels and productivity must also be considered. Strategies may thus seek to enhance organisational energy efficiency in the public sector by promoting positive behavioural changes amongst occupants or visitors. However, such strategies must be informed by knowledge of related behaviours, business processes and best practices for saving energy within specific workplace contexts. To encourage and support participants in adopting energy-conscious behaviours, the incorporation of serious games and gamification offers potential to bring about positive behavioural change. This paper presents the OrbEEt Behavioural Change Framework and its application through the development of a gamified ecosystem consisting of three interfaces; a smartphone game, an intranet portal, and an in-office display. This involves the incorporation of behavioural triggers through an infrastructure of high granularity sensor data, the identification of which are informed by the results of a questionnaire targeting 28 participants across four European pilot sites, representing a diverse range of cultural, climatic, and operational settings for public sector buildings. The work herein represents the pre-intervention stage of the ongoing 3-year OrbEEt research project, with the potential application of these behavioural triggers and interfaces extending to various organisations that are looking to improve overall energy efficiency, while maintaining business productivity and ensuring best practices.",2017
141,Ian Dunwell,Essential features of serious games design in higher education: Linking learning attributes to game mechanics,https://pureportal.coventry.ac.uk/en/publications/essential-features-of-serious-games-design-in-higher-education-li-2,"This paper consolidates evidence and material from a range of specialist and disciplinary fields
to provide an evidence-based review and synthesis on the design and use of serious games in
higher education. Search terms identified 165 papers reporting conceptual and empirical
evidence on how learning attributes and game mechanics may be planned, designed, and
implemented by university teachers interested in using games, which are integrated into lesson
plans and orchestrated as part of a learning sequence at any scale. The findings outline the
potential of classifying the links between learning attributes and game mechanics as a means to
scaffold teachers’ understanding of how to perpetuate learning in optimal ways whilst
enhancing the in-game learning experience. The findings of this paper provide a foundation for
describing methods, frames, and discourse around experiences of design and use of serious
games, linked to methodological limitations and recommendations for further research in this
area.",Jul 2017
142,Ian Dunwell,Promoting healthy adolescent lifestyles through serious games: Enacting a multidisciplinary approach,https://pureportal.coventry.ac.uk/en/publications/promoting-healthy-adolescent-lifestyles-through-serious-games-ena,"Long-term health risks associated with unhealthy lifestyles present a significant current and future burden for healthcare providers. Adolescence represents a critical time for intervention, as habits formed during this period can persist throughout adult life. Given the prevalence of gaming as an entertainment medium amongst adolescents, and subsequent potential for engagement, the use of serious games to promote changes in lifestyle behaviour offers a potential solution. Creating such games requires a breadth of multidisciplinary expertise, working collaboratively to create research-informed designs which reflect both behavioural theory and entertainment game design best practices. In this chapter, challenges and benefits associated with multidisciplinary design are identified and discussed, with strategies presented to overcome and avoid potential issues. With reference to a current project, the perspectives of the theorist, iterative designer, and game developer are contrasted, providing a reference for future projects implementing multidisciplinary approaches to serious game design.",4 Mar 2017
143,Ian Dunwell,Translating open data to educational minigames,https://pureportal.coventry.ac.uk/en/publications/translating-open-data-to-educational-minigames-2,"As web-based open data sources become increasingly accessible and rich, translating and repurposing this data towards an educational goal is a topic of interest. Significant challenges exist in taking this data and translating it to a form meaningful, relevant, and engaging to the learner, addressing the gap between information, knowledge, and understanding. Games provide a key medium through which this may be achieved, though limited evidence exists as regards the best techniques, both pedagogical and technological, by which data can be translated to engaging and educational material. In this paper, we describe the approach adopted by a serious game supporting the development of healthy lifestyles amongst adolescents. The game itself places the player as a survivor in a post-apocalyptic scenario, tasked with survival and exploration. Utilising the United States Department of Agriculture's open data on nutritional information, four different mini-games are implemented in the form of two quiz-based approaches, a puzzle, and a system directly connected to wider game mechanics as a “crafting” system. We discuss the design rationale behind these games and their differences, and present the outcomes of usability testing showing some insight into the various techniques. Our discussion contributes to the theory of how common game mechanics might best be applied to open data to provide effective and engaging educational experiences.",24 Nov 2016
144,Ian Dunwell,A mobile serious game for lifestyle change: Conveying nutritional knowledge and motivation through play,https://pureportal.coventry.ac.uk/en/publications/a-mobile-serious-game-for-lifestyle-change-conveying-nutritional--2,"This paper describes work in progress to create a serious game integrated with an ecosystem of services towards overall project goals of ethically recording, analysing, and motivating adolescent behaviour towards healthier long-term lifestyle. The design outlines an approach that minimises textual and dialogic content in favour of experiential and abstract elements, reflecting existing evidence alongside the need to provide a motivation for users to engage with a wider suite of apps and technologies. Illustrating the use of “freemium” mechanics commonly used to incentivise in-app purchases as a motivator, this paper discusses their use as means towards instead incentivising the use of services to promote a healthier lifestyle. An additional mechanic sources and applies nutritional information from a large database to create a deck of food “cards”, with which the player is challenged to apply their understanding of nutrition to create in-game rewards. Preliminary findings from pre-pilot focus group evaluations with adolescents aged 14-16 (n~10) in Italy and Spain demonstrate enthusiasm for the approach taken to linking real-world behaviour with in-game rewards, as well as potential differences in reception to visual style options between sites and cultures.

",16 Dec 2015
145,Ian Dunwell,A training framework for the creation of location-based experiences using a game authoring environment,https://pureportal.coventry.ac.uk/en/publications/a-training-framework-for-the-creation-of-location-based-experienc,"To support the development and implementation of location-based experience (LBE) as a future educational practice, we evaluate a practical approach to training and guidance, which seeks to transfer an understanding of the design and creation methods for LBEs to practitioners from multi-disciplinary backgrounds. A preliminary version of the ""LBE Training Framework"" is presented, facilitating consideration of constructivist pedagogical theories, training processes, visual design principles, and technical and design constraints when training end-users. The LBE Training Framework is informed by the MAGELLAN Training Framework, which utilises a constructivist paradigm to train participants on how to use the MAGELLAN Authoring Tool. To inform future iterations of the LBE Training Framework and assess the efficacy of the training methodology adopted, this paper presents a case study following a training workshop that featured the initial release of the MAGELLAN Authoring Tool. This workshop, conducted in Greece with 14 end-user participants from multi-disciplinary backgrounds, was used to gather data and evaluate the Training Process taken from the MAGELLAN Training Framework. End-user feedback and user evaluation observations were collected from the workshop participants through a series of questionnaires, one-to one interviews, and focus groups. This paper presents an analysis of the findings, and considers the delivery methods and the training content used at the workshop, informed by the MAGELLAN Training Framework which is presented in the LBE Training Framework, a training paradigm for LBE's.",2015
146,Ian Dunwell,Foundations of dynamic learning analytics: Using university student data to increase retention,https://pureportal.coventry.ac.uk/en/publications/foundations-of-dynamic-learning-analytics-using-university-studen-2,"With digitisation and the rise of e-learning have come a range of computational tools and approaches that have allowed educators to better support the learners' experience in schools, colleges and universities. The move away from traditional paper-based course materials, registration, admissions and support services to the mobile, always-on and always accessible data has driven demand for information and generated new forms of data observable through consumption behaviours. These changes have led to a plethora of data sets that store learning content and track user behaviours. Most recently, new data analytics approaches are creating new ways of understanding trends and behaviours in students that can be used to improve learning design, strengthen student retention, provide early warning signals concerning individual students and help to personalise the learner's experience. This paper proposes a foundational learning analytics model (LAM) for higher education that focuses on the dynamic interaction of stakeholders with their data supported by visual analytics, such as self-organising maps, to generate conversations, shared inquiry and solution-seeking. The model can be applied for other educational institutions interested in using learning analytics processes to support personalised learning and support services. Further work is testing its efficacy in increasing student retention rates.

",Nov 2015
147,Ian Dunwell,Game-based lifestyle interventions for adolescents: An evidence-based approach,https://pureportal.coventry.ac.uk/en/publications/game-based-lifestyle-interventions-for-adolescents-an-evidence-ba-2,"With lifestyle-related conditions such as obesity amongst adolescents on the rise across the developed world, a pressing need exists for interventions which tackle the many factors underlying early-stage lifestyle formation. As a medium, digital games have the potential to integrate well with existing lifestyle patterns in adolescents, whilst engaging them and facilitating such lifestyle changes. Given the wide range of choices open to a game designer, including whether a game should be social, collaborative, competitive, belong to a specific genre, or be blended with other technologies such as wearable sensors, a need exists to identify success factors and translate these to underlying design principles. This paper provides a review of current literature, examining existing game-based interventions alongside the wider evidence base on interventions for lifestyle change. The important role of parent, teacher, or peer interactions, and historical avoidance of competitive elements in intervention design are described through a review of 47 studies of lifestyle interventions and background discussion of 6 existing meta-reviews. The early-stage findings presented by this paper form an evidence base when considering game design for lifestyle intervention.",Jan 2015
148,Ian Dunwell,Green@CU: An environmental game for residential accommodation,https://pureportal.coventry.ac.uk/en/publications/greencu-an-environmental-game-for-residential-accommodation-2,"The importance of using games for supporting behavioural and attitudinal change has been explored in the literature, most recently the games for change movement has promulgated the use of games for supporting altruistic changes that have a positive impact upon the environment. This paper presents a Serious Game designed for University students and its main aim is to educate them about environmental issues. In particular, the focus lies in the importance of saving energy. A user study with 42 participants assessed the feeling of presence of the whole virtual learning experience.",16 Dec 2015
149,Ian Dunwell,OPTIMISING THE DESIGN AND DEVELOPMENT OF LOCATION-BASED GAMES: THE LBE FRAMEWORK,https://pureportal.coventry.ac.uk/en/publications/optimising-the-design-and-development-of-location-based-games-the-2,"The European project MAGELLAN designs and develops, among other systems and services, the
Magellan Authoring Tool (MAT), which is a games authoring platform that has been specifically
created to enable non-programmers to rapidly create and publish multiple forms of location-based
experiences, involving several participants who compete or collaborate to achieve the activities and
goals decided by the author. In the context of the project’s training activities, a series of training
processes, content and events have been realised commensurate to training creative people to
create their own location-based games. To inform future iterations of the Location Based Experience
(LBE) Training Framework and to assess the efficacy of the training methodology adopted for
training users in the Magellan platform, this paper presents a case study following the Training and
Evaluation of an associated project workshop that featured the Alpha release of the platform. An
analysis of the findings is presented from data collected at the workshop featuring both end-user
feedback and user evaluation observations. An investigation into the delivery methods and training
content, specifically created for the Magellan Alpha Workshop, are considered and explored further
as the LBE Training Framework is refined to incorporate feedback concerning future user training
requirements for creating Location-Based Experiences.",2015
150,Ian Dunwell,Providing career guidance to adolescents through digital games: A case study,https://pureportal.coventry.ac.uk/en/publications/providing-career-guidance-to-adolescents-through-digital-games-a--3,"In an evolving global workplace, it is increasingly important for graduates and school-leavers to possess an understanding of the job market, their relevant skills, and career progression paths. However, both the marketplace and career paths are becoming increasingly dynamic, with employees more frequently moving between sectors and positions than was the case for previous generations. The concept of a ""job for life"" at a single organization is becoming less prevalent across sectors and cultures. In such a context, traditional approaches to career guidance, which often focused upon identifying a suitable occupation for adolescents at an early stage and establishing a route towards it, are being challenged with the need to communicate the value of transferrable skills and non-linear progression paths. This article explores the role digital games might play in allowing learners to develop these skills as part of a wider careers guidance programme. Through a case study of the ""MeTycoon"" serious game, the potential reach of such games is discussed, with 38,097 visits to the game's website, and 408,247 views of embedded educational videos. An online survey of players (n=97) gives some insight into their opinions of the game's impact and appeal, with positive comments regarding the design of the game and its emphasis on creating an enjoyable gaming experience whilst providing educational content.",31 Mar 2015
151,Ian Dunwell,Raising awareness on sustainability issues through a mobile game,https://pureportal.coventry.ac.uk/en/publications/raising-awareness-on-sustainability-issues-through-a-mobile-game-2,"The paper presents a review on, and analysis of, the design, development and evaluation of experiences of learning through the `Sustainability Serious Game'. The mobile game has been developed as means of helping public authorities to collect information and feedback on how public spaces could be improved based on collective intelligence procedures. Furthermore, as part of enhancing learning, the game intends to provide knowledge and awareness on sustainability issues for public constructions relevant to engineering and architectural disciplines. Deployed targeted questionnaires with thirty-three (33) computer science students in UK and analysed through a Likert Scale findings from evaluation demonstrate that a conceptual change may be achieved in relation to how sustainability has been perceived. A questionnaire with 20 questions was distributed to students for evaluating various elements of the game such as usability characteristics, accumulation, assimilation and consolidation of new knowledge patterns related to the learning-oriented benefits of the game with an implicit focus on whether the game can be integrated within an academic setting. The fundamental conclusion from the analysis of the game uptake is that it enhances student's engagement with sustainability issues, especially in blended learning contexts for `blending' different pedagogical approaches with game-oriented features as means of improving educational practice.",2015
152,Ian Dunwell,A game-based learning approach to road safety: the code of everand,https://pureportal.coventry.ac.uk/en/publications/a-game-based-learning-approach-to-road-safety-the-code-of-everand-2,"Game and gamification elements are increasingly seeing use as part of interface designs for applications seeking to engage and retain users whilst transferring information. This paper presents an evaluation of a game-based approach seeking to improve the road safety behaviour amongst children aged 9-15 within the UK, made available outside of a classroom context as an online, browser-based, free-to-play game. The paper reports on data for 99,683 players over 315,882 discrete logins, supplemented by results from a nationally-representative survey of children at UK schools (n=1,108), an incentivized survey of the player-base (n=1,028), and qualitative data obtained through a series of one-to-one interviews aged 9-14 (n=28). Analysis demonstrates the reach of the game to its target demographic, with 88.13% of players within the UK. A 3.94 male/female ratio was observed amongst players surveyed, with an age distribution across the target range of 9-15. Noting mean and median playtimes of 93 and 31 minutes (n=99,683), it is suggested such an approach to user engagement and retention can surpass typical contact times obtained through other forms of web-based content. The size of the player-base attracted to the game and players' qualitative feedback demonstrates the potential for serious games deployed on a national scale.

",26 Apr 2014
153,Ian Dunwell,A usability evaluation of game-based approaches assessing risk and delayed gratification,https://pureportal.coventry.ac.uk/en/publications/a-usability-evaluation-of-game-based-approaches-assessing-risk-an-2,"This paper presents the usability evaluation of two games that are built upon existing experiments, assessing risk aversion and delayed gratification. The games were created in order to elicit players' personality traits. The game scenarios were based on adapted validated experiments on cognitive psychology and behavioural economics. The purpose of these games is to enable the generation of predictive behavioural models, and thus design an adaptive and dynamic game promoting responsible energy consumption. Adapting the behaviour of energy consumers to follow environmentally friendly consumption patterns is a central challenge when seeking to address environmental concerns. To perform such adaptation, an understanding of an individual user's traits can allow for customised solutions to be delivered, increasing the likelihood of impact. To assess the usability of the games, domain experts filled in two QUIS questionnaires. The results showed a broadly positive reception of the games' usability; taking into account time, financial and other resources, though they also highlight some areas for future work.. More broadly, knowledge generated has the potential to inform designs of similar games that adapt behavioural tasks to elicit an understanding of the user.",2014
154,Ian Dunwell,Facilitating intuitive-guided learning in a serious game through integration with a learning content management system,https://pureportal.coventry.ac.uk/en/publications/facilitating-intuitive-guided-learning-in-a-serious-game-through--2,"Increased global uptake of entertainment gaming has the potential to lead to high expectations of engagement and interactivity from users of technology-enhanced learning environments. Blended approaches to implementing game-based learning as part of distance or technology-enhanced education have led to demonstrations of the benefits they might bring, allowing learners to interact with immersive technologies as part of a broader, structured learning experience. In this article, we explore how the integration of a serious game can be extended to a learning content management system (LCMS) to support a blended and holistic approach, described as an 'intuitive-guided' method. Through a case study within the EU-Funded Adaptive Learning via Intuitive/Interactive, Collaborative and Emotional Systems (ALICE) project, a technical integration of a gaming engine with a proprietary LCMS is demonstrated, building upon earlier work and demonstrating how this approach might be realized. In particular, how this method can support an intuitive-guided approach to learning is considered, whereby the learner is given the potential to explore a non-linear environment whilst scaffolding and blending provide guidance ensuring targeted learning objectives are met. Through an evaluation of the developed prototype with 32 students aged 14-16 across two Italian schools, a varied response from learners is observed, coupled with a positive reception from tutors. The study demonstrates that challenges remain in providing high-fidelity content in a classroom environment, particularly as an increasing gap in technology availability between leisure and school times emerges.",Oct 2014
155,Ian Dunwell,Fostering Science Teachers’ Design for Inquiry-Based Learning by Using a Serious Game,https://pureportal.coventry.ac.uk/en/publications/fostering-science-teachers-design-for-inquiry-based-learning-by-u-2,"There is wide consensus internationally amongst 
scientific communities that Inquiry-Based Learning can be 
employed to foster acquisition of clearly defined, ‘certain’ 
knowledge such as the conceptual foundations of a scientific 
discipline

",2014
156,Ian Dunwell,Neurophysiological methods for monitoring brain activity in serious games and virtual environments: a review,https://pureportal.coventry.ac.uk/en/publications/neurophysiological-methods-for-monitoring-brain-activity-in-serio-2,"The use of serious games and virtual environments for learning is increasing worldwide. These technologies have the potential to collect live data from users through game play and can be combined with neuroscientific methods such as EEG, fNIRS and fMRI. The several learning processes triggered by serious games are associated with specific patterns of activation that distributed in time and space over different neural networks. This paper explores the opportunities offered and challenges posed by neuroscientific methods when capturing user feedback and using the data to create greater user adaptivity in game. Existing neuroscientific studies examining cortical correlates of game-based learning do not form a common or homogenous field. In contrast, they often have disparate research questions and are represented through a broad range of study designs and game genres. In this paper, the range of studies and applications of neuroscientific methods in game-based learning are reviewed.",2014
157,Ian Dunwell,Pegaso: A serious game to prevent obesity,https://pureportal.coventry.ac.uk/en/publications/pegaso-a-serious-game-to-prevent-obesity-2,"The problem of obesity in the world has grown considerably in recent years. Between 16% and 33% of children and adolescents are obese. Even if obesity is among one of the easiest medical conditions to recognize, it is one of the most difficult to treat. The issue of individuals' motivation to change is the most significant obstacle in promoting positive health behaviours. Games' ability to reach and engage large number of players for long periods of time provides an opportunity for them to be used as a pedagogical tool. This paper describes how serious games and 'gamified' daily life processes appear to be a suitable means for supporting persuasion towards healthful behaviour within the frame of the Pegaso project that aims to develop a multi-dimensional cross-disciplinary ICT system to prevent overweight and obesity in the younger population.",2014
158,Ian Dunwell,Providing Career Guidance to Adolescents through Digital Games: A Case Study,https://pureportal.coventry.ac.uk/en/publications/providing-career-guidance-to-adolescents-through-digital-games-a--2,"In an evolving global workplace, it is increasingly important for graduates and school-leavers to possess an understanding of the job market, their relevant skills, and career progression paths. However, both the marketplace and career paths are becoming increasingly dynamic, with employees more frequently moving between sectors and positions than was the case for previous generations. The concept of a “job for life” at a single organization is becoming less prevalent across sectors and cultures. In such a context, traditional approaches to career guidance, which often focused upon identifying a suitable occupation for adolescents at an early stage and establishing a route towards it, are being challenged with the need to communicate the value of transferrable skills and non-linear progression paths. This article explores the role digital games might play in allowing learners to develop these skills as part of a wider careers guidance programme. Through a case study of the “MeTycoon” serious game, the potential reach of such games is discussed, with 38,097 visits to the game's website, and 408,247 views of embedded educational videos. An online survey of players (n=97) gives some insight into their opinions of the game's impact and appeal, with positive comments regarding the design of the game and its emphasis on creating an enjoyable gaming experience whilst providing educational content.",Oct 2014
159,Ian Dunwell,THE GROWTH: An environmental game focusing on overpopulation issues,https://pureportal.coventry.ac.uk/en/publications/the-growth-an-environmental-game-focusing-on-overpopulation-issue-2,"THE GROWTH is an environmental game aiming to tackle growing population issues and its impact on natural environment. The game also extends to cover social issues and unsustainable resources consumption caused by rapid population growth. Unlike many environmental games, THE GROWTH demonstrates that financial, social and health factors can be improved simply by committing to sustainable consumption patterns. The game aims to investigate the possibility of using serious games to promote players’ environmental awareness and ultimately, the possibility of using serious games to modify players’ consumption patterns. This game is designed for a specific target group of male population between 20-30 years of age in Bangkok (Thailand) and is focused on environmental issues raising the residential accommodation. Early experimental sessions were conducted with 17 participants and this paper presents the preliminary results of the study.",2014
160,Ian Dunwell,Training Science Teachers to Design Inquiry-Based Lesson Plans through a Serious Game,https://pureportal.coventry.ac.uk/en/publications/training-science-teachers-to-design-inquiry-based-lesson-plans-th-2,"A significant challenge for science teachers’ training 
is to understand how to enact teaching strategies that would 
encourage students to perceive learning as a memorable 
experience instantiated through an activity; and thereby 
getting involved in a process of meaning-making. This paper 
describes SimAULA, a serious game that aims to integrate 
inquiry learning into game dynamics for scaffolding science 
teachers’ efforts to design their lesson plans. To this line, the 
paper proposes a 7-step process of orchestrating inquiry 
features that enable science teachers to think about inquiry in 
the context of creating activities based on real-world situations 
that map closely on to students’ understandings rather than 
those with naturally occurring complex patterns. SimAULA’s 
overarching architecture is presented in the context of the 7-
stage inquiry process to be implemented and evaluated in a 
number of schools across Europe.

",2014
161,Ian Dunwell,A game-based approach for raising awareness on sustainability issues in public spaces,https://pureportal.coventry.ac.uk/en/publications/a-game-based-approach-for-raising-awareness-on-sustainability-iss-2,,2013
162,Ian Dunwell,Creating coherent incidental learning journeys on mobile devices through feedback and progress indicators,https://pureportal.coventry.ac.uk/en/publications/creating-coherent-incidental-learning-journeys-on-mobile-devices--2,"Timely and appropriate feedback and indicators of progress can motivate learners. Mobile learning poses a challenge to established instructional strategies with respect to delivering feedback and monitoring learner progress, particularly in informal and incidental learning occurring outside of formal structured learning environments. We argue that well-designed and managed feedback and progress indicators can offer guidance and a sense of structure to learners in the absence of a formal curriculum, accreditation or set outcomes. Furthermore, they can encourage casual users of mobile applications to move from fragmented learning episodes towards a more long term and reflective learning journey. In this paper we describe how we are developing feedback and progress indicators for the EU-funded MASELTOV project, which explores how smartphones can support language learning and social inclusion for recent immigrants to Europe. Presenting educational services and materials on mobile devices allows learning episodes to be incorporated into daily activities and schedules, to be accessed at times and in places that suit learners best. Feedback and progress indicators embedded into these services may motivate such an audience to reconceptualise fragmentary, ephemeral educational experiences into a more coherent, sustained learning journey. We describe how feedback and progress indicators have been used successfully in web-based and games-based learning, and our assessment of which types may best support incidental mobile learning and the challenges we face.

",2013
163,Ian Dunwell,Developing a digital game to support cultural learning amongst immigrants,https://pureportal.coventry.ac.uk/en/publications/developing-a-digital-game-to-support-cultural-learning-amongst-im-2,"Immigrants entering the European Community face a range of challenges in adapting to and understanding the culture of their host nation. Failure to address these challenges can lead to isolation and difficulties integrating into the society of the host country, leading to fragmented communities and a range of social issues. As part of a comprehensive suite of services for immigrants, the European-funded Mobile Assistance for Social Inclusion and Empowerment of Immigrants with Persuasive Learning Technologies and Social Network Services (MASELTOV) project seeks to provide both practical tools and learning services via mobile devices, providing a readily usable resource for immigrants. In this workshop paper, the game-based learning aspect of the MASELTOV project is introduced, with the rationale behind its design presented. In doing so, the benefits and implications of mobile platforms and emergent data capture techniques for game-based learning are discussed, as are the methods for putting engaging gameplay at the forefront of the experience whilst relying on rich data capture and analysis to provide an effective learning solution. Through comparison to several other projects, a number of recommendations are put forward for games deployed in contexts similar to that of MASELTOV: a focus on establishing a significant audience with which to conduct ethical research into efficacy, the need for robust pedagogical frameworks suited to the learning context, and the evolution of methods for data capture and analysis of player activity.",2013
164,Ian Dunwell,Integrating games into the classroom: towards new teachership,https://pureportal.coventry.ac.uk/en/publications/integrating-games-into-the-classroom-towards-new-teachership-2,"Publisher statement: This chapter appears in New Pedagogical Approaches in Game Enhanced Learning: Curriculum Integration, edited by S. de Freitas, M. Ott, M.M. Popescu & I. Stanescu. Copyright, 2013, IGI Global, www.igi-global.com. Posted by permission of the publisher.",2013
165,Ian Dunwell,Integrating serious games in adaptive hypermedia applications for personalised learning experiences,https://pureportal.coventry.ac.uk/en/publications/integrating-serious-games-in-adaptive-hypermedia-applications-for-2,,2013
166,Ian Dunwell,MeTycoon: A game-based approach to career guidance,https://pureportal.coventry.ac.uk/en/publications/metycoon-a-game-based-approach-to-career-guidance-2,,2013
167,Ian Dunwell,"Repurposing, integrating, and rating serious games as learning objects",https://pureportal.coventry.ac.uk/en/publications/repurposing-integrating-and-rating-serious-games-as-learning-obje-2,"The use of computer games within educational contexts has been encouraged by a number of studies showing that, in certain circumstances, their use can allow educators to realize significant improvements over traditional teaching and training methods.",2013
168,Ian Dunwell,Serious games and e-learning-learning standards: towards an integrated experience,https://pureportal.coventry.ac.uk/en/publications/serious-games-and-e-learning-learning-standards-towards-an-integr-2,,2013
169,Ian Dunwell,The development approach of a pedagogically-driven serious game to support Relationship and Sex Education (RSE) within a classroom setting,https://pureportal.coventry.ac.uk/en/publications/the-development-approach-of-a-pedagogically-driven-serious-game-t-2,"Didactic approaches to Relationships and Sex Education (RSE) have been shown to yield limited outcomes when compared to approaches that stimulate peer discussion and debate. Creating effective interventions, which stimulate peer involvement, remains a demanding task and finding a solution that is not only engaging but also pedagogically sound is vital. A case thus exists for exploring how game technology might facilitate more feasible solutions. This paper presents the development approach of a digital game: PR:EPARe (Positive Relationships: Eliminating Coercion and Pressure in Adolescent Relationships), designed by a cross-disciplinary team of UK researchers from Coventry University's Studies in Adolescent Sexual Health (SASH) research group and the Serious Games Institute (SGI). Psychological targets for game content were identified through Intervention Mapping (IM) and the game design process was based on the Four-Dimensional Framework of Learning (4DF) emphasizing the context of deployment, learner profiling and the pedagogical perspective that influence the mode of representation of the learning content. Early efficacy testing of the game solution was validated through a cluster-randomized controlled trial in local schools (n = 505) indicated some positive outcomes in favour of the game-based approach, based on self-reported measures of psycho-social preparedness for avoiding coercion (F [3, 501] = 15.306, p <.001, η2p [please see printed abstract for correct symbol] = 0.084). Analysis of observation data suggests that blending this interactive game-based approach with traditional classroom delivery encouraged the teachers and students to engage in communal discussions and debriefing during and after game play. Together, the results demonstrated real benefits for pedagogy-driven game-based approaches to support the delivery of RSE within a classroom setting.",2013
170,Ian Dunwell,The Herbert virtual museum,https://pureportal.coventry.ac.uk/en/publications/the-herbert-virtual-museum-2,"In recent years, virtual reality and augmented reality have emerged as areas of extreme interest as unique methods for visualising and interacting with digital museum artefacts in a different context, for example, as a virtual museum or exhibition, particularly over the Internet. Modern cultural heritage exhibitions have evolved from static to dynamic exhibitions and challenging explorations. This paper presents two different applications developed for the Herbert Museum and Art Gallery that make the user's experience more immersive, engaging, and interactive. The first application utilizes mobile phone devices in order to enrich the visitors experience in the museum, and the second application is a serious game for cultural heritage and in particular for museum environments focusing on the younger visitors.

",2013
171,Ian Dunwell,The open innovation exchange platform: experiences of implementing a business community engagement platform for channeling IP development and collaboration with local businesses,https://pureportal.coventry.ac.uk/en/publications/the-open-innovation-exchange-platform-experiences-of-implementing-2,"The Open Innovation Exchange Program (OpEx) is an online market place for Business Community Engagement, which encourages collaboration on innovative products and services. Individual participants are able to set their dissemination level keeping their Intellectual Property safe, while still enabling collaborations between Coventry University academics and businesses. The project will implement the web based market place and also integrate immersive virtual technologies where appropriate. The platform is currently being rolled out across Coventry University, the Times Higher Education award winning 'Entrepreneurial University of the Year of 2011. This paper describes the experiences of implementing the marketplace for business community engagement in Coventry. It shows preliminary studies on the use of different technologies, describes the development of the platform and describes a preliminary evaluation of its effectiveness and how it can support Open Innovation and foster IP creation.

",2013
172,Ian Dunwell,Authoring Adaptive Serious Games,https://pureportal.coventry.ac.uk/en/publications/authoring-adaptive-serious-games-2,,21 Sept 2012
173,Ian Dunwell,Authoring of adaptive serious games,https://pureportal.coventry.ac.uk/en/publications/authoring-of-adaptive-serious-games-3,,2012
174,Ian Dunwell,"CC-LO: Embedding interactivity, challenge and empowerment into collaborative learning sessions",https://pureportal.coventry.ac.uk/en/publications/cc-lo-embedding-interactivity-challenge-and-empowerment-into-coll-2,,2012
175,Ian Dunwell,Defining a metadata schema for serious games as learning objects,https://pureportal.coventry.ac.uk/en/publications/defining-a-metadata-schema-for-serious-games-as-learning-objects-2,,2012
176,Ian Dunwell,E-commerce transactions in a virtual environment: virtual transactions,https://pureportal.coventry.ac.uk/en/publications/e-commerce-transactions-in-a-virtual-environment-virtual-transact-2,,2012
177,Ian Dunwell,Game engines selection framework for high-fidelity serious applications,https://pureportal.coventry.ac.uk/en/publications/game-engines-selection-framework-for-high-fidelity-serious-applic-2,,2012
178,Ian Dunwell,Guiding intuitive learning in serious games: An achievement-based approach to externalized feedback and assessment,https://pureportal.coventry.ac.uk/en/publications/guiding-intuitive-learning-in-serious-games-an-achievement-based-,"Despite the rapid emergence of game-based learning as a method for conveying educational content, constructing pedagogies which effectively combine elements of entertainment gaming with methods of instruction remains a demanding task. Through the notion of 'intuitive guided' learning, this paper presents an approach which seeks to facilitate a structured learning experience whilst allowing learners to explore a non-linear environment. To do so, a framework is presented which externalizes the assessment process in a serious game, whilst also providing a means for game content to be adapted dynamically to translate the outcomes of the assessment process to effective feedback. A developed prototype is implemented to examine the theory in-practice through the case of a game for civil defence training in schools. Using this prototype, a range of methods in which achievements might be related to learner actions are introduced, and their subsequent implications for intuitive learning discussed. Furthermore, the prototype illustrates how assessment rules can be defined as external to the game and subsequently used to generate feedback for a virtual companion who assumes the role of a more-able partner. The long-term potential of such methods as a source of data on player behaviour is discussed, suggesting further benefits the technique might offer to educators seeking to introduce game-based learning within the curriculum in a blended fashion.",28 Sept 2012
179,Ian Dunwell,PR:EPARe: A game-based approach to relationship guidance for adolescents,https://pureportal.coventry.ac.uk/en/publications/prepare-a-game-based-approach-to-relationship-guidance-for-adoles-2,"Ensuring adolescents are equipped with the necessary skills to handle coercion and pressure from peers is a central component of effective relationship education. However, for teachers attempting to convey these principles, didactic methods have been shown to meet with limited success, as the highest-risk students may fail to engage with the subject matter in a meaningful fashion. In this paper, the potential a digital game may hold as a component of a blended learning solution to this problem is explored though the development of PR:EPARe (Positive Relationships: Eliminating Coercion and Pressure in Adolescent Relationships). Adopting a participatory design approach, designers considered relevant input from stakeholders, subject experts, teachers and students in the development of PR:EPARe. Participatory involvement has allowed the game to be developed in such a way that draws focus on the role of the end user to extend from the traditional concern of the student's learning needs to consider that of the practitioner's needs as another primary condition of successful game based learning. An examination of the first section of the PR:EPARe game is undertaken through a cluster randomized control trial of 507 students across three UK schools. Using ANOVA to demonstrating significant differences between control and game groups (p",2012
180,Ian Dunwell,Re-using serious games by encapsulating them in learning objects,https://pureportal.coventry.ac.uk/en/publications/re-using-serious-games-by-encapsulating-them-in-learning-objects-2,,2012
181,Ian Dunwell,Serious games for healthcare: applications and implications,https://pureportal.coventry.ac.uk/en/publications/serious-games-for-healthcare-applications-and-implications-2,"With advances in technologies and revolutions in patient, trainee, and public expectations, the global healthcare sector is increasingly turning to serious games to solve problems. Serious games are applications with serious purposes, developed using computer game technologies more often associated with entertainment.

Serious Games for Healthcare: Applications and Implications will introduce the development and application of game technologies for health-related serious games. Further, it provides cutting-edge academic research and industry updates which will inform readers about the current and future advances in the area. Encapsulating the knowledge of commercial and noncommercial researchers, developers, and practitioners in a single volume will benefit not only the research and development community within this field, but could also serve public health interests by improving awareness and outcomes.",2012
182,Ian Dunwell,Technical evaluation of the mEducator 3.0 linked databased environment for sharing medical educational resources,https://pureportal.coventry.ac.uk/en/publications/technical-evaluation-of-the-meducator-30-linked-databased-environ,"mEducator 3.0 is a content sharing approach for medical education, based on Linked Data principles. Through standardization, it enables sharing and discovery of medical information. Overall the mEducator project seeks to address the following two different approaches, mEducator 2.0, based on web 2.0 and ad-hoc Application Programmers Interfaces (APIs), and mEducator 3.0, which builds upon a collection of Semantic Web Services that federate existing sources of medical and Technology Enhanced Learning (TEL) data. The semantic mEducator 3.0 approach It has a number of different instantiations, allowing flexibility and choice. At present these comprise of a standalone social web-based instantiation (MetaMorphosis+) and instantiations integrated with Drupal, Moodle and OpenLabyrinth systems. This paper presents the evaluation results of the mEducator 3.0 Linked Data based environment for sharing medical educational resources and focuses on metadata enrichment, conformance to the requirements and technical performance (of the MetaMorphosis+ and Drupal instantiations).",1 Dec 2012
183,Mark Elshaw,Pedestrian and Cyclist Detection and Intent Estimation for Autonomous Vehicles: A Survey,https://pureportal.coventry.ac.uk/en/publications/pedestrian-and-cyclist-detection-and-intent-estimation-for-autono,"As autonomous vehicles become more common on the roads, their advancement draws on safety concerns for vulnerable road users, such as pedestrians and cyclists. This paper presents a review of recent developments in pedestrian and cyclist detection and intent estimation to increase the safety of autonomous vehicles, for both the driver and other road users. Understanding the intentions of the pedestrian/cyclist enables the self-driving vehicle to take actions to avoid incidents. To make this possible, development of methods/techniques, such as deep learning (DL), for the autonomous vehicle will be explored. For example, the development of pedestrian detection has been significantly advanced using DL approaches, such as; Fast Region-Convolutional Neural Network (R-CNN) , Faster R-CNN and Single Shot Detector (SSD). Although DL has been around for several decades, the hardware to realise the techniques have only recently become viable. Using these DL methods for pedestrian and cyclist detection and applying it for the tracking, motion modelling and pose estimation can allow for a successful and accurate method of intent estimation for the vulnerable road users. Although there has been a growth in research surrounding the study of pedestrian detection using vision-based approaches, further attention should include focus on cyclist detection. To further improve safety for these vulnerable road users (VRUs), approaches such as sensor fusion and intent estimation should be investigated.",6 Jun 2019
184,Mark Elshaw,Visual and Thermal Data for Pedestrian and Cyclist Detection,https://pureportal.coventry.ac.uk/en/publications/visual-and-thermal-data-for-pedestrian-and-cyclist-detection,"With the continued advancement of autonomous vehicles and their implementation in public roads, accurate detection of vulnerable road users (VRUs) is vital for ensuring safety. To provide higher levels of safety for these VRUs, an effective detection system should be employed that can correctly identify VRUs in all types of environments (e.g. VRU appearance, crowded scenes) and conditions (e.g. fog, rain, night-time). This paper presents optimal methods of sensor fusion for pedestrian and cyclist detection using Deep Neural Networks (DNNs) for higher levels of feature abstraction. Typically, visible sensors have been utilized for this purpose. Recently, thermal sensors system or combination of visual and thermal sensors have been employed for pedestrian detection with advanced detection algorithm. DNNs have provided promising results for improving the accuracy of pedestrian and cyclist detection. This is because they are able to extract features at higher levels than typical hand-crafted detectors. Previous studies have shown that amongst the several sensor fusion techniques that exist, Halfway Fusion has provided the best results in terms of accuracy and robustness. Although sensor fusion and DNN implementation have been used for pedestrian detection, there is considerably less research undertaken for cyclist detection.",2019
185,Mark Elshaw,A hybrid deep learning neural approach for emotion recognition from facial expressions for socially assistive robots,https://pureportal.coventry.ac.uk/en/publications/a-hybrid-deep-learning-neural-approach-for-emotion-recognition-fr,"We have recently seen significant advancements in the development of robotic machines that are designed to assist people with their daily lives. Socially assistive robots are now able to perform a number of tasks autonomously and without human supervision. However, if these robots are to be accepted by human users, there is a need to focus on the form of human–robot interaction that is seen as acceptable by such users. In this paper, we extend our previous work, originally presented in Ruiz-Garcia et al. (in: Engineering applications of neural networks: 17th international conference, EANN 2016, Aberdeen, UK, September 2–5, 2016, proceedings, pp 79–93, 2016. https://doi.org/10.1007/978-3-319-44188-7_6), to provide emotion recognition from human facial expressions for application on a real-time robot. We expand on previous work by presenting a new hybrid deep learning emotion recognition model and preliminary results using this model on real-time emotion recognition performed by our humanoid robot. The hybrid emotion recognition model combines a Deep Convolutional Neural Network (CNN) for self-learnt feature extraction and a Support Vector Machine (SVM) for emotion classification. Compared to more complex approaches that use more layers in the convolutional model, this hybrid deep learning model produces state-of-the-art classification rate of 96.26 % , when tested on the Karolinska Directed Emotional Faces dataset (Lundqvist et al. in The Karolinska Directed Emotional Faces—KDEF, 1998), and offers similar performance on unseen data when tested on the Extended Cohn–Kanade dataset (Lucey et al. in: Proceedings of the third international workshop on CVPR for human communicative behaviour analysis (CVPR4HB 2010), San Francisco, USA, pp 94–101, 2010). This architecture also takes advantage of batch normalisation (Ioffe and Szegedy in Batch normalization: accelerating deep network training by reducing internal covariate shift. http://arxiv.org/abs/1502.03167, 2015) for fast learning from a smaller number of training samples. A comparison between Gabor filters and CNN for feature extraction, and between SVM and multilayer perceptron for classification is also provided.",Apr 2018
186,Mark Elshaw,Deep Learning for Illumination Invariant Facial Expression Recognition,https://pureportal.coventry.ac.uk/en/publications/deep-learning-for-illumination-invariant-facial-expression-recogn,"In this work we propose a novel method to address illumination invariance for facial expression recognition. We propose a Deep Convolutional Network (CNN) pre-trained as a Deep Stacked Convolutional Autoencoder (SCAE) in a greedy layer-wise unsupervised fashion. The SCAE model learns to encode facial expression images and produce a feature vector with relatively similar illumination, regardless of the luminance level of the input image. Moreover, we propose fine-tuning the stacked shallow autoencoders after each one of these is trained greedily, rather than just at the end, and show that this approach significantly improves the set of illumination invariant features learnt by the SCAE. Finally, we propose the use of a variant rectifier linear unit transfer function that helps the SCAE model reduce or increase the illumination of images with high or low luminance, and show that the lower and upper bounds greatly influence classification performance. The method proposed provides an increase in classification accuracy of 4% on the KDEF dataset and 8% on the CK+ dataset.",10 Oct 2018
187,Mark Elshaw,Deep learning for real time facial expression recognition in social robots,https://pureportal.coventry.ac.uk/en/publications/deep-learning-for-real-time-facial-expression-recognition-in-soci,"Human robot interaction is a rapidly growing topic of interest in today’s society. The development of real time emotion recognition will further improve the relationship between humans and social robots. However, contemporary real time emotion recognition in unconstrained environments has yet to reach the accuracy levels achieved on controlled static datasets. In this work, we propose a Deep Convolutional Neural Network (CNN), pre-trained as a Stacked Convolutional Autoencoder (SCAE) in a greedy layer-wise unsupervised manner, for emotion recognition from facial expression images taken by a NAO robot. The SCAE model is trained to learn an illumination invariant down-sampled feature vector. The weights of the encoder element are then used to initialize the CNN model, which is fine-tuned for classification. We train the model on a corpus composed of gamma corrected versions of the CK+, JAFFE, FEEDTUM and KDEF datasets. The emotion recognition model produces a state-of-the-art accuracy rate of 99.14% on this corpus. We also show that the proposed training approach significantly improves the CNN’s generalisation ability by over 30% on nonuniform data collected with the NAO robot in unconstrained environments.",17 Nov 2018
188,Mark Elshaw,Stacked deep convolutional auto-encoders for emotion recognition from facial expressions,https://pureportal.coventry.ac.uk/en/publications/stacked-deep-convolutional-auto-encoders-for-emotion-recognition-,"Emotion recognition is critical for everyday living and is essential for meaningful interaction. If we are to progress towards human and machine interaction that is engaging the human user, the machine should be able to recognize the emotional state of the user. Deep Convolutional Neural Networks (CNN) have proven to be efficient in emotion recognition problems. The good degree of performance achieved by these classifiers can be attributed to their ability to self-learn a down-sampled feature vector that retains spatial information through filter kernels in convolutional layers. Given the view that random initialization of weights can lead to convergence to non-optimal local minima, in this paper we explore the impact of training the initial weights in an unsupervised manner. We study the effect of pre-training a Deep CNN as a Stacked Convolutional Auto-Encoder (SCAE) in a greedy layer-wise unsupervised fashion for emotion recognition using facial expression images. When trained with randomly initialized weights, our CNN emotion recognition model achieves a performance rate of 91.16% on the Karolinska Directed Emotional Faces (KDEF) dataset. In contrast, when each layer of the model, including the hidden layer, is pre-trained as an Auto-Encoder, the performance increases to 92.52%. Pre-training our CNN as a SCAE also reduces training time marginally. The emotion recognition model developed in this work will form the basis of a real-time empathic robot system.",3 Jul 2017
189,Mark Elshaw,Deep Learning for Emotion Recognition in Faces,https://pureportal.coventry.ac.uk/en/publications/deep-learning-for-emotion-recognition-in-faces-2,"Deep Learning (DL) has shown real promise for the classification efficiency for emotion recognition problems. In this paper we present experimental results for a deeply-trained model for emotion recognition through the use of facial expression images. We explore two Convolutional Neural Network (CNN) architectures that offer automatic feature extraction and representation, followed by fully connected softmax layers to classify images into seven emotions. The first architecture explores the impact of reducing the number of deep learning layers and the second splits the input images horizontally into two streams based on eye and mouth positions. The first proposed architecture produces state of the art results with an accuracy rate of 96.93 % and the second architecture with split input produces an average accuracy rate of 86.73 %, respectively.",13 Aug 2016
190,Mark Elshaw,Emotion Recognition Using Facial Expression Images for a Robotic Companion,https://pureportal.coventry.ac.uk/en/publications/emotion-recognition-using-facial-expression-images-for-a-robotic--2,"Social robots are gradually becoming part of society. However, social robots lack the ability to adequately interact with users in a natural manner and are in need of more human-like abilities. In this paper we present experimental results on emotion recognition through the use of facial expression images obtained from the KDEF database, a fundamental first step towards the development of an empathic social robot. We compare the performance of Support Vector Machines (SVM) and a Multilayer Perceptron Network (MLP) on facial expression classification. We employ Gabor filters as an image pre-processing step before classification. Our SVM model achieves an accuracy rate of 97.08 %, whereas our MLP achieves 93.5 %. These experiments serve as benchmark for our current research project in the area of social robotics.",2016
191,Mark Elshaw,Smartphone Based Human Activity and Postural Transition Classification with Deep Stacked Autoencoder Networks,https://pureportal.coventry.ac.uk/en/publications/smartphone-based-human-activity-and-postural-transition-classific-2,Human activity recognition (HAR) is a prominent research area attracting considerable interest in recent years.,2016
192,Mark Elshaw,Emotional recognition from the speech signal for a virtual education agent,https://pureportal.coventry.ac.uk/en/publications/emotional-recognition-from-the-speech-signal-for-a-virtual-educat,"This paper explores the extraction of features from the speech wave to perform intelligent emotion recognition. A feature extract tool (openSmile) was used to obtain a baseline set of 998 acoustic features from a set of emotional speech recordings from amicrophone. The initial features were reduced to the most important ones so recognition ofemotions using a supervised neural network could be performed. Given that the future use of virtual education agents lies with making the agents more interactive, developing agents with the capability to recognise and adapt to the emotional state of humans is an important step.",2013
193,Mark Elshaw,A Hybrid Neural Emotion Recogniser for Human-Robotic Agent Interaction,https://pureportal.coventry.ac.uk/en/publications/a-hybrid-neural-emotion-recogniser-for-human-robotic-agent-intera,"This paper presents a hybrid neural approach to emotion recognition from speech, which combines feature selection using principal component analysis (PCA) with unsupervised neural clustering through self-organising map (SOM). Given the importance that is associated with emotions in humans, it is unlikely that robots will be accepted as anything more that machines if they do not express and recognise emotions. In this paper, we describe the performance of an unsupervised approach to emotion recognition that achieves similar performance to current supervised intelligent approaches. Performance, however, reduces when the system is tested using samples from a male volunteer not in the training set using a low cost microphone. Through the use of an unsupervised neural approach, it is possible to go beyond the basic binary classification of emotions to consider the similarity between emotions and whether speech can express multiple emotions at the same time",2012
194,Mark Elshaw,An attention-gating recurrent working memory architecture for emergent speech representation,https://pureportal.coventry.ac.uk/en/publications/an-attention-gating-recurrent-working-memory-architecture-for-eme,"This paper describes an attention-gating recurrent self-organising map approach for emergent speech representation. Inspired by evidence from human cognitive processing, the architecture combines two main neural components. The first component, the attention-gating mechanism, uses actor-critic learning to perform selective attention towards speech. Through this selective attention approach, the attention-gating mechanism controls access to working memory processing. The second component, the recurrent self-organising map memory, develops a temporal-distributed representation of speech using phone-like structures. Representing speech in terms of phonetic features in an emergent self-organised fashion, according to research on child cognitive development, recreates the approach found in infants. Using this representational approach, in a fashion similar to infants, should improve the performance of automatic recognition systems through aiding speech segmentation and fast word learning. ",2010
195,Mark Elshaw,Modeling Neurons of the Inferior Colliculus,https://pureportal.coventry.ac.uk/en/publications/modeling-neurons-of-the-inferior-colliculus,The MiCRAM project has been developing detailed neural models of the inferior colliculus (IC) as the basis for understanding the neural networks that underlie early auditory processing at that level. The initial phase of this project has been to develop biologically plausible models of the physiologically distinct cell types of the IC. This has led to the recognition that some of the gross behavior that produces delay sensitivity may be the result of detailed dynamic interactions between multiple channels. ,2007
196,Mark Elshaw,A hybrid generative and predictive model of the motor cortex,https://pureportal.coventry.ac.uk/en/publications/a-hybrid-generative-and-predictive-model-of-the-motor-cortex,"We describe a hybrid generative and predictive model of the motor cortex. The generative model is related to the hierarchically directed cortico-cortical (or thalamo-cortical) connections and unsupervised training leads to a topographic and sparse hidden representation of its sensory and motor input. The predictive model is related to lateral intra-area and inter-area cortical connections, functions as a hetero-associator  and is trained to predict the future state of the network. Applying partial input, the generative model can map sensory input to motor actions and can thereby perform learnt action sequences of the agent within the environment. The predictive model can additionally predict a longer perception- and action sequence (mental simulation). The models’ performance is demonstrated on a visually guided robot docking manoeuvre. We propose that the motor cortex might take over functions previously learnt by reinforcement in the basal ganglia and relate this to mirror neurons and imitation",May 2006
197,Mark Elshaw,Towards multimodal neural robot learning,https://pureportal.coventry.ac.uk/en/publications/towards-multimodal-neural-robot-learning,"Learning by multimodal observation of vision and language offers a potentially powerful paradigm for robot learning. Recent experiments have shown that ‘mirror’ neurons are activated when an action is being performed, perceived, or verbally referred to. Different input modalities are processed by distributed cortical neuron ensembles for leg, arm and head actions. In this overview paper we consider this evidence from mirror neurons by integrating motor, vision and language representations in a learning robot.",30 Jun 2004
198,Mark Elshaw,Learning robot actions based on self-organising language memory,https://pureportal.coventry.ac.uk/en/publications/learning-robot-actions-based-on-self-organising-language-memory,"In the MirrorBot project we examine perceptual processes using models of cortical assemblies and mirror neurons to explore theemergence of semantic representations of actions, percepts and concepts in a neural robot. The hypothesis under investigation is whether a neural model will produce a life-like perception system for actions. In this context we focus in this paper on how instructions for actions can be modeled in a self-organising memory. Current approaches for robot control often do not use language and ignore neural learning. However, our approach uses language instruction and draws from the concepts of regional distributed modularity, self-organisation and neural assemblies. We describe a self-organising model that clusters actions into different locations depending on the body part they areassociated with. In particular, we use actual sensor readings from the MIRA robot to represent semantic features of the action verbs.",2003
199,Mark Elshaw,Towards Integrating Learning by Demonstration and Learning by Instruction in a Multimodal Robotics,https://pureportal.coventry.ac.uk/en/publications/towards-integrating-learning-by-demonstration-and-learning-by-ins,"Learning by demonstration and learning by instruction offers a potentially more powerful paradigm than programming robots directly for specific tasks. Learning in humans or primates substantially benefits from demonstration of actions or instruction by language in the appropriate context and there is initial neurocognitive cortical evidence for such processes. Cortical assemblies have been identified in the cortex that activate in response to the performance of motor tasks at a semantic level. This evidence supports that such mirror neuron assemblies are involved in actions, observing actions and communicating actions. Furthermore, neurocognitive evidence supports that cell assemblies are activated in different regions of the brain dependent on theaction type being processed. Based on this neurocognitive evidence we have begun to design a neural robot in the MirrorBot project that is based on multimodal integration and topological organisation of actions using associative memory. As part of these studies in this paper we describe a self-organising model that clusters actions into different locations dependent on the body part they are associated with. In particular, we use actual sensor readings from the MIRA robot to represent semantic features of the action verbs. Furthermore, ongoing work focuses on integration ofmotor, vision and language representations for learning fromdemonstration and language instruction.",2003
200,Xiang Fei,A Survey of Community Detection in Complex Networks Using Nonnegative Matrix Factorization,https://pureportal.coventry.ac.uk/en/publications/a-survey-of-community-detection-in-complex-networks-using-nonnega,"Community detection is one of the popular research topics in the field of complex networks analysis. It aims to identify communities, represented as cohesive subgroups or clusters, where nodes in the same community link to each other more densely than others outside. Due to the interpretability, simplicity, flexibility, and generality, nonnegative matrix factorization (NMF) has become a very ideal model for community detection and lots of related methods have been presented. To facilitate research on NMF-based community detection, in this article, we make a comprehensive review on NMF-based methods for community detection, especially the state-of-the-art methods presented in high prestige journals or conferences. First, we introduce the basic principles of NMF and explain why NMF can detect communities and design a general framework of NMF-based community detection. Second, according to the applicable network types, we propose a taxonomy to divide the existing NMF-based methods for community detection into six categories, namely, topology networks, signed networks, attributed networks, multilayer networks, dynamic networks, and large-scale networks. We deeply analyze representative methods in every category. Finally, we summarize the common problems faced by all methods and potential solutions and propose four promising research directions. We believe that this survey can fully demonstrate the versatility of NMF-based community detection and serve as a useful guideline for researchers in related fields.",1 Apr 2022
201,Xiang Fei,Boosting nonnegative matrix factorization based community detection with graph attention auto-encoder,https://pureportal.coventry.ac.uk/en/publications/boosting-nonnegative-matrix-factorization-based-community-detecti,"Community detection is of great help to understand the structures and functions of complex networks. It has become one of popular research topics in the field of complex networks analysis. Due to the simplicity, flexibility, effectiveness and interpretability, Nonnegative Matrix Factorization (NMF)-based methods have been widely employed for community detection. However, most existing NMF-based community detection methods are linear and their performance is limited when facing networks with diversified structure information. In view of this, we propose a nonlinear NMF-based method named NMFGAAE, which is composed of two main modules: NMF and Graph Attention Auto-Encoder (GAAE). This approach can boost the performance of NMF-based community detection methods by the aid of graph neural networks and deep clustering. More specifically, GAAE introduces an attention mechanism directed by NMF-based community detection to learn the node representations, while NMF can simultaneously factor these representations to uncover the community structure. We design a unified framework to jointly optimize GAAE and NMF modules, which is very beneficial to obtain better community detection results. We conduct extensive experiments on synthetic and real-world networks. The results show that NMFGAAE not only performs better than state-of-the-art NMF-based community detection methods, but also outperforms some network representation based baselines.",1 Aug 2022
202,Xiang Fei,From Music Information Retrieval to Stock Market Analysis: Theoretical Discussion on Feature Extraction Transfer,https://pureportal.coventry.ac.uk/en/publications/from-music-information-retrieval-to-stock-market-analysis-theoret,"Finding similar objects and patterns based on the similarity score is one of the fundamental and useful tasks in Data Mining. Different applications may introduce different features that need to be extract and analyzed. However, if two applications share some similar core concepts, it is possible to transfer some features that will be beneficial to transfer learning. Thus, this paper uses some features from Music Information Retrieval and Stock Market Analysis to theoretically illustrate the possibility of Feature Extraction Transfer. We use a 3-tuple or 6-tuple vector to record the music fundamental melody whereas a 5-tuple vector to record the daily behavior of the stock market from the candlestick chart. Hence, the flow of one music melody and the flow of one stock market can be treat as a time series vector sequence. Using this linkage, we have computed some feature exaction from Music Information Retrieval onto Stock Market Analysis and obtained some positive results. For example, the similarity between Activision Blizzard Inc and Zynga Inc have achieved a similarity score of 0.6250. Moreover, these positive results gave some ideas on implementing a self-supervised learning based system to manage your stock market and the potential of implementing a transfer learning between these two applications.",11 Apr 2021
203,Xiang Fei,Similarity preserving overlapping community detection in signed networks,https://pureportal.coventry.ac.uk/en/publications/similarity-preserving-overlapping-community-detection-in-signed-n,"Community detection in signed networks is a challenging research problem, and is of great importance to understanding the structural and functional properties of signed networks. It aims at dividing nodes into different clusters with more intra-cluster and less inter-cluster links. Meanwhile, most positive links should lie within clusters and most negative links should lie between clusters. In recent years, some methods for community detection in signed networks have been proposed, but few of them focus on overlapping community detection. Moreover, most of them directly exploit the sparse link topology to detect communities, which often makes them perform poorly. In view of this, in this paper we propose a similarity preserving overlapping community detection (SPOCD) method. SPOCD firstly extracts node similarity information and geometric structure information from the link topology, and then uses a graph regularized binary semi-nonnegative matrix factorization (GRBSNMF) model to fuse these two sources of information to detect communities. Through this mechanism, nodes with high similarity can be well preserved in the same community. Besides, SPOCD devises a special discretization strategy to obtain the binary community indicator matrix, which is very convenient for directly identifying overlapping communities in signed networks. We conduct extensive experiments on synthetic and real-world signed networks, and the results demonstrate that our method outperforms state-of-the-art methods.",Mar 2021
204,Xiang Fei,Network Embedding Using Deep Robust Nonnegative Matrix Factorization,https://pureportal.coventry.ac.uk/en/publications/network-embedding-using-deep-robust-nonnegative-matrix-factorizat,"As an effective technique to learn low-dimensional node features in complicated network environment, network embedding has become a promising research direction in the ﬁeld of network analysis. Due to the virtues of better interpretability and ﬂexibility, matrix factorization based methods for network embedding have received increasing attentions. However, most of them are inadequate to learn more complicated hierarchical features hidden in complex networks because of their mechanisms of single-layer factorization structure. Besides, their original feature matrices used for factorization and their robustness against noises also need to be further improved. To solve these problems, we propose a novel network embedding method named DRNMF (deep robust nonnegative matrix factorization), which is formed by multi-layer NMF learning structure. Meanwhile, DRNMF employs the combination of high-order proximity matrices of the network as the original feature matrix for the factorization. To improve the robustness against noises, we use l2,1 norm to devise the objective function for the DRNMF network embedding model. Effective iterative update rules are derived to resolve the model, and the convergence of these rules is strictly proved. Moreover, we introduce a pre-training strategy to improve the efﬁciency of convergence. Extensive experiments on several benchmarks of complex networks demonstrate that our proposed method DRNMF is effective and has better performance than the state-of-the-art matrix factorization based methods for network embedding.",4 May 2020
205,Xiang Fei,CPS Data Streams Analytics based on Machine Learning for Cloud and Fog Computing: A Survey,https://pureportal.coventry.ac.uk/en/publications/cps-data-streams-analytics-based-on-machine-learning-for-cloud-an,"Cloud and Fog computing has emerged as a promising paradigm for the Internet of things (IoT) and cyber–physical systems (CPS). One characteristic of CPS is the reciprocal feedback loops between physical processes and cyber elements (computation, software and networking), which implies that data stream analytics is one of the core components of CPS. The reasons for this are: (i) it extracts the insights and the knowledge from the data streams generated by various sensors and other monitoring components embedded in the physical systems; (ii) it supports informed decision making; (iii) it enables feedback from the physical processes to the cyber counterparts; (iv) it eventually facilitates the integration of cyber and physical systems. There have been many successful applications of data streams analytics, powered by machine learning techniques, to CPS systems. Thus, it is necessary to have a survey on the particularities of the application of machine learning techniques to the CPS domain. In particular, we explore how machine learning methods should be deployed and integrated in Cloud and Fog architectures for better fulfilment of the requirements of mission criticality and time criticality arising in CPS domains. To the best of our knowledge, this paper is the first to systematically study machine learning techniques for CPS data stream analytics from various perspectives, especially from a perspective that leads to the discussion and guidance of how the CPS machine learning methods should be deployed in a Cloud and Fog architecture.",Jan 2019
206,Xiang Fei,Improving generalization ability of Instance-transfer Based Imbalanced Sentiment Classification of Turn-Level Interactive Chinese Texts,https://pureportal.coventry.ac.uk/en/publications/improving-generalization-ability-of-instance-transfer-based-imbal,"Generally, a classification model achieving better generalization ability means the model performs better on the future incoming data, otherwise the history dataset. Increasing the generalization ability of multi-domain and imbalanced multi-class emotion classification of turn-level interactive Chinese texts poses the challenges due to its high dimension and sparse feature values in its feature space. Moreover, the properties of different feature spaces or diverse data distributions in various domains of target dataset (T) and source dataset (S) make it difficult to employ multi-class and multi-domain instance transfer. To address these challenges, we propose a data-level sampling approach for multi-class and multi-domain instance transfer which is inspired by transfer learning. To verify the validity of our proposed method, an imbalanced dataset is taken as target dataset, while three datasets, one collected from Bulletin Board System of Xi'an Jiaotong University and other two datasets collected from China microblog platform Weibo, as source datasets. The experimental results show that the proposed approach outperforms classic algorithms by alleviating the imbalanced problem in interactive texts effectively. Moreover, a classification model that is trained on immigrated datasets produced by employing our proposed method achieves the best ability of generalization. ",Jun 2019
207,Xiang Fei,Improving NMF-based community discovery using distributed robust nonnegative matrix factorization with SimRank similarity measure,https://pureportal.coventry.ac.uk/en/publications/improving-nmf-based-community-discovery-using-distributed-robust-,"Nonnegative Matrix Factorization (NMF) has become a powerful model for community discovery in complex networks. Existing NMF-based methods for community discovery often factorize the corresponding adjacent matrix of complex networks to obtain its community indicator matrix. However, the adjacent matrix cannot represent the global structure feature of complex networks very well, and this leads to the performance degradation of community discovery. Besides, most of existing methods are not robust and scalable enough, so they are not effective to deal with complex networks with noises and large-scales. Aiming at these problems above, in this paper we propose a method for community discovery using distributed robust NMF with SimRank similarity measure. This method selects SimRank measure to construct the feature matrix, which can more accurately represent the global structure feature of complex networks. To improve the robustness, we select ℓ2;1 norm instead of the widely used Frobenius norm to construct its NMFbased community discovery model. In addition, to improve the scalability, we implement its key components by using MapReduce distributed computing framework, including computing SimRank feature matrix and iteratively solving the NMF-based model for community discovery. We conduct extensive experiments on several typical complex networks. The results show that our method has better performance and robustness than other representative NMF-based methods for community discovery. Moreover, our method presents good scalability, and hence can be used to discover communities in the largescale complex networks.",Oct 2018
208,Xiang Fei,A method of demand-driven and data-centric Web service configuration for flexible business process implementation,https://pureportal.coventry.ac.uk/en/publications/a-method-of-demand-driven-and-data-centric-web-service-configurat-2,"Facing the rapidly changing business environments, implementation of flexible business process is crucial, but difficult especially in data-intensive application areas. This study aims to provide scalable and easily accessible information resources to leverage business process management. In this article, with a resource-oriented approach, enterprise data resources are represented as data-centric Web services, grouped on-demand of business requirement and configured dynamically to adapt to changing business processes. First, a configurable architecture CIRPA involving information resource pool is proposed to act as a scalable and dynamic platform to virtualise enterprise information resources as data-centric Web services. By exposing data-centric resources as REST services in larger granularities, tenant-isolated information resources could be accessed in business process execution. Second, dynamic information resource pool is designed to fulfil configurable and on-demand data accessing in business process execution. CIRPA also isolates transaction data from business process while supporting diverse business processes composition. Finally, a case study of using our method in logistics application shows that CIRPA provides an enhanced performance both in static service encapsulation and dynamic service execution in cloud computing environment.
This is an Accepted Manuscript of an article published by Taylor & Francis in Enterprise Information Systems on 3 Mar 2016, available online: http://www.tandfonline.com/10.1080/17517575.2016.115052 

",2017
209,Xiang Fei,A topic community-based method for friend recommendation in large-scale online social networks,https://pureportal.coventry.ac.uk/en/publications/a-topic-community-based-method-for-friend-recommendation-in-large-2,"Online social networks (OSNs) have become more and more popular and have attracted a great many users. Friend recommendation, which is one of the important services in OSN, can help users discover their interested friends and alleviate the problem of information overload. However, most of existing recommendation methods only consider either user link or content information and hence are not effective enough to provide high quality recommendations. In this paper, we propose a topic community-based method via Nonnegative Matrix Factorization (NMF). This method first applies joint NMF model to mine topic communities existing in OSN by combing link and content information. Then it computes user pairwise similarities and makes friends recommendation based on topic communities. Furthermore, this method can be implemented using the MapReduce distributed computing framework. Extensive experiments show that our proposed method not only has better recommendation performance than state-of-the-art methods but also has good scalability to deal with the problem of friend recommendation in large-sale OSNs. Moreover, the application case demonstrates that it can significantly improve friend recommendation service in the real world OSN.",25 Mar 2017
210,Xiang Fei,Graph Analysis of Fog Computing Systems for Industry 4.0,https://pureportal.coventry.ac.uk/en/publications/graph-analysis-of-fog-computing-systems-for-industry-40,"Increased adoption of Fog Computing concepts into Cyber Physical Systems (CPS) is a driving force for implementing Industry 4.0. The modern industrial environment focuses on providing a flexible factory floor that suits the needs of modern manufacturing through the reduction of downtimes, reconfiguration times, adoption of new technologies and the increase of its production capabilities and rates. Fog Computing through CPS aims to provide a flexible orchestration and management platform that can meet the needs of this emerging industry model. Proposals on Fog Computing platform and Software Defined Networks (SDN) for Industry allow for resource virtualization and access throughout the system enabling large composite application systems to be deployed on multiple nodes. The increase of reliability, redundancy and runtime parameters as well as the reduction of costs in such systems are of key interest to Industry and researchers as well. The development of optimization algorithms and methods is made difficult by the complexity of such systems and the lack of real-world data on fog systems resulting in algorithms that are not being designed for real world scenarios. We propose a set of use-case scenarios based on our Industrial partner that we analyze to determine the graph based parameters of the system that allows us to scale and generate a more realistic testing scenario for future optimization attempts as well as determine the nature of such systems in comparison to other networks types. To show the differences between these scenarios and our real-world use-case we have selected a set of key graph characteristics based on which we analyze and compare the resulting graphs from the systems.",22 Nov 2017
211,Xiang Fei,Platform as a service gateway for the Fog of Things,https://pureportal.coventry.ac.uk/en/publications/platform-as-a-service-gateway-for-the-fog-of-things-2,"Internet of Things (IoT), one of the key research topics in recent years, together with concepts from Fog Computing, brings rapid advancements in Smart City, Monitoring Systems, industrial control, transportation and other fields. These applications require a reconfigurable sensor architecture that can span multiple scenarios, devices and use cases that allow storage, networking and computational resources to be efficiently used on the edge of the network. There are a number of platforms and gateway architectures that have been proposed to manage these components and enable application deployment. These approaches lack horizontal integration between multiple providers as well as higher order functionalities like load balancing and clustering. This is partly due to the strongly coupled nature of the deployed applications, a lack of abstraction of device communication layers as well as a lock-in for communication protocols. This limitation is a major obstacle for the development of a protocol agnostic application environment that allows for single application to be migrated and to work with multiple peripheral devices with varying protocols from different local gateways. This research looks at existing platforms and their shortcomings as well as proposes a messaging based modular gateway platform that enables clustering of gateways and the abstraction of peripheral communication protocol details. These novelties allow applications to send and receive messages regardless of their deployment location and destination device protocol, creating a more uniform development environment. Furthermore, it results in a more streamlined application development and testing while providing more efficient use of the gateway’s resources. Our evaluation of a prototype for the system shows the need for the migration of resources and the QoS advantages of such a system. The examined use case scenarios show that clustering proves to be an advantage in certain use cases as well as presenting the deployment of a larger testing and control environment through the platform.Publisher Statement: NOTICE: this is the author’s version of a work that was accepted for publication in Advanced Engineering Informatics. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in Advanced Engineering Informatics, [33, (2016)] DOI: 10.1016/j.aei.2016.11.003© 2016, Elsevier. Licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International http://creativecommons.org/licenses/by-nc-nd/4.0/",Aug 2017
212,Xiang Fei,A Topic Community-based Method for Friend Recommendation in Online Social Networks via Joint Nonnegative Matrix Factorization,https://pureportal.coventry.ac.uk/en/publications/a-topic-community-based-method-for-friend-recommendation-in-onlin-2,"Online social networks (OSN) have become more and more popular and have accumulated a great many users. Friend recommendation can help users discover their interested friends and alleviate the problem of information overload. However, most of existing recommendation methods only consider user link or content information and hence are not effective enough to provide high quality recommendations. In this paper, we propose a topic community-based method via nonnegative matrix factorization (NMF). This method first applies joint NMF model to mine topic community existing in OSN by combing link and content information. Then it makes friend recommendation based on topic community. Experiments show that our method can reflect user preferences on friend selection more appropriately and has better recommendation performance than traditional methods. Moreover, our application case also demonstrates that it can obviously improve friend recommendation service in the real world OSN.

",2015
213,Xiang Fei,IT for future e-business management [editorial],https://pureportal.coventry.ac.uk/en/publications/it-for-future-e-business-management-editorial-2,"Information technology (IT) plays an important role in e-Business management. It enables the development of e-Business information systems and affects the way of how the e-Business is conducted. To support e-Business based organizations in achieving excellence and the competitive edge, IT for Future E-Business Management must rise to new challenges by providing tools to analyse large volumes of data from various sources and support decision making, generating models for investigating factors in fast growing e-Commerce sectors, and developing mechanisms for improving the efficiency of processes, etc.

",2015
214,Xiang Fei,Stochastic modeling of dynamic right-sizing for energy-efficiency in cloud data centers,https://pureportal.coventry.ac.uk/en/publications/stochastic-modeling-of-dynamic-right-sizing-for-energy-efficiency-2,"Large data centers are usually built to support increasing computational and data storage demand of growing global business and industry, which consume an enormous amount of energy, at a huge cost to both business and the environment. However, much of that energy is wasted to maintain excess service capacity during periods of low load. In this paper, we investigate the problem of “right-sizing“ data center for energy-efficiency through virtualization which allows consolidation of workloads into smaller number of servers while dynamically powering off the idle ones. In view of the dynamic nature of data centers, we propose a stochastic model based on Queueing theory to capture the main characteristics. Solving this model, we notice that there exists a tradeoff between the energy consumption and performance. We hereby develop a BFGS based algorithm to optimize the tradeoff by searching for the optimal system parameter values for the data center operators to “right-size“ the data centers. We implement our Stochastic Right-sizing Model (SRM) and deploy it in the real-world cloud data center. Experiments with two real-world workload traces show that SRM can significantly reduce the energy consumption while maintaining high performance.",Jul 2015
215,Xiang Fei,An intelligent framework for activity led learning in network planning and management,https://pureportal.coventry.ac.uk/en/publications/an-intelligent-framework-for-activity-led-learning-in-network-pla-2,Monitoring students' activity and performance is vital to enable educators to provide effective teaching and learning to engage students with the subject and improve their understanding of the material. We describe the use of a fuzzy linguistic summarisation (LS) technique for extracting linguistically interpretable rules from student data describing prominent relationships between activity/engagement characteristics and achieved performance. We propose an intelligent framework for monitoring individual or group performance during activity and problem-based learning tasks. The proposed system is developed as a set of services to cater for data heterogeneity and deployable on a cloud computing platform. We present a case study and experiments in which we apply the fuzzy LS technique for analysing the effectiveness of using a group performance model (GPM) to deploy activity led learning (ALL) in a master-level module. Results show that the fuzzy rules can identify useful relationships between student engagement and performance.,2014
216,Xiang Fei,Energy Consumption Data Based Machine Anomaly Detection,https://pureportal.coventry.ac.uk/en/publications/energy-consumption-data-based-machine-anomaly-detection-2,"The ever increasing of product development and the scarcity of the energy resources that those manufacturing activities heavily rely on have made it of great significance the study on how to improve the energy efficiency in manufacturing environment. Energy consumption sensing and collection enables
the development of effective solutions to higher energy efficiency. Further, it is found that the data on energy consumption of manufacturing machines also contains the information on the conditions of these machines. In this paper, methods of machine anomaly detection based on energy consumption information are developed and applied to cases on our Syil X4 computer numerical control (CNC) milling machine. Further, given massive amount of energy consumption data from large amount machining tasks, the proposed algorithms are being implemented on a Storm and Hadoop based framework aiming at online realtime machine anomaly detection.

",Nov 2014
217,Xiang Fei,Applications development on a rule-based WSN middleware,https://pureportal.coventry.ac.uk/en/publications/applications-development-on-a-rule-based-wsn-middleware-2,,2012
218,Xiang Fei,REED: Flexible rule based programming of wireless sensor networks at runtime,https://pureportal.coventry.ac.uk/en/publications/reed-flexible-rule-based-programming-of-wireless-sensor-networks--2,,2012
219,Xiang Fei,Development of a rule based wireless sensor network middleware,https://pureportal.coventry.ac.uk/en/publications/development-of-a-rule-based-wireless-sensor-network-middleware-2,,2010
220,Xiang Fei,Priority based message transmission over unreliable wireless links for safety critical monitoring applications,https://pureportal.coventry.ac.uk/en/publications/priority-based-message-transmission-over-unreliable-wireless-link-2,,2009
221,Xiang Fei,The application of mobile-commerce in the University and its security concerns - a case study of Coventry University,https://pureportal.coventry.ac.uk/en/publications/the-application-of-mobile-commerce-in-the-university-and-its-secu-2,,2009
222,Marwan Fuad,Evolutionary algorithms for modeling non-equilibrium population,https://pureportal.coventry.ac.uk/en/publications/evolutionary-algorithms-for-modeling-non-equilibrium-population,"During protein synthesis the genetic code links each codon, a triplet of nucleotides, with the corresponding amino acid. Synonymous codons are those that code for the same amino acid. The difference in the frequency of occurrence of certain synonymous codons over other synonymous codons is called the codon usage bias (CUB). The Zeng and Charlesworth model is used to estimate the strength of CUB. In their model the evolutionary process is represented by a Markov model, which allows the population size to vary over time. In this paper we propose a new method that incorporates demographic changes into the model. The method is a hybrid of two optimizers, the first is evolutionary programming and the second is a version of the genetic algorithms that uses chromosomes of variable lengths, which allows for expressing more demographic changes than what the simplified model presented by Zeng and Charlesworth does. We conduct several simulations to show why this hybridization is necessary, and also to show the superior performance of this new hybrid.",Jan 2022
223,Marwan Fuad,Applying nature-inspired optimization algorithms for selecting important timestamps to reduce time series dimensionality,https://pureportal.coventry.ac.uk/en/publications/applying-nature-inspired-optimization-algorithms-for-selecting-im,"Time series data account for a major part of data supply available today. Time series mining handles several tasks such as classification, clustering, query-by-content, prediction, and others. Performing data mining tasks on raw time series is inefficient as these data are high-dimensional by nature. Instead, time series are first pre-processed using several techniques before different data mining tasks can be performed on them. In general, there are two main approaches to reduce time series dimensionality; the first is what we call landmark methods. These methods are based on finding characteristic features in the target time series. The second is based on data transformations. These methods transform the time series from the original space into a reduced space, where they can be managed more efficiently. The method we present in this paper applies a third approach, as it projects a time series onto a lower-dimensional space by selecting important points in the time series. The novelty of our method is that these points are not chosen according to a geometric criterion, which is subjective in most cases, but through an optimization process. The other important characteristic of our method is that these important points are selected on a dataset-level and not on a single time series-level. The direct advantage of this strategy is that the distance defined on the low-dimensional space lower bounds the original distance applied to raw data. This enables us to apply the popular GEMINI algorithm. The promising results of our experiments on a wide variety of time series datasets, using different optimizers, and applied to the two major data mining tasks, validate our new method.",1 Mar 2019
224,Marwan Fuad,Aggressive pruning strategy for time series retrieval using a multi-resolution representation based on vector quantization coupled with discrete wavelet transform,https://pureportal.coventry.ac.uk/en/publications/aggressive-pruning-strategy-for-time-series-retrieval-using-a-mul,"Time series representation methods are widely used to handle time series data by projecting them onto low-dimensional spaces where queries are processed. Multi-resolution representation methods speed up the similarity search process by using pre-computed distances, which are calculated and stored at the indexing stage and then used at the query stage, together with filters in the form of exclusion conditions. In this paper, we present a new multi-resolution representation method that combines the Haar wavelet-based multi-resolution method with vector quantization to maximize the pruning power of the similarity search algorithm. The new method is validated through extensive experiments on different datasets from several time series repositories. The results obtained prove the efficiency of the new method.",Feb 2017
225,Marwan Fuad,Modeling non-equilibrium population using variable-chromosome-length genetic algorithm,https://pureportal.coventry.ac.uk/en/publications/modeling-non-equilibrium-population-using-variable-chromosome-len,"Codon usage bias is the preferential use of synonymous codons. First models that studied this phenomenon assumed that the population is at mutation-selection-drift equilibrium, but more advanced models were proposed later to incorporate demographic changes. One of these models proposed by Zeng and Charlesworth represents the evolutionary process by a Markov model, allowing for changes in the population size. Their model is, however, too simple to reflect many realistic demographic changes. In this paper, we extend their model by allowing complex demographies with many changes in population size. Such extension requires a more powerful optimization algorithm compared with the simple one used in the model proposed by Zeng and Charlesworth. The optimization algorithm we use is a version of the genetic algorithm that we develop particularly for this purpose. We validate our method using simulated data.",5 Jul 2017
226,Marwan Fuad,A differential evolution optimization algorithm for reducing time series dimensionality,https://pureportal.coventry.ac.uk/en/publications/a-differential-evolution-optimization-algorithm-for-reducing-time,"Performing data mining tasks on raw time series is inefficient as these data are high-dimensional by nature. Instead, time series are first pre-processed using several techniques before the different data mining tasks can be performed. In general, there are two main approaches to pre-process time series. The first is what we call landmark methods. These methods are based on finding characteristic features in the target time series. The other approach is based on data transformations. These methods transform the time series from the original space into a reduced space so that they can be managed more efficiently. The method we present in this paper applies a third approach, as it projects a time series onto a lower-dimensional space by selecting important points in the time series. The novelty of our method is that these points are not chosen according to a geometric criterion which is subjective in most cases. The other important difference is that these important points are selected on a dataset-level and not on a single time series-level. The direct advantage of this strategy is that the distance defined on the low-dimensional space lower bounds the original distance applied to raw data. This enables us to apply the popular GEMINI algorithm. The promising results of our experiments on a wide variety of time series datasets validate our new method.",21 Nov 2016
227,Marwan Fuad,An experimental evaluation of the adaptive sampling method for time series classification and clustering,https://pureportal.coventry.ac.uk/en/publications/an-experimental-evaluation-of-the-adaptive-sampling-method-for-ti,"Adaptive sampling is a dimensionality reduction technique of time series data inspired by the dynamic programming piecewise linear approximation. This dimensionality reduction technique yields a suboptimal solution of the problem of polygonal curve approximation by limiting the search space. In this paper, we conduct extensive experiments to evaluate the performance of adaptive sampling in 1-NN classification and k-means clustering tasks. The experiments we conducted show that adaptive sampling gives satisfactory results in the aforementioned tasks even for relatively high compression ratios.",1 Jan 2016
228,Marwan Fuad,Optimized word-size time series representation method using a genetic algorithm with a flexible encoding scheme,https://pureportal.coventry.ac.uk/en/publications/optimized-word-size-time-series-representation-method-using-a-gen,"Performing time series mining tasks directly on raw data is inefficient, therefore these data require representation methods that transform them into low-dimension spaces where they can be managed more efficiently. Owing to its simplicity, the piecewise aggregate approximation is a popular time series representation method. But this method uses a uniform word-size for all the segments in the time series, which reduces the quality of the representation. Although some alternatives use representations with different word-sizes in a way that reflects the various information contents of different segments, such methods apply a complicated representation scheme, as it uses a different representation for each time series in the dataset. In this paper we present two modifications of the original piecewise aggregate approximation. The novelty of these modifications is that they use different word-sizes, which allows for a flexible representation that reflects the level of activity in each segment, yet these new medications address this problem on a dataset-level, which simplifies establishing a lower bounding distance. The word-sizes are determined through an optimization process. The experiments we conducted on a variety of time series datasets validate the two new modifications.",5 Nov 2016
229,Marwan Fuad,Variable-chromosome-length genetic algorithm for time series discretization,https://pureportal.coventry.ac.uk/en/publications/variable-chromosome-length-genetic-algorithm-for-time-series-disc,"The symbolic aggregate approximation method (SAX) of time series is a widely-known dimensionality reduction technique of time series data. SAX assumes that normalized time series have a high-Gaussian distribution. Based on this assumption SAX uses statistical lookup tables to determine the locations of the breakpoints on which SAX is based. In a previous work, we showed how this assumption oversimplifies the problem, which may result in high classification errors. We proposed an alternative approach, based on the genetic algorithms, to determine the locations of the breakpoints. We also showed how this alternative approach boosts the performance of the original SAX. However, the method we presented has the same drawback that existed in the original SAX; it was only able to determine the locations of the breakpoints but not the corresponding alphabet size, which had to be input by the user in the original SAX. In the method we previously presented we had to run the optimization process as many times as the range of the alphabet size. Besides, performing the optimization process in two steps can cause overfitting. The novelty of the present work is twofold; first, we extend a version of the genetic algorithms that uses chromosomes of different lengths. Second, we apply this new version of variable-chromosome-length genetic algorithm to the problem at hand to simultaneously determine the number of the breakpoints, together with their locations, so that the optimization process is run only once. This speeds up the training stage and also avoids overfitting. The experiments we conducted on a variety of datasets give promising results.",6 Aug 2016
230,Marwan Fuad,A Haar wavelet-based multi-resolution representation method of time series data,https://pureportal.coventry.ac.uk/en/publications/a-haar-wavelet-based-multi-resolution-representation-method-of-ti,"Similarity search of time series can be efficiently handled through a multi-resolution representation scheme which offers the possibility to use pre-computed distances that are calculated and stored at indexing time and then utilized at query time together with filters in the form of exclusion conditions which speed up the search. In this paper we introduce a new multi-resolution representation and search framework of time series. Compared with our previous multi-resolution methods which use first degree polynomials to reduce the dimensionality of the time series at different resolution levels, the novelty of this work is that it applies Haar wavelets to represent the time series. This representation is particularly adapted to our multi-resolution approach as discrete wavelet transforms have the ability of reflecting the local and global information content at every resolution level thus enhancing the performance of the similarity search algorithm, which is what we have shown in this paper through extensive experiments on different datasets.",1 Jan 2015
231,Marwan Fuad,Applying non-dominated sorting genetic algorithm ii to multi-objective optimization of a weighted multi-metric distance for performing data mining tasks,https://pureportal.coventry.ac.uk/en/publications/applying-non-dominated-sorting-genetic-algorithm-ii-to-multi-obje,"Multi-objective optimization (MOO) is a class of optimization problems where several objective functions must be simultaneously optimized. Traditional search methods are difficult to extend to MOO problems so many of these problems are solved using bio-inspired optimization algorithms. One of the famous optimization algorithms that have been applied to MOO is the nondominated sorting genetic algorithm II (NSGA-II). NSGA-II algorithm has been successfully used to solve MOO problems owing to its lower computational complexity compared with the other optimization algorithms. In this paper we use NSGA-II to solve a MOO problem of time series data mining. The problem in question is determining the optimal weights of a multi-metric distance that is used to perform several data mining tasks. NSGA-II is particularly appropriate to optimize data mining problems where fitness functions evaluation usually involves intensive computing resources. Whereas several previous papers have proposed different methods to optimize time series data mining problems, this paper is, to our knowledge, the first paper to optimize several time series data mining tasks simultaneously. The experiments we conducted show that the performance of the optimized combination of multi-metric distances we propose in executing time series data mining tasks is superior to that of the distance metrics that constitute the combination when they are applied separately.",2015
232,Marwan Fuad,Chemo-inspired genetic algorithm for optimizing the piecewise aggregate approximation,https://pureportal.coventry.ac.uk/en/publications/chemo-inspired-genetic-algorithm-for-optimizing-the-piecewise-agg,In a previous work we presented DEWPAA: an improved version of the piecewise aggregate approximation representation method of time series. DEWPAA uses differential evolution to set weights to different segments of the time series according to their information content. In this paper we use a hybrid of bacterial foraging and genetic algorithm (CGA) to set the weights of the different segments in our improved piecewise aggregate approximation. Our experiments show that the new hybrid gives better results in time series clasification.,1 Jan 2015
233,Marwan Fuad,Hierarchical clustering of DNA microarray data using a hybrid of bacterial foraging and differential evolution,https://pureportal.coventry.ac.uk/en/publications/hierarchical-clustering-of-dna-microarray-data-using-a-hybrid-of-,"Microarray technology is one the most important advances in bioinformatics which allows the study of the expression levels of a large number of genes simultaneously. Data mining techniques have been widely applied in order to infer useful knowledge from DNA microarray data. One of these principle techniques is clustering which groups expressed genes according to their similarity. Hierarchical clustering is one of the main clustering methods which represents data in dendrograms. In a previous work the authors used the genetic algorithms to optimize the hierarchical clustering quality based on different clustering measures. In this paper we propose another optimization method based on a hybrid of differential evolution and bacterial foraging optimization algorithm to handle the optimization problem of hierarchical clustering of DNA microarray data. We show through experiments that this hybrid optimization method is more appropriate to tackle this problem than the one which uses the genetic algorithms, as this new method gives a better clustering quality according to different clustering measures.",19 Nov 2015
234,Marwan Fuad,Multi-objective optimization for clustering microarray gene expression data - a comparative study,https://pureportal.coventry.ac.uk/en/publications/multi-objective-optimization-for-clustering-microarray-gene-expre,"Clustering is one of the main data mining tasks. It can be performed on a fuzzy or a crisp basis. Fuzzy clustering is widely-applied with microarray gene expression data as these data are usually uncertain and imprecise. There are several measures to evaluate the quality of clustering, but their performance is highly related to the dataset to which they are applied. In a previous work the authors proposed using a multi-objective genetic algorithm – based method, NSGA – II, to optimize two clustering validity measures simultaneously. In this paper we use another multi-objective optimizer, NSPSO, which is based on the particle swarm optimization algorithm, to solve the same problem. The experiments we conducted on two microarray gene expression data show that NSPSO is superior to NSGA-II in handling this problem.",1 Jan 2015
235,Marwan Fuad,On the application of bio-inspired optimization algorithms to fuzzy C-Means clustering of time series,https://pureportal.coventry.ac.uk/en/publications/on-the-application-of-bio-inspired-optimization-algorithms-to-fuz,"Fuzzy c-means clustering (FCM) is a clustering method which is based on the partial membership concept. As with the other clustering methods, FCM applies a distance to cluster the data. While the Euclidean distance is widely-used to perform the clustering task, other distances have been suggested in the literature. In this paper we study the use of a weighted combination of metrics in FCM clustering of time series where the weights in the combination are the outcome of an optimization process using differential evolution, genetic algorithms, and particle swarm optimization as optimizers. We show how the overfitting phenomenon interferes in the optimization process that the optimal results obtained during the training stage degrade during the testing stage as a result of overfitting.",2015
236,Marwan Fuad,Optimized multi-resolution indexing and retrieval scheme of time series,https://pureportal.coventry.ac.uk/en/publications/optimized-multi-resolution-indexing-and-retrieval-scheme-of-time-,"Multi-resolution representation has been successfully used for indexing and retrieval of time series. In a previous work we presented Tight-MIR, a multi-resolution representation method which speeds up the similarity search by using distances pre-computed at indexing time. At query time Tight-MIR applies two pruning conditions to filter out non-qualifying time series. Tight-MIR has the disadvantage of storing all the distances corresponding to all resolution levels, even those whose pruning power is low. At query time Tight-MIR also processes all stored resolution levels. In this paper we optimize the Tight-MIR algorithm by enabling it to store and process only the resolution levels with the maximum pruning power. The experiments we conducted on the new optimized version show that it does not only require less storage space, but it is also faster than the original algorithm.",Sept 2015
237,Marwan Fuad,A hybrid of bacterial foraging and differential evolution -based distance of sequences,https://pureportal.coventry.ac.uk/en/publications/a-hybrid-of-bacterial-foraging-and-differential-evolution-based-d,"In a previous work we presented a new distance that we called the sigma gram distance, which is used to compute the similarity between two sequences. This distance is based on parameters which we computed through an optimization process that used the artificial bee colony; a bio-inspired optimization algorithm. In this paper we show how a hybrid of two optimization algorithms; bacterial foraging and differential evolution, when used to compute the parameters of the sigma gram distance, can yield better results than those obtained by applying artificial bee colony. This superiority in performance is validated through experiments on the same data sets to which artificial bee colony, on the same optimization problem, was tested.",1 Jan 2014
238,Marwan Fuad,A synergy of artificial bee colony and genetic algorithms to determine the parameters of the ∑-gram distance,https://pureportal.coventry.ac.uk/en/publications/a-synergy-of-artificial-bee-colony-and-genetic-algorithms-to-dete,In a previous work we presented the ∑-gram distance that computes the similarity between two sequences. This distance includes parameters that we calculated by means of an optimization process using artificial bee colony. In another work we showed how population-based bio-inspired algorithms can be sped up by applying a method that utilizes a pre-initialization stage to yield an optimal initial population. In this paper we use this pre-initialization method on the artificial bee colony algorithm to calculate the parameters of the ∑-gram distance. We show through experiments how this pre-initialization method can substantially speed up the optimization process.,1 Jan 2014
239,Marwan Fuad,A weighted minimum distance using hybridization of particle swarm optimization and Bacterial Foraging,https://pureportal.coventry.ac.uk/en/publications/a-weighted-minimum-distance-using-hybridization-of-particle-swarm,"In a previous work we used a popular bio-inspired algorithm; particle swam optimization (PSO) to improve the performance of a well-known representation method of time series data which is the symbolic aggregate approximation (SAX), where PSO was used to propose a new weighted minimum distance WMD for SAX to recover some of the information loss resulting from the original minimum distance MINDIST on which SAX is based. WMD sets different weights to different segments of the time series according to their information content, where these weights are determined using PSO. We showed how SAX in conjunction with WMD can give better results in times series classification than the original SAX which uses MINDIST. In this paper we revisit this problem and propose optimizing WMD by using a hybrid of PSO and another bio-inspired optimization method which is Bacterial Foraging (BF); an effective bio-inspired optimization algorithm in solving difficult optimization problems. We show experimentally how by using this hybrid to set the weights of WMD we can obtain better classification results than those obtained when using PSO to set these weights.",1 Jan 2014
240,Marwan Fuad,Differential evolution-based weighted combination  of distance metrics for k-means clustering,https://pureportal.coventry.ac.uk/en/publications/differential-evolution-based-weighted-combination-of-distance-met,"Bio-inspired optimization algorithms have been successfully used to solve many problems in engineering, science, and economics. In computer science bio-inspired optimization has different applications in different domains such as software engineering, networks, data mining, and many others. One of the main tasks in data mining is clustering, namely k-means clustering. Distance metrics are at the heart of all data mining tasks. In this paper we present a new method which applies differential evolution, one of the main bio-inspired optimization algorithms, on a time series k-means clustering task to set the weights of the distance metrics used in a combination that is used to cluster the time series. The weights are obtained by applying an optimization process that gives optimal clustering quality. We show through extensive experiments how this optimized combination outperforms all the other stand-alone distance metrics, all by keeping the same low complexity of the distance metrics used in the combination.",1 Jan 2014
241,Marwan Fuad,One-step or two-step optimization and the overfitting phenomenon: A case study on time series classification,https://pureportal.coventry.ac.uk/en/publications/one-step-or-two-step-optimization-and-the-overfitting-phenomenon-,"For the last few decades, optimization has been developing at a fast rate. Bio-inspired optimization algorithms are metaheuristics inspired by nature. These algorithms have been applied to solve different problems in engineering, economics, and other domains. Bio-inspired algorithms have also been applied in different branches of information technology such as networking and software engineering. Time series data mining is a field of information technology that has its share of these applications too. In previous works we showed how bio-inspired algorithms such as the genetic algorithms and differential evolution can be used to find the locations of the breakpoints used in the symbolic aggregate approximation of time series representation, and in another work we showed how we can utilize the particle swarm optimization, one of the famous bio-inspired algorithms, to set weights to the different segments in the symbolic aggregate approximation representation. In this paper we present, in two different approaches, a new meta optimization process that produces optimal locations of the breakpoints in addition to optimal weights of the segments. The experiments of time series classification task that we conducted show an interesting example of how the overfitting phenomenon, a frequently encountered problem in data mining which happens when the model overfits the training set, can interfere in the optimization process and hide the superior performance of an optimization algorithm.",1 Jan 2014
242,Marwan Fuad,Parameter-free extended edit distance,https://pureportal.coventry.ac.uk/en/publications/parameter-free-extended-edit-distance,"The edit distance is the most famous distance to compute the similarity between two strings of characters. The main drawback of the edit distance is that it is based on local procedures which reflect only a local view of similarity. To remedy this problem we presented in a previous work the extended edit distance, which adds a global view of similarity between two strings. However, the extended edit distance includes a parameter whose computation requires a long training time. In this paper we present a new extension of the edit distance which is parameter-free. We compare the performance of the new extension to that of the extended edit distance and we show how they both perform very similarly.",1 Jan 2014
243,Marwan Fuad,A pre-initialization stage of population-based bio-inspired metaheuristics for handling expensive optimization problems,https://pureportal.coventry.ac.uk/en/publications/a-pre-initialization-stage-of-population-based-bio-inspired-metah,"Metaheuristics are probabilistic optimization algorithms which are applicable to a wide range of optimization problems. Bio-inspired, also called nature-inspired, optimization algorithms are the most widely-known metaheuristics. The general scheme of bio-inspired algorithms consists in an initial stage of randomly generated solutions which evolve through search operations, for several generations, towards an optimal value of the fitness function of the optimization problem at hand. Such a scenario requires repeated evaluation of the fitness function. While in some applications each evaluation will not take more than a fraction of a second, in others, mainly those encountered in data mining, each evaluation may take up several minutes, hours, or even more. This category of optimization problems is called expensive optimization. Such cases require a certain modification of the above scheme. In this paper we present a new method for handling expensive optimization problems. This method can be applied with different population-based bio-inspired optimization algorithms. Although the proposed method is independent of the application to which it is applied, we experiment it on a data mining task.",1 Dec 2013
244,Marwan Fuad,When optimization is just an illusion,https://pureportal.coventry.ac.uk/en/publications/when-optimization-is-just-an-illusion,"Bio-inspired optimization algorithms have been successfully applied to solve many problems in engineering, science, and economics. In computer science bio-inspired optimization has different applications in different domains such as software engineering, networks, data mining, and many others. However, some applications may not be appropriate or even correct. In this paper we study this phenomenon through a particular method which applies the genetic algorithms on a time series classification task to set the weights of the similarity measures used in a combination that is used to classify the time series. The weights are supposed to be obtained by applying an optimization process that gives optimal classification accuracy. We show in this work, through examples, discussions, remarks, explanations, and experiments, that the aforementioned method of optimization is not correct and that completely randomly-chosen weights for the similarity measures can give the same classification accuracy.",1 Dec 2013
245,Marwan Fuad,ABC-SG: A new artificial bee colony algorithm-based distance of sequential data using sigma grams,https://pureportal.coventry.ac.uk/en/publications/abc-sg-a-new-artificial-bee-colony-algorithm-based-distance-of-se,"The problem of similarity search is one of the main problems in computer science. This problem has many applications in text-retrieval, web search, computational biology, bioinformatics and others. Similarity between two data objects can be depicted using a similarity measure or a distance metric. There are numerous distance metrics in the literature, some are used for a particular data type, and others are more general. In this paper we present a new distance metric for sequential data which is based on the sum of n-grams. The novelty of our distance is that these n-grams are weighted using artificial bee colony; a recent optimization algorithm based on the collective intelligence of a swarm of bees on their search for nectar. This algorithm has been used in optimizing a large number of numerical problems. We validate the new distance experimentally.",1 Jan 2012
246,Marwan Fuad,Differential evolution versus genetic algorithms: Towards symbolic aggregate approximation of non-normalized time series,https://pureportal.coventry.ac.uk/en/publications/differential-evolution-versus-genetic-algorithms-towards-symbolic,"The differential evolution (DE) is a very powerful search method for solving many optimization problems. In this paper we present a new scheme (DESAX) based on the differential evolution to localize the breakpoints utilized with the symbolic aggregate approximation method; one of the most important symbolic representation techniques for times series data. We compare the new scheme with a previous one (GASAX), which is based on the genetic algorithms, and we show how the new scheme outperforms the original one. We also show how (DESAX) can be used for the symbolic aggregate approximation of non-normalized time series.",28 Sept 2012
247,Marwan Fuad,Genetic algorithms-based symbolic aggregate approximation,https://pureportal.coventry.ac.uk/en/publications/genetic-algorithms-based-symbolic-aggregate-approximation,"Time series data appear in a broad variety of economic, medical, and scientific applications. Because of their high dimensionality, time series data are managed by using representation methods. Symbolic representation has attracted particular attention because of the possibility it offers to benefit from algorithms and techniques of other fields in computer science. The symbolic aggregate approximation method (SAX) is one of the most important symbolic representation techniques of times series data. SAX is based on the assumption of ""high Gaussianity"" of normalized time series which permits it to use breakpoints obtained from Gaussian lookup tables. The use of these breakpoints is the heart of SAX. In this paper we show that this assumption of Gaussianity oversimplifies the problem and can result in very large errors in time series mining tasks. We present an alternative scheme, based on the genetic algorithms (GASAX), to find the breakpoints. The new scheme does not assume any particular distribution of the data, and it does not require normalizing the data either. We conduct experiments on different datasets and we show that the new scheme clearly outperforms the original scheme.",1 Oct 2012
248,Marwan Fuad,Particle swarm optimization of information-content weighting of symbolic aggregate approximation,https://pureportal.coventry.ac.uk/en/publications/particle-swarm-optimization-of-information-content-weighting-of-s,"Bio-inspired optimization algorithms have been gaining more popularity recently. One of the most important of these algorithms is particle swarm optimization (PSO). PSO is based on the collective intelligence of a swam of particles. Each particle explores a part of the search space looking for the optimal position and adjusts its position according to two factors; the first is its own experience and the second is the collective experience of the whole swarm. PSO has been successfully used to solve many optimization problems. In this work we use PSO to improve the performance of a well-known representation method of time series data which is the symbolic aggregate approximation (SAX). As with other time series representation methods, SAX results in loss of information when applied to represent time series. In this paper we use PSO to propose a new minimum distance WMD for SAX to remedy this problem. Unlike the original minimum distance, the new distance sets different weights to different segments of the time series according to their information content. This weighted minimum distance enhances the performance of SAX as we show through experiments using different time series datasets.",1 Dec 2012
249,Marwan Fuad,Towards normalizing the edit distance using a genetic algorithms-based scheme,https://pureportal.coventry.ac.uk/en/publications/towards-normalizing-the-edit-distance-using-a-genetic-algorithms-,"The normalized edit distance is one of the distances derived from the edit distance. It is useful in some applications because it takes into account the lengths of the two strings compared. The normalized edit distance is not defined in terms of edit operations but rather in terms of the edit path. In this paper we propose a new derivative of the edit distance that also takes into consideration the lengths of the two strings, but the new distance is related directly to the edit distance. The particularity of the new distance is that it uses the genetic algorithms to set the values of the parameters it uses. We conduct experiments to test the new distance and we obtain promising results.",1 Dec 2012
250,Marwan Fuad,Using differential evolution to set weights to segments with different information content in the piecewise aggregate approximation,https://pureportal.coventry.ac.uk/en/publications/using-differential-evolution-to-set-weights-to-segments-with-diff,"Time series mining handles several tasks such as classification, clustering and similarity search. These data are high-dimensional in nature so time series representation methods are widely used to reduce the dimensionality of these data so that they can be handled efficiently and effectively. One of the side effects of using representation methods is the loss of information which results from the dimensionality reduction implied in the representation methods. Several representation methods have pointed out that some regions in the times series may contain more information than others so a faithful representation method should be able to reflect the different information contents in different regions of a time series. One of the techniques that can be utilized for this purpose is to set different weights to different regions according to the information they contain, but the challenge is to find an objective scheme to set the weights. Differential evolution is an efficient optimizer that has been successfully used to solve many optimization problems, mainly continuous ones. In this paper we show how differential evolution can be used to set weights to different segments of time series according to their information content. Although our scheme establishes a fully functional time series representation method, with lower bounding distance and a dimensionality reduction technique, we consider this as a by-product of our work and our main aim is to show how the information contents of different time series segments can be reflected using unconventional methods such as the differential evolution. We compare the new scheme with the piecewise aggregate approximation as a method that completely lacks the ability to distinguish regions with high information from others with low information. We show how the new scheme can recover the loss of information caused by dimensionality reduction. We validate our scheme by experiments on different datasets.",Sept 2012
251,Marwan Fuad,Enhancing the symbolic aggregate approximation method using updated lookup tables,https://pureportal.coventry.ac.uk/en/publications/enhancing-the-symbolic-aggregate-approximation-method-using-updat,"Similarity search in time series data mining is a problem that has attracted increasing attention recently. The high dimensionality and large volume of time series databases make sequential scanning inefficient to tackle this problem. There are many representation techniques that aim at reducing the dimensionality of time series so that the search can be handled faster at a lower dimensional space level. Symbolic representation is one of the promising techniques, since symbolic representation methods try to benefit from the wealth of search algorithms used in bioinformatics and text mining communities. The symbolic aggregate approximation (SAX) is one of the most competitive methods in the literature. SAX utilizes a similarity measure that is easy to compute because it is based on pre-computed distances obtained from lookup tables. In this paper we present a new similarity measure that is almost as easy to compute as the original similarity measure, but it is tighter because it uses updated lookup tables. In addition, the new similarity measure is more intuitive than the original one. We conduct several experiments which show that the new similarity measure gives better results than the original one.",23 Nov 2010
252,Marwan Fuad,Fast retrieval of time series using a multi-resolution filter with multiple reduced spaces,https://pureportal.coventry.ac.uk/en/publications/fast-retrieval-of-time-series-using-a-multi-resolution-filter-wit,Fast retrieval of time series that are similar to a given pattern in large databases is a problem which has received a lot of attention in the last decade. The high dimensionality and large size of time series databases make sequential scanning inefficient to handle the similarity search problem. Several dimensionality reduction techniques have been proposed to reduce the complexity of the similarity search. Multi-resolution techniques are methods that speed-up the similarity search problem by economizing distance computations. In this paper we revisit two of previously proposed methods and present an improved algorithm that combine the advantages of these two methods. We conduct extensive experiments that show the show the superior performance of the improved algorithm over the previously proposed techniques.,21 Dec 2010
253,Marwan Fuad,Multi-resolution approach to time series retrieval,https://pureportal.coventry.ac.uk/en/publications/multi-resolution-approach-to-time-series-retrieval,"We propose a new multi-resolution indexing and retrieval method of the similarity search problem in time series databases. The proposed method is based on a fast-and-dirty filtering scheme that iteratively reduces the search space using several resolution levels. For each resolution level the time series are approximated by an appropriate function. The distance between the time series and the approximating function is computed and stored at indexing-time. At query-time, assigned filters use these precomputed distances to exclude wide regions of the search space, which do not contain answers to the query, using the least number of query-time distance computations. The resolution level is progressively increased to converge towards higher resolution levels where the exclusion power rises, but the cost of query-time distance computations also increases. The proposed method uses lower bounding distances, so there are no false dismissals, and the search process returns all the possible answers to the query. A post-processing scanning on the candidate response set is performed to filter out any false alarms and return the final response set. We present experimentations that compare our method with sequential scanning on different datasets, using different threshold values and different approximating functions. The experiments show that our new method is faster than sequential scanning by an order of magnitude.",15 Dec 2010
254,Marwan Fuad,Speeding-up the similarity search in time series databases by coupling dimensionality reduction techniques with a fast-and-dirty filter,https://pureportal.coventry.ac.uk/en/publications/speeding-up-the-similarity-search-in-time-series-databases-by-cou,In this paper we present a new generic frame that boosts the performance of different time series dimensionality reduction techniques by using a fast-and-dirty filter that we combine with the lower bounding condition of the dimensionality reduction technique to increase the pruning power. This fast-and-dirty filter is based on an optimal approximation of the segmented time series. The distances between these segmented time series and their approximating functions are computed and stored at indexing-time. This step is repeated using different resolution levels which correspond to different lengths of the segments. At query-time these pre-computed distances are utilized to prune those time series which are not similar to the given pattern using the least number of query-time distance computations. We conduct experiments that validate the theoretical basis of our proposed method.,11 Nov 2010
255,Marwan Fuad,Towards a faster symbolic aggregate approximation method,https://pureportal.coventry.ac.uk/en/publications/towards-a-faster-symbolic-aggregate-approximation-method,"The similarity search problem is one of the main problems in time series data mining. Traditionally, this problem was tackled by sequentially comparing the given query against all the time series in the database, and returning all the time series that are within a predetermined threshold of that query. But the large size and the high dimensionality of time series databases that are in use nowadays make that scenario inefficient. There are many representation techniques that aim at reducing the dimensionality of time series so that the search can be handled faster at a lower-dimensional space level. The symbolic aggregate approximation (SAX) is one of the most competitive methods in the literature. In this paper we present a new method that improves the performance of SAX by adding to it another exclusion condition that increases the exclusion power. This method is based on using two representations of the time series: one of SAX and the other is based on an optimal approximation of the time series. Pre-computed distances are calculated and stored offline to be used online to exclude a wide range of the search space using two exclusion conditions. We conduct experiments which show that the new method is faster than SAX.",1 Dec 2010
256,Marwan Fuad,Extending the edit distance using frequencies of common characters,https://pureportal.coventry.ac.uk/en/publications/extending-the-edit-distance-using-frequencies-of-common-character,"Similarity search of time series has attracted many researchers recently. In this scope, reducing the dimensionality of data is required to scale up the similarity search. Symbolic representation is a promising technique of dimensionality reduction, since it allows researchers to benefit from the richness of algorithms used for textual databases. To improve the effectiveness of similarity search we propose in this paper an extension to the edit distance that we call the extended edit distance. This new distance is applied to symbolic sequential data objects, and we test it on time series data bases in classification task experiments. We also prove that our distance is a metric.",7 Oct 2008
257,Marwan Fuad,The extended edit distance metric,https://pureportal.coventry.ac.uk/en/publications/the-extended-edit-distance-metric,"The problem of similarity search has attracted increasing attention recently, because it has many applications. Time series are high dimensional data objects. In order to utilize an indexing structure that can effectively handle large time series databases, we need to reduce the dimensionality of these data objects. One of the promising techniques of dimensionality reduction is symbolic representation, which allows researchers to avail from the wealth of text-retrieval algorithms and techniques. To improve the effectiveness of similarity search we propose an extension to the well-known edit distance that we call the extended edit distance. This new distance is applied to symbolic sequential data objects. We test the proposed distance on time series data bases in classification task experiments. We also compare it to other distances that are well known in the literature for symbolic data objects, and we also prove, mathematically, that our new distance is metric",15 Aug 2008
258,Daniel Goldsmith,Platform as a service gateway for the Fog of Things,https://pureportal.coventry.ac.uk/en/publications/platform-as-a-service-gateway-for-the-fog-of-things-2,"Internet of Things (IoT), one of the key research topics in recent years, together with concepts from Fog Computing, brings rapid advancements in Smart City, Monitoring Systems, industrial control, transportation and other fields. These applications require a reconfigurable sensor architecture that can span multiple scenarios, devices and use cases that allow storage, networking and computational resources to be efficiently used on the edge of the network. There are a number of platforms and gateway architectures that have been proposed to manage these components and enable application deployment. These approaches lack horizontal integration between multiple providers as well as higher order functionalities like load balancing and clustering. This is partly due to the strongly coupled nature of the deployed applications, a lack of abstraction of device communication layers as well as a lock-in for communication protocols. This limitation is a major obstacle for the development of a protocol agnostic application environment that allows for single application to be migrated and to work with multiple peripheral devices with varying protocols from different local gateways. This research looks at existing platforms and their shortcomings as well as proposes a messaging based modular gateway platform that enables clustering of gateways and the abstraction of peripheral communication protocol details. These novelties allow applications to send and receive messages regardless of their deployment location and destination device protocol, creating a more uniform development environment. Furthermore, it results in a more streamlined application development and testing while providing more efficient use of the gateway’s resources. Our evaluation of a prototype for the system shows the need for the migration of resources and the QoS advantages of such a system. The examined use case scenarios show that clustering proves to be an advantage in certain use cases as well as presenting the deployment of a larger testing and control environment through the platform.Publisher Statement: NOTICE: this is the author’s version of a work that was accepted for publication in Advanced Engineering Informatics. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may have been made to this work since it was submitted for publication. A definitive version was subsequently published in Advanced Engineering Informatics, [33, (2016)] DOI: 10.1016/j.aei.2016.11.003© 2016, Elsevier. Licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International http://creativecommons.org/licenses/by-nc-nd/4.0/",Aug 2017
259,Daniel Goldsmith,Cool to Warm Up? Understanding Student Energy Behaviour In Indonesian University Buildings.,https://pureportal.coventry.ac.uk/en/publications/cool-to-warm-up-understanding-student-energy-behaviour-in-indones-2,"We report on a study at Universitas Indonesia’s Computing Department, where there is interest in students’ contributions to energy reduction, particularly related to use of air conditioning (AC). We ran a survey with 190 students, complemented by environmental monitoring together with observational work, to understand energy attitudes and behaviour in order to draw implications on potential behaviour change interventions. While students showed much interest in ecological issues there was much lower awareness of impacts of the use of appliances, and no observed energy-saving action by students. Thus, while attitudes supporting behaviour change appear to be in place, this is not yet translating into action. Drawing on Social Practice Theory (SPT, Shove et al, 2012), we propose that this is to do with absence of salience (energy use is not the key focus of student activity), together with absence of licence (students appear not to feel they are permitted). We draw implications for future behaviour change work amongst the Indonesian student body centring on energy-saving AC use.",2015
260,Daniel Goldsmith,Edge mining the internet of things,https://pureportal.coventry.ac.uk/en/publications/edge-mining-the-internet-of-things-2,"This paper examines the benefits of edge mining – data mining that takes place on the wireless, battery-powered smart sensing devices that sit at the edge points of the Internet of Things. Through local data reduction and transformation, edge mining can quantifiably reduce the number of packets that must be sent, reducing energy usage and remote storage requirements. Additionally, edge mining has the potential to reduce the risk to personal privacy through embedding of information requirements at the sensing point, limiting inappropriate use. The benefits of edge mining are examined with respect to three specific algorithms: Linear Spanish Inquisition Protocol (L-SIP), ClassAct, and Bare Necessities (BN), which are all instantiations of the General SIP (G-SIP). In general, the benefits provided by edge mining are related to the predictability of data streams and availability of precise information requirements; results show that L-SIP typically reduces packet transmission by around 95% (20-fold), BN reduces packet transmission by 99.98% (5000-fold) and ClassAct reduces packet transmission by 99.6% (250-fold). Although energy reduction is not as radical due to other overheads, minimisation of these overheads can lead to up to a 10-fold battery life extension for L-SIP, for example. These results demonstrate the importance of edge mining to the feasibility of many IoT applications.

",2013
261,Daniel Goldsmith,Virtual sensors to improve on-line hydraulic model calibration,https://pureportal.coventry.ac.uk/en/publications/virtual-sensors-to-improve-on-line-hydraulic-model-calibration,"A new approach for monitoring a water distribution system involving Virtual Sensors is presented. In this approach, wireless sensor nodes are permanently deployed within the distribution system, providing continuous, on-line hydraulic data that can be assimilated into hydraulic models. In addition, temporary nodes are deployed for short periods (one week) around the distribution network. A Virtual Sensor is implemented using a data imputation technique called Gaussian Process Regression, which combines the historical data collected by the temporary node with correlated data from a subset of permanent sensor nodes. Use of spatially-correlated data accounts for new trends in the data that do not appear in the historical data collected by the temporary node. An increase in the number of sensors (a combination of real and virtual) is important for reducing the ill-conditioned state of the hydraulic model calibration procedure. The technique is demonstrated as a proof-of-concept using data collected from the WaterWiSe@SG testbed in Singapore, and is shown to predict pressure data trends with an accuracy of 0.76 PSI RMSE after a six-week test.",2012
262,Daniel Goldsmith,WaterWiSe@SG: A testbed for continuous monitoring of the water distribution system in Singapore,https://pureportal.coventry.ac.uk/en/publications/waterwisesg-a-testbed-for-continuous-monitoring-of-the-water-dist,"This paper describes the development of WaterWiSe@ SG, a wireless sensor network to enable real-time monitoring of a water distribution network in Singapore. The overall project is directed towards three main goals: 1) the application of a low cost wireless sensor network for high data rate, on-line monitoring of hydraulic parameters within a large urban water distribution system; 2) the development of systems to enable remote detection of leaks and prediction of pipe burst events; 3) the integrated monitoring of hydraulic and water quality parameters. In this paper we will describe the current state of the WaterWiSe@SG testbed, and report on experimentation we have performed with respect to leak detection and localization. Furthermore, we describe how we have assimilated real time pressure and flow measurements from the sensor network into hydraulic models that are used to improve state estimation for the network. Finally, we discuss the future plans for the project.",2012
263,Daniel Goldsmith,The Spanish Inquisition Protocol—Model based transmission reduction for wireless sensor networks,https://pureportal.coventry.ac.uk/en/publications/the-spanish-inquisition-protocolmodel-based-transmission-reductio-2,"The Spanish Inquisition Protocol (SIP) reduces Wireless Sensor Network (WSN) energy cost by transmitting only unexpected information and is so-named because ""nobody expects the Spanish Inquisition!"" SIP extends prior Dual Prediction Scheme (DPS) algorithms that model phenomena at both node and sink. SIP's key advancement is that it transmits a state vector estimate rather than individual readings. SIP can be tuned according to the desired estimate accuracy, with lower desired accuracy typically leading to fewer transmitted packets. In simulation with real data, less than 5% of the samples needed to be transmitted to provide the sink with an accurate estimate of the sensor value (within 0.5°C, in the case of temperature). SIP also significantly outperforms prior DPS results when using the same data sets. In deployment on Telos motes, SIP shows similar performance to the simulations.

",2010
264,Daniel Goldsmith,FieldMAP: a spatiotemporal field monitoring application prototyping framework,https://pureportal.coventry.ac.uk/en/publications/fieldmap-a-spatiotemporal-field-monitoring-application-prototypin-2,"The fundamental aim of monitoring is to identify abnormalities in the observed phenomena and allow inference of the likely cause. Faced with the common problems of spatially irregular sensor distribution and intermittent sensor measurement availability, key to fulfilling the monitoring aim is filling in the spatiotemporal gaps in the data. While wireless sensor networks (WSNs) technology, combined with microelectromechanical systems availability potentially offer sensing solutions for a variety of application domains, in the context of monitoring applications a conceptual shift is needed from currently available, point-measurement-based ldquosense-and-sendrdquo systems toward the provision of phenomena field representations, in real time, enabling effective visualization of the spatiotemporal patterns. This paper argues the case for a generic, rapid prototyping framework for end-to-end sensing systems that support the approach of providing field representations for visualization. A formal approach to framework development was taken, ensuring that resulting instrumentation systems are well specified. Both the framework development and its evaluation are linked to the full cycle of requirements setting, design, and deployment of a prototype instrumentation system for aerospace applications-specifically, health monitoring of a gas turbine engine. The field monitoring application prototyping (FieldMAP) framework supports multimodal sensing, provides a number of opportunities for data processing and information extraction, caters for monitoring of the instrumentation health, offers a modular field-mapping design component and allows for real-time phenomena visualization, data and information logging, and postanalysis. Experience with the FieldMAP has shown that sophisticated and robust prototypes can be developed in a short period of time.

",Nov 2009
265,Daniel Goldsmith,Performance analysis of a prototype wireless monitoring system for a gas turbine,https://pureportal.coventry.ac.uk/en/publications/performance-analysis-of-a-prototype-wireless-monitoring-system-fo-2,"The report describes the design, development and evaluation of an end-to-end wireless monitoring system “table-top” demonstrator. The system is dedicated to gas flow temperature monitoring for gas turbine engines used in aerospace applications. The demonstrator was built with off-the-shelf hardware components, in-house produced interface boards, and software developed by the authors here. The demonstrator was evaluated in terms of: its added informational value compared with existing wired thermocouple harnesses, the performance of the wireless network, and the power consumption of the wireless nodes.",2009
266,Daniel Goldsmith,Wireless sensor networks for aerospace applications- thermal monitoring for a gas turbine engine,https://pureportal.coventry.ac.uk/en/publications/wireless-sensor-networks-for-aerospace-applications-thermal-monit-2,"The paper here reports on the development of a prototype wireless sensor network for thermal monitoring of aircraft gas turbine engines. The prototype acts as a concept demonstrator for the application at hand. Building upon the state of the art in the domain, the authors pursued a rapid prototyping approach, supported by a base prototyping framework - FieldMAP. As a key property, the framework enables the conceptual shift from data to user relevant information. Consequently, an information extraction and visualisation component is put forward as an addition to traditional “sense and send” WSN systems. The component offers an intuitive approach to user understanding of the global evolution of the observed phenomena. Integrated within the prototype, this component makes use of the processing power available within the WSN coupled with interpolation algorithms borrowed from the geosciences domain. Reconstruction of field representations of the phenomena from the sparse sensed data allows identification of abnormalities and inference of their likely cause.

",2009
267,Daniel Goldsmith,Augmented reality environmental monitoring using wireless sensor networks,https://pureportal.coventry.ac.uk/en/publications/augmented-reality-environmental-monitoring-using-wireless-sensor--2,,2008
268,Daniel Goldsmith,Prototype of a wireless monitoring system for a gas turbine engine,https://pureportal.coventry.ac.uk/en/publications/prototype-of-a-wireless-monitoring-system-for-a-gas-turbine-engin-2,"A critical aspect of modern condition-based maintenance (CBM) systems is the provision of detailed, accurate and reliable sensing for the part, or subsystem under observation. Existing thermocouple based flow sensing systems for gas turbine engines deal effectively with the multipoint measurement of the high temperatures involved, however, due to the need for low added weight, they only provide averaged temperature data over a single heavy duty cable. The conflicting measurement system requirements of low weight and detailed, high rate, robust, multipoint measurement can be mitigated through the use of wire-less instrumentation. This technical report describes a prototype system that explores the use of multiple wirelessly networked sensors to deliver detailed spatial-temporal flow temperature information to enable CBM and enhance informational output from engine testing.",Sept 2008
269,Daniel Goldsmith,Wireless instrumentation for aerospace applications—thermal monitoring for a gas turbine engine,https://pureportal.coventry.ac.uk/en/publications/wireless-instrumentation-for-aerospace-applicationsthermal-monito-2,"Rolls-Royce are pioneers in the concept of “power-by-the-hour”, whereby they no longer sell gas turbine engines and leave maintenance and spare parts costs to the customer but rather sell a service agreement to provide thrust on an hours of use basis. This approach has reoriented engine manufacturers from selling spare parts to trying to maximise each engine’s longevity. This reorientation has introduced a new emphasis on sensing and monitoring. An example is the temperature sensors harness developed by Vibro Meter UK, a wholly owned subsidiary of Meggit Plc. Their thermocouple probes are able to withstand the high temperatures found within the gas stream. In principle, the large number of thermocouple sensors mounted within the engine could provide detailed thermal maps and thus provide for accurate diagnosis of potential problems before they occur. A difficulty, however, is that sending all the individual sensor data back to the control unit would require a large amount of heavy duty cabling, thus significantly increasing the weight of the engine. To avoid this, sensor values are averaged, and only a single cable is used.
Even a single cable may be more than is necessary, however. By making use of wireless technology, low-power electronics, and advanced visualisation techniques researchers at Coventry University’s Cogent Computing Applied Research Centre (CCARC), are developing a system to wirelessly connect the high temperature thermocouples and perhaps other sensors on the gas turbine engine. Furthermore, they are looking at developing visualisation tools to ensure that the much more detailed gathered data can be easily interpreted. It is hoped that the development of such a wireless sensing system will lead to several important benefits: it will reduce the weight of the engine; it will allow a detailed map of temperatures within the gas flow of the engine to be obtained; it will allow sensor faults to be detected more readily.",2008
270,Daniel Goldsmith,Sense-enabled mixed reality museum exhibitions,https://pureportal.coventry.ac.uk/en/publications/sense-enabled-mixed-reality-museum-exhibitions-2,,2007
271,Beate Grawemeyer,Feedback and Engagement on an Introductory Programming Module,https://pureportal.coventry.ac.uk/en/publications/feedback-and-engagement-on-an-introductory-programming-module,"We ran a study on engagement and achievement for a first year undergraduate programming module which  used an online learning environment containing tasks which generate automated feedback.  Students could also access human feedback from traditional labs. We gathered quantitative data on engagement and achievement which allowed us to split the cohort into 6 groups.  We then ran interviews with students after the end of the module to produce qualitative data on perceptions of what feedback is, how useful it is, the uses made of it, and how it bears on engagement. A general finding was that human and automated feedback are different but complementary. However there are different feedback needs by group. Our findings imply: (1) that a blended human-automated feedback approach improves engagement; and (2) that this approach needs to be differentiated according to type of student. We give implications for the design of feedback for programming modules. ",6 Jan 2022
272,Beate Grawemeyer,Social Explainability of AI: The Impact of Non-Technical Explanations on Trust,https://pureportal.coventry.ac.uk/en/publications/social-explainability-of-ai-the-impact-of-non-technical-explanati,"In striving for explainable AI, it is not necessarily technical understanding that will maximise perceived transparency and trust. Most of us board planes with little understanding about how the plane works, and without knowing the pilot, be-cause we put trust in the regulatory and authoritative systems that govern the people and processes. By providing knowledge of the governing ecosystem, industries like aviation and engineering have built stable trust with everyday people. This is known as “social explainability.” We extend this concept to AI systems using a series of ""social"" explanations designed with users (based on external certification of the system, data security and privacy). Core research questions are: Do social explanations, purely technical explanations, or a combination of the two, predict greatest trust from users? Does this depend on digital literacy of the user? An interaction between explanation type and digital literacy reveals that more technical information predicts higher trust from those with higher digital literacy, but those of lower digital literacy given purely technical explanations have the worst trust overall. For this group, social explainability works best. Overall, combined socio-technical explanations appear more successful in building trust than purely social explanations. As in other areas, social explainability may be a useful tool for building stable trust for non-experts in AI systems.",23 Jul 2022
273,Beate Grawemeyer,When the Going Gets Tough: Students’ Perceptions on Affect-Aware Support in an Exploratory Learning Environment for Fractions,https://pureportal.coventry.ac.uk/en/publications/when-the-going-gets-tough-students-perceptions-on-affect-aware-su,"It is well understood that affect interacts with and influences the learning process [2, 7, 9]. The impact of affect on learning is not straightforward. For example, D’Mello et al. explore how confusion, which superficially might be considered a negative affective state, is likely to promote learning under appropriate conditions [3]. In addition, the way the students perceive the tasks and the support they receive can impact their experience, agency and self-efficacy  which in turn has been shown to relate to persistence and long-term outcomes [1]. It is important therefore, to deepen our understanding of the role of affect in learning in general and in particular students’ perceptions of their own learning with digital environments that provide feedback.In previous work [4] we described the development of affect-aware support and the effect of such support in relation to learning during a whole classroom intervention with a sequence of fraction learning tasks within the iTalk2Learn platform. In contrast, in this paper, we report on a study that asked students to self-report their affective states while undertaking fractions tasks.",26 Jul 2022
274,Beate Grawemeyer,Design and evaluation of adaptive feedback to foster ICT information processing skills in young adults,https://pureportal.coventry.ac.uk/en/publications/design-and-evaluation-of-adaptive-feedback-to-foster-ict-informat,"This paper explores the provision of adaptive hints based on attainment levels in the context of supporting the development of young adults' ICT information processing skills. We describe the design of the LIBE VLE, particularly its personalisation and adaptation features, and a User Study undertaken with young adults at a vocational education centre. Using data collected through the LIBE VLE, we anal-yse the relationships between learners' accessing of hints, motivation, and performance. Results point to a positive effect of accessing of hints on students' perception of the LIBE VLE and their likelihood of using it again for further learning; and also a positive effect of students' interest in the course subject on their engagement and performance in course activities. These findings have important implications for supporting young adults in developing key competences necessary for integration into the workforce and for fostering self-regulated lifelong learning.",1 Jan 2019
275,Beate Grawemeyer,The impact of affect-aware support on learning tasks that differ in their cognitive demands,https://pureportal.coventry.ac.uk/en/publications/the-impact-of-affect-aware-support-on-learning-tasks-that-differ-,"This paper investigates the effect of affect-aware support on learning tasks that differ in their cognitive demands. We conducted a study with the iTalk2learn platform where students are undertaking fractions tasks of varying difficulty and assigned in one of two groups; one group used the iTalk2learn platform that included the affect-aware support, whereas in the other group the affect-aware support was switched off and support was provided based on students’ performance only. We investigated the hypothesis that affect-aware support has a more pronounced effect when the cognitive demands of the tasks are higher. The results suggest that students that undertook the more challenging tasks were significantly more in-flow and less confused in the group where affect-aware support was provided than students who were supported based on their performance only.",20 Jun 2018
276,Beate Grawemeyer,Affective learning: improving engagement and enhancing learning with affect-aware feedback,https://pureportal.coventry.ac.uk/en/publications/affective-learning-improving-engagement-and-enhancing-learning-wi,"This paper describes the design and ecologically valid evaluation of a learner model that lies at the heart of an intelligent learning environment called iTalk2Learn. A core objective of the learner model is to adapt formative feedback based on students’ affective states. Types of adaptation include what type of formative feedback should be provided and how it should be presented. Two Bayesian networks trained with data gathered in a series of Wizard-of-Oz studies are used for the adaptation process. This paper reports results from a quasi-experimental evaluation, in authentic classroom settings, which compared a version of iTalk2Learn that adapted feedback based on students’ affective states as they were talking aloud with the system (the affect condition) with one that provided feedback based only on the students’ performance (the non-affect condition). Our results suggest that affect-aware support contributes to reducing boredom and off-task behavior, and may have an effect on learning. We discuss the internal and ecological validity of the study, in light of pedagogical considerations that informed the design of the two conditions. Overall, the results of the study have implications both for the design of educational technology and for classroom approaches to teaching, because they highlight the important role that affect-aware modelling plays in the adaptive delivery of formative feedback to support learning.",1 Mar 2017
277,Beate Grawemeyer,Exploring students’ affective states during learning with external representations,https://pureportal.coventry.ac.uk/en/publications/exploring-students-affective-states-during-learning-with-external,"We conducted a user study that explored the relationship between students’ usage of multiple external representations and their affective states during fractions learning. We use the affective states of the student as a proxy indicator for the ease of reasoning with the representation. Extending existing literature that highlights the advantages of learning with multiple external representations, our results indicate that low-performing students have difficulties in reasoning with representations that do not fully accommodate the fraction as a part-whole concept. In contrast, high-performing students were at ease with a range of representations, including the ones that vaguely involved the fraction as part-whole concept.",23 Jun 2017
278,Beate Grawemeyer,Using Graph-based Modelling to explore changes in students’ affective states during exploratory learning tasks,https://pureportal.coventry.ac.uk/en/publications/using-graph-based-modelling-to-explore-changes-in-students-affect,"We describe a graph-based modelling approach to exploring interactions associated with a change in students’ affective state when they are working with an exploratory learning environment (ELE). Student-system interactions data collected during a user study was modelled, visualized and queried as a graph. Our findings provide new insights into how students are interacting with the ELE and the effects of the system’s interventions on students’ affective states.",1 Jan 2017
279,Beate Grawemeyer,Affecting Off-Task Behaviour: How Affect-aware feedback can improve student learning,https://pureportal.coventry.ac.uk/en/publications/affecting-off-task-behaviour-how-affect-aware-feedback-can-improv,"This paper describes the development and evaluation of an affect-aware intelligent support component that is part of a learning environment known as iTalk2Learn. The intelligent support component is able to tailor feedback according to a student's affective state, which is deduced both from speech and interaction. The affect prediction is used to determine which type of feedback is provided and how that feedback is presented (interruptive or non-interruptive). The system includes two Bayesian networks that were trained with data gathered in a series of ecologically-valid Wizard-of-Oz studies, where the effect of the type of feedback and the presentation of feedback on students' affective states was investigated. This paper reports results from an experiment that compared a version that provided affect-aware feedback (affect condition) with one that provided feedback based on performance only (non-affect condition). Results show that students who were in the affect condition were less bored and less off-task, with the latter being statically significant. Importantly, students in both conditions made learning gains that were statistically significant, while students in the affect condition had higher learning gains than those in the non-affect condition, although this result was not statistically significant in this study's sample. Taken all together, the results point to the potential and positive impact of affect-aware intelligent support.",25 Apr 2016
280,Beate Grawemeyer,"It ain't what you do, it's the way that you do it: Investigating the effect of students' active and constructive interactions with fractions representations",https://pureportal.coventry.ac.uk/en/publications/it-aint-what-you-do-its-the-way-that-you-do-it-investigating-the-,"We show that not only the number of fractions representations but also the way how students interact with (multiple) representations is important for their conceptual understanding of fractions. We found that a combination of students' constructive and active interaction (e.g., manipulating and constructing representations) with multiple fractions representations as compared to students' active interaction (e.g., looking at representations) with multiple representations leads to higher conceptual knowledge measured by students' ability to flexibly represent a fraction. Furthermore, students' representational flexibility was correlated with their general learning performance when students' interacted constructively and actively with representations but not when they interacted only actively with representations. In line with the ICAP-framework we conclude that active interactions trigger more intensively attending processes whereas constructive interactions trigger more intensively creating processes and are thus superior to the first kind of students' cognitive engagement with multiple representations.",1 Jan 2016
281,Beate Grawemeyer,Adapting feedback types according to students’ affective states,https://pureportal.coventry.ac.uk/en/publications/adapting-feedback-types-according-to-students-affective-states,"Affective states play a significant role in students’ learning behaviour. Positive affective states can enhance learning, while negative ones can inhibit it. This paper describes the development of an affective state reasoner that is able to adapt the feedback type according to students’ affective states in order to evoke positive affective states and as such improve their learning experience. The reasoner relies on a dynamic Bayesian network trained with data gathered in a series of ecologically valid Wizard-of-Oz studies, where the effect of feedback on students’ affective states was investigated.",17 Jun 2015
282,Beate Grawemeyer,Affect matters: Exploring the impact of feedback during mathematical tasks in an exploratory environment,https://pureportal.coventry.ac.uk/en/publications/affect-matters-exploring-the-impact-of-feedback-during-mathematic,We describe a Wizard-of-Oz study that investigates the impact of different types of feedback on students’ affective states. Our results indicate the importance of matching carefully the affective state with appropriate feedback in order to help students transition into more positive states. For example when students were confused affect boosts and specific instruction seem to be effective in helping students to be in flow again. We discuss this and other effective ways to and implications for the development of our system and the field in general,17 Jun 2015
283,Beate Grawemeyer,Can young people with autism spectrum disorder benefit from an open learner model?,https://pureportal.coventry.ac.uk/en/publications/can-young-people-with-autism-spectrum-disorder-benefit-from-an-op,"This paper describes the evaluation of Maths Island Tutor - an intelligent tutoring system for children with autism spectrum disorder (ASD). The tutor includes an open learner model (OLM). In order to benefit from this feature, the learner needs to be able to process metacognitive attributes, which can be impaired in ASD. In order to address the needs of this specific population, young people with ASD were involved in the design of the software for their use, including the OLM. A preliminary study evaluating the system demonstrated that young people with ASD did initiate access to their OLM, could correctly reproduce details from their OLM, and could also highlight the location of (study-intended) errors within their OLMs giving rise to suggestions about their abilities to remember and potentially meta-cognitively reflect on their learning.",17 Jun 2015
284,Beate Grawemeyer,Deficits in metacognitive monitoring in mathematics assessments in learners with autism spectrum disorder,https://pureportal.coventry.ac.uk/en/publications/deficits-in-metacognitive-monitoring-in-mathematics-assessments-i,"Children and adults with autism spectrum disorder have been found to have deficits in metacognition that could impact upon their learning. This study explored metacognitive monitoring in 28 (23 males and 5 females) participants with autism spectrum disorder and 56 (16 males and 40 females) typically developing controls who were being educated at the same level. Participants were asked a series of mathematics questions. Based upon previous research, after each question they were asked two metacognitive questions: (1) whether they thought they had got the answer correct or not (or 'don't know') and (2) whether they meant to get the answer correct or not (or 'don't know'). Participants with autism spectrum disorder were significantly more likely than the typically developing group to erroneously think that they had got an incorrect answer correct. Having made an error, those with autism spectrum disorder were also significantly more likely to report that they had meant to make the error. Different patterns in the types of errors made were also identified between the two groups. Deficits in metacognition were identified for the autism spectrum disorder group in the learning of mathematics. This is consistent with metacognitive research from different contexts and the implications for supporting learning in autism spectrum disorder are discussed.",1 Jan 2015
285,Beate Grawemeyer,"International workshop on affect, meta-affect, data and learning (AMADL 2015)",https://pureportal.coventry.ac.uk/en/publications/international-workshop-on-affect-meta-affect-data-and-learning-am,,1 Jan 2015
286,Beate Grawemeyer,Light-bulb moment? Towards adaptive presentation of feedback based on students' affective state,https://pureportal.coventry.ac.uk/en/publications/light-bulb-moment-towards-adaptive-presentation-of-feedback-based,"Affective states play a significant role in students' learning behaviour. Positive affective states can enhance learning, whilst negative affective states can inhibit it. This paper describes a Wizard-of-Oz study which investigates whether the way feedback is presented should change according to the affective state of a student, in order to encourage affect change if that state is negative. We presented high-interruptive feedback in the form of pop-up windows in which messages were immediately viewable; or low-interruptive feedback, a glowing light bulb which students needed to click in order to access the messages. Our results show that when students are confused or frustrated high-interruptive feedback is more effective, but when students are enjoying their activity, there is no difference. Based on the results, we present guidelines for adaptively tailoring the presentation of feedback based on students' affective states when interacting with learning environments.",1 Jan 2015
287,Beate Grawemeyer,Preface,https://pureportal.coventry.ac.uk/en/publications/preface-10,,1 Jan 2015
288,Beate Grawemeyer,Preface,https://pureportal.coventry.ac.uk/en/publications/preface-9,,1 Jan 2015
289,Beate Grawemeyer,Purpose and level of feedback in an exploratory learning environment for fractions,https://pureportal.coventry.ac.uk/en/publications/purpose-and-level-of-feedback-in-an-exploratory-learning-environm,"This paper reports on our progress on a systematic approach to operationalizing support in Fractions Lab – an exploratory learning environment for learning fractions in primary education. In particular, we focus on the question of what feedback to provide and consider in detail the implementation of feedback according to two dimensions: the purpose of the feedback, depending on the task-specific needs of the student, and the level of feedback, depending on the cognitive needs of the student. We present early findings from our design-based research that includes Wizard-of-Oz studies of the intelligent feedback system and student perception questionnaires.",1 Jan 2015
290,Beate Grawemeyer,Robust student knowledge: Adapting to individual student needs as they explore the concepts and practice the procedures of fractions,https://pureportal.coventry.ac.uk/en/publications/robust-student-knowledge-adapting-to-individual-student-needs-as-,"Robust knowledge consists of both conceptual and procedural knowledge. In order to address both types of knowledge, offering students opportunities to explore target concepts in an exploratory learning environment (ELE) is insufficient. Instead, we need to combine exploratory learning environments, to support students acquisition of conceptual knowledge, with more structured learning environments that allow students to practice problem-solving procedures step-by-step, to support students' acquisition of procedural knowledge. However, how best to combine both kinds of learning environments and thus both types of learning activities is an open question. We have developed a pedagogical intervention model that selects and sequences learning activities, exploratory learning activities and structured practice activities, that are appropriate for the individual learner. Technically, our intervention model is implemented as a rule-based system in a learning platform about fractions. The model's decisionmaking process relies on the detection of each individual student's level of challenge (i.e. whether they were under-, appropriately or over-challenged by the previous learning activity). Thus, our model adapts flexibly to each individual student's needs and provides them with a unique sequence of learning activities. Our formative evaluation trials suggest that single components of the intervention model, such as the ELE, mostly achieve their aims. The interplay between the different components of the intervention model (i.e. the outcomes of sequencing and selecting exploratory and structured practice activities) is currently being evaluated.",1 Jan 2015
291,Beate Grawemeyer,"Talk, tutor, explore, learn: Intelligent tutoring and exploration for robust learning",https://pureportal.coventry.ac.uk/en/publications/talk-tutor-explore-learn-intelligent-tutoring-and-exploration-for,"It is widely acknowledged that many children have difficulty learning fractions. Accordingly, we are developing the iTalk2Learn system (www. italk2learn.eu), which aims to facilitate the robust learning of fractions by children in primary and early secondary education. The iTalk2 Learn system integrates structured, practice-based tasks with exploratory, conceptually-oriented tasks, and intelligent affect-aware support. The system focus seson natural interaction via intuitive user interfaces, which includes speech recognition, and speech production.",1 Jan 2015
292,Beate Grawemeyer,The impact of feedback on students' affective states,https://pureportal.coventry.ac.uk/en/publications/the-impact-of-feedback-on-students-affective-states-2,"Affective states play a significant role in students' learning behaviour. Positive affective states can enhance learning, while negative affective states can inhibit it. This paper describes a Wizard-of-Oz study that investigates the impact of different types of feedback on students' affective states. Our results indicate the importance of providing feedback matched carefully to the affective state of the students in order to help them transition into more positive states. For example when students were confused affect boosts and specific instructive feedback seem to be effective in helping students to be in ow again. We discuss this and other ways to adapt the feedback, together with implications for the development of our system and the field in general.",Jun 2015
293,Beate Grawemeyer,The impact of feedback on students' affective states,https://pureportal.coventry.ac.uk/en/publications/the-impact-of-feedback-on-students-affective-states,"Affective states play a significant role in students' learning behaviour. Positive affective states can enhance learning, while negative affective states can inhibit it. This paper describes a Wizard-of-Oz study that investigates the impact of different types of feedback on students' affective states. Our results indicate the importance of providing feedback matched carefully to the affective state of the students in order to help them transition into more positive states. For example when students were confused affect boosts and specific instructive feedback seem to be effective in helping students to be in flow again. We discuss this and other ways to adapt the feedback, together with implications for the development of our system and the field in general.",Jun 2015
294,Beate Grawemeyer,Employing speech to contribute to modelling and adapting to students' affective states,https://pureportal.coventry.ac.uk/en/publications/employing-speech-to-contribute-to-modelling-and-adapting-to-stude,"Affect plays a significant role in students' learning behaviour. Positive affective states can enhance learning, while negative ones can inhibit it. This paper describes how we provide intelligent support in a learning platform based on affect states. We discuss two components: an affective state detector to perceive affective states in speech during interaction with the platform; and an affective state reasoner to provide support, which aims at aligning the learner's personal goal with the learning task to evoke positive affective states for an enhanced learning experience.",1 Jan 2014
295,Beate Grawemeyer,Exploring the potential of speech recognition to support problem solving and reflection: Wizards go to school in the elementary maths classroom,https://pureportal.coventry.ac.uk/en/publications/exploring-the-potential-of-speech-recognition-to-support-problem-,"The work described in this paper investigates the potential of Automatic Speech Recognition (ASR) to support young children's exploration and reflection as they are working with interactive learning environments. We describe a unique ecologically valid Wizard-of-Oz (WoZ) study in a classroom equipped with computers, two of which were set up to allow human facilitators (wizards) to listen to students thinking-aloud while having access to their interaction with the environment. The wizards provided support using a script and following an iterative methodology that limited on purpose their communication capacity in order to simulate the actual system. Our results indicate that the feedback received from the wizards did serve its function i.e. it helped modify students' behaviour in that they did think-aloud significantly more than in past interactions and rephrased their language to employ mathematical terminology. Additional results from student perception questionnaires show that overall students find the system suggestions helpful, not repetitive and understandable. Most also enjoy thinking aloud to the computer but, as expected, some find the feedback cognitively overloading, indicating that more work is needed on how to design the interaction tipping the balance towards facilitating post-task reflection.",1 Jan 2014
296,Beate Grawemeyer,"Interventions during student multimodal learning activities: Which, and why?",https://pureportal.coventry.ac.uk/en/publications/interventions-during-student-multimodal-learning-activities-which,"Emotions play a significant role in students' learning behaviour. Positive emotions can enhance learning, whilst negative emotions can inhibit it. This paper describes a Wizard-of-Oz (WoZ) study which investigates the potential of Automatic Speech Recognition (ASR) together with an emotion detector able to classify emotions from speech to support young children in their exploration and reection whilst working with interactive learning environments. We describe a unique ecologically valid WoZ study in a class- room. During the study the wizards provided support using a script, and followed an iterative methodology which limited their capacity to communicate, in order to simulate the real system we are developing. Our results indicate that there is an effect of emotions on the acceptance of feedback. Additionally, certain types of feedback are more effective than others for particular emotions.",1 Jan 2014
297,Beate Grawemeyer,Developing an embodied pedagogical agent with and for young people with autism spectrum disorder,https://pureportal.coventry.ac.uk/en/publications/developing-an-embodied-pedagogical-agent-with-and-for-young-peopl,"This paper describes how we developed an embodied pedagogical agent (EPA) with and for young people with autism spectrum disorder (ASD). ASD is characterised by impairments in social communication, imagination, and perspective-taking, which can compromise design and collaboration. However, if an ASD preference for visual processing can be supported by providing images of design ideas as they develop, these difficulties may be overcome. We describe a methodology that successfully supports the visualisation and development of EPAs using our prototype visualisation tool (EPA DK), enabling ASD users to function as active design participants.",22 Jun 2012
298,Beate Grawemeyer,Developing IDEAS: Supporting children with Autism within a participatory design team,https://pureportal.coventry.ac.uk/en/publications/developing-ideas-supporting-children-with-autism-within-a-partici,"IDEAS (Interface Design Experience for the Autistic Spectrum) is a method for involving children with Autism Spectrum Disorders (ASD) in the technology design process. This paper extends the IDEAS method to enable use with a design team, providing specific added support for communication and collaboration difficulties that may arise. A study to trial this extended method was conducted with two design teams, each involving three children with ASD, in a series of six, weekly design sessions focused on designing a math game. The findings from this study reveal that the children were able to successfully participate in the sessions and collaborate with other children. The findings also highlight the positive experience that involvement in such a process can offer this population.",24 May 2012
299,Beate Grawemeyer,Rational security: Modelling everyday password use,https://pureportal.coventry.ac.uk/en/publications/rational-security-modelling-everyday-password-use,"To inform the design of security policy, task models of password behaviour were constructed for different user groups - Computer Scientists, Administrative Staff and Students. These models identified internal and external constraints on user behaviour and the goals for password use within each group. Data were drawn from interviews and diaries of password use. Analyses indicated password security positively correlated with the sensitivity of the task, differences in frequency of password use were related to password security and patterns of password reuse were related to knowledge of security. Modelling revealed Computer Scientists viewed information security as part of their tasks and passwords provided a way of completing their work. By contrast, Admin and Student groups viewed passwords as a cost incurred when accessing the primary task. Differences between the models were related to differences in password security and used to suggest six recommendations for security officers to consider when setting password policy.",1 Jun 2012
300,Beate Grawemeyer,IDEAS: An interface design experience for the autistic spectrum,https://pureportal.coventry.ac.uk/en/publications/ideas-an-interface-design-experience-for-the-autistic-spectrum,"Designing products and services to meet the specific requirements of children with Autism Spectrum Disorder (ASD) can be difficult due to their wide ranging and individual needs. Participatory Design (PD) is a design method that could be used to better meet these needs, by giving this population an opportunity to. directly contribute to software designed for their use. Researchers have begun to involve children with ASD in the design process, but there is not yet a design method specifically adapted to support the potential difficulties this group may experience during PD sessions. This paper presents a new design method, IDEAS, which attempts to fulfill this need. The development of this method is described along with an initial pilot undertaken to determine the feasibility of using this method with an ASD population. The results indicate that the majority of children with ASD were able to produce a successful final design using this method, and have the potential to be involved in PD sessions as part of a design team.",8 Jun 2011
301,Beate Grawemeyer,The Impact of Autism Spectrum Disorder on the Categorisation of External Representations,https://pureportal.coventry.ac.uk/en/publications/the-impact-of-autism-spectrum-disorder-on-the-categorisation-of-e,"The knowledge structures and reasoning processes that underlie the use of external representations (ERs) in individuals with autism spectrum disorder (ASD) are not well understood. This paper compares the organisation of knowledge of ERs in young people with a diagnosis of ASD and an age-matched typically developing control group. ASD and non-ASD participants (twenty-eight in each group) were given an untimed ER card-sorting task. The ERs were based on representations used in educational software, for example graphs, charts, and text. Cluster analysis of the card sort task revealed similar clusters for both groups: maps, drawings, text, graphs and charts, and network and tree diagrams. However, comparison of the card sorts of the two different groups showed a difference in ‘basic level’ categories. While in the non-ASD group, maps and non-maps were the most distinctive category, analysis of the ASD cluster revealed, in addition, another ‘basic level’ category of textual representations. These results are discussed in relation to theories of information processing in autism. Our ultimate research aim is to develop educational software tailored to the specific needs of users with ASD. We wish to use our research results to inform requirements for the development of such educational software, in which ERs are able to support differences in information processing for individuals with ASD.",2011
302,Beate Grawemeyer,Using and managing multiple passwords: A week to a view,https://pureportal.coventry.ac.uk/en/publications/using-and-managing-multiple-passwords-a-week-to-a-view,"Security policies are required that protect information from unauthorised access, and also respect challenges users face in creating, and particularly managing, increasing numbers of passwords. This paper investigates real password use in the context of daily life. It presents the results of an empirical study where participants completed a password diary over 7 days, followed by debrief interviews to gain further knowledge and understanding of user behaviour. The results reported relate to how many passwords are in use, the types of passwords participants created, the relationships between different passwords and to sensitive services, how participants retrieved their passwords and finally, the different strategies adopted by users in their management of passwords. The paper concludes by providing a high level set of password guidelines, along with suggestions for mechanisms to support creating, encoding, retrieving and executing multiple passwords.",1 May 2011
303,Beate Grawemeyer,The effects of users' background diagram knowledge and task characteristics upon information display selection,https://pureportal.coventry.ac.uk/en/publications/the-effects-of-users-background-diagram-knowledge-and-task-charac,"This paper explores factors associated with effective external representation (ER) use. We describe an information-processing approach to the assessment of ER knowledge. We also present findings from a study that examined the effects of users' background knowledge of ERs upon performance and their preferences for particular information display forms across a range of database query types that differed in their representational specificity. A representationally specific task is one which can only be performed effectively with one type of representation (or a narrow range of representations). On highly representationally specific tasks, optimal ER selection is crucial. Both ER selection performance and reasoning performance are, in turn, predicted by an individual's prior knowledge of ERs. On representationally nonspecific tasks, participants performed well with any of several different ER types regardless of their level of prior ER knowledge. It is argued that ER effectiveness crucially depends upon a three-way interaction between user characteristics (e.g. prior knowledge), the cognitive properties of an ER, and task characteristics.",1 Dec 2008
304,Beate Grawemeyer,Evaluation of ERST - An external representation selection tutor,https://pureportal.coventry.ac.uk/en/publications/evaluation-of-erst-an-external-representation-selection-tutor,"This paper describes the evaluation of ERST, an adaptive system which is designed to improve its users' external representation (ER) selection accuracy on a range of database query tasks. The design of the system was informed by the results of experimental studies. Those studies examined the interactions between the participants' background knowledge-of-external representations, their preferences for selecting particular information display forms, and their performance across a range of tasks involving database queries. The paper describes how ERST's adaptation is based on predicting users' ER-to-task matching skills and performance at reasoning with ERs, via a Bayesian user model. The model drives ERST's adaptive interventions in two ways - by 1. hinting to the user that particular representations be used, and/or 2. by removing from the user the opportunity to select display forms which have been associated with prior poor performance for that user. The results show that ERST does improve an individual's ER reasoning performance. The system is able to successfully predict users' ER-to-task matching skills and their ER reasoning performance via its Bayesian user model.",1 Jan 2006
305,Beate Grawemeyer,A bayesian approach to modelling users' information display preferences,https://pureportal.coventry.ac.uk/en/publications/a-bayesian-approach-to-modelling-users-information-display-prefer,"This paper describes the process by which we constructed a user model for ERST - an External Representation Selection Tutor - which recommends external representations (ERs) for particular database query task types based upon individual preferences, in order to enhance ER reasoning performance. The user model is based on experimental studies which examined the effect of background knowledge of ERs upon performance and preferences over different types of tasks.",1 Jan 2005
306,Beate Grawemeyer,Developing a Bayes-net based student model for an External Representation Selection Tutor,https://pureportal.coventry.ac.uk/en/publications/developing-a-bayes-net-based-student-model-for-an-external-repres,This paper describes the process by which we are constructing an intelligent tutoring system (ERST) designed to improve learners' external representation (ER) selection accuracy on a range of database query tasks. This paper describes how ERST's student model is being constructed - it is a Bayesian network seeded with data from experimental studies. The studies examined the effects of students' background knowledge-of-external representations (KER) upon performance and their preferences for particular information display forms across a range of database query types.,2005
307,Beate Grawemeyer,Graphical data displays and database queries: Helping users select the right display for the task,https://pureportal.coventry.ac.uk/en/publications/graphical-data-displays-and-database-queries-helping-users-select,"This paper describes the process by which we have constructed an adaptive system for external representation (ER) selection support, designed to enhance users' ER reasoning performance. We describe how our user model has been constructed - it is a Bayesian network with values seeded from data derived from experimental studies. The studies examined the effects of users' background knowledge-of-external representations (KER) upon performance and their preferences for particular information display forms across a range of database query types.",1 Jan 2005
308,Beate Grawemeyer,The effect of knowledge-of-external-representations upon performance and representational choice in a database query task,https://pureportal.coventry.ac.uk/en/publications/the-effect-of-knowledge-of-external-representations-upon-performa,"This study examined the representation selection preference patterns of participants in a database query task. In the database task, participants were provided with a choice of information-equivalent data representations and chose one of them to use in answering database queries. A range of database tasks were posed to participants - some required the identification of unique entities, some required the detection of clusters of similar entities, and some involved the qualitative comparison of values, etc. Participants were divided, post hoc, into two groups on the basis of a pre-experimental task (card sort) designed to assess 'knowledge of external representations' (KER). Results showed that low and high KER groups differed most in terms of representation selection on cluster type database query tasks. Participants in the low group tended to change from more 'graphical' representations such as scatterplots to less complex representations (like bar charts or tables) from early to late trials. In contrast, high KER participants were able to successfully use a wider range of ER types. They also selected more 'appropriate' ERs (ie. ones that the diagrammatic reasoning literature predicts to be well-matched to the task).",1 Jan 2004
309,Beate Grawemeyer,AUDIX: A Knowledge-based System for speech-therapeutic auditory discrimination exercises,https://pureportal.coventry.ac.uk/en/publications/audix-a-knowledge-based-system-for-speech-therapeutic-auditory-di,"AUDIX is a knowledge-based multimedia system for auditory discrimination exercises. The aim of AUDIX is to provide patients with a computer-based therapy system which they can use between sessions with the human therapist, at home on an 'on-demand' basis. It is centered around computer based cognitive rehabilitation therapy whereas most existing programs in this area are only used for assessment. The auditory discrimination exercise system is designed for adult people who are speech-impaired as a result of a stroke. These people have auditory perceptual problems. The nature of the perceptual problem is an inability to perceive differences between phonemes. This requires a type of therapy called auditory discrimination training. The system provides computer-based auditory discrimination training. Through the knowledge-based design the domain dependent therapy knowledge is separated from the system core and provides a way for the therapist to add new knowledge, as new stimuli, or to create a new knowledge base to provide special exercises for an individual patient. The AUDIX architecture is described and the advantages of computer-based therapy are discussed.",1 Jan 2000
310,Beate Grawemeyer,Knowledge-based document analysis,https://pureportal.coventry.ac.uk/en/publications/knowledge-based-document-analysis,"The performance of document analysis systems significantly depends on knowledge about the application domain that can be exploited in the analysis process. Typically one has to deal with different sources of knowledge like syntactic knowledge, semantic knowledge or strategic knowledge guiding the analysis process. We present a knowledge based document analysis system based on a knowledge representation language specially designed for document analysis tasks. It allows to model and to interpret structural knowledge about documents and knowledge about the analysis process declaratively in a common framework.",Aug 1997
311,John Halloran,Feedback and Engagement on an Introductory Programming Module,https://pureportal.coventry.ac.uk/en/publications/feedback-and-engagement-on-an-introductory-programming-module,"We ran a study on engagement and achievement for a first year undergraduate programming module which  used an online learning environment containing tasks which generate automated feedback.  Students could also access human feedback from traditional labs. We gathered quantitative data on engagement and achievement which allowed us to split the cohort into 6 groups.  We then ran interviews with students after the end of the module to produce qualitative data on perceptions of what feedback is, how useful it is, the uses made of it, and how it bears on engagement. A general finding was that human and automated feedback are different but complementary. However there are different feedback needs by group. Our findings imply: (1) that a blended human-automated feedback approach improves engagement; and (2) that this approach needs to be differentiated according to type of student. We give implications for the design of feedback for programming modules. ",6 Jan 2022
312,John Halloran,Touch and Play? Investigating The Value of Touchscreens for Gamer Experience,https://pureportal.coventry.ac.uk/en/publications/touch-and-play-investigating-the-value-of-touchscreens-for-gamer-,"Touchscreens - mobile phones, tablets, phablets, laptops - are now omnipresent. They are increasingly used as a gaming platform: puzzle games, role play games and first-person shooters are just some of the genres to have appeared on this platform. Despite this, there is only limited research on the particular value of touchscreens for gamer experience. This paper discusses a raft of experiments designed to explore this issue. We compared games played on touchscreen, with the same games played on two other platforms: console and PC. We measured three dependent variables related to gamer experience: ease of controls, ease of task completion, and satisfaction. We found that the value of touchscreens for gamer experience depends on the interaction of three factors: characteristics of players (their gaming background and preferences); types of games (their genre and design); and platform (their controls and affordances). We discuss how these interactions can be further understood and explored, and lay out a set of sensitivities and hazards to inform the future design of touchscreen games.",Dec 2019
313,John Halloran,Design implications for task-specific search utilities for retrieval and re-engineering of code,https://pureportal.coventry.ac.uk/en/publications/design-implications-for-task-specific-search-utilities-for-retrie-2,"The importance of information retrieval systems is unquestionable in the modern society and both individuals as well as enterprises recognise the benefits of being able to find information effectively. Current code-focused information retrieval systems such as Google Code Search, Codeplex or Koders produce results based on specific keywords. However, these systems do not take into account developers’ context such as development language, technology framework, goal of the project, project complexity and developer’s domain expertise. They also impose additional cognitive burden on users in switching between different interfaces and clicking through to find the relevant code. Hence, they are not used by software developers. In this paper, we discuss how software engineers interact with information and general-purpose information retrieval systems (e.g. Google, Yahoo!) and investigate to what extent domain-specific search and recommendation utilities can be developed in order to support their work-related activities. In order to investigate this, we conducted a user study and found that software engineers followed many identifiable and repeatable work tasks and behaviours. These behaviours can be used to develop implicit relevance feedback-based systems based on the observed retention actions. Moreover, we discuss the implications for the development of task-specific search and collaborative recommendation utilities embedded with the Google standard search engine and Microsoft IntelliSense for retrieval and re-engineering of code. Based on implicit relevance feedback, we have implemented a prototype of the proposed collaborative recommendation system, which was evaluated in a controlled environment simulating the real-world situation of professional software engineers. The evaluation has achieved promising initial results on the precision and recall performance of the system.

Publisher statement: This is an Accepted Manuscript of an article published by Taylor & Francis in Enterprise Information Systems on 9th October 2015, available online: http://www.tandfonline.com/10.1080/17517575.2015.1086494",2017
314,John Halloran,The Human Element: Social Leveraging of User Engagement with Assisted Living Technology,https://pureportal.coventry.ac.uk/en/publications/the-human-element-social-leveraging-of-user-engagement-with-assis,"Research into user engagement with assisted living technology (ALT) has investigated design issues including usability, functionality and aesthetics; looked at user attitude and acceptance research; and examined social factors including the need to create ALT which appropriately supports the relationship between users and service providers. Based on an empirical case study of older persons’ independent living services offered by a large UK housing provider, we propose that there is a further, key dimension of ALT user engagement: social leveraging. We show how user engagement with key ALT including personal pendant alarms, pull cords and intercoms is shaped and supported in important ways by the ongoing social interaction of residents and skilled staff at independent living schemes. We discuss implications of social leveraging for reconsidering the importance of human resource as part of independent living services, during a time of transition to new technological models, and in light of current funding and organizational priorities.",May 2017
315,John Halloran,Cool to Warm Up? Understanding Student Energy Behaviour In Indonesian University Buildings.,https://pureportal.coventry.ac.uk/en/publications/cool-to-warm-up-understanding-student-energy-behaviour-in-indones-2,"We report on a study at Universitas Indonesia’s Computing Department, where there is interest in students’ contributions to energy reduction, particularly related to use of air conditioning (AC). We ran a survey with 190 students, complemented by environmental monitoring together with observational work, to understand energy attitudes and behaviour in order to draw implications on potential behaviour change interventions. While students showed much interest in ecological issues there was much lower awareness of impacts of the use of appliances, and no observed energy-saving action by students. Thus, while attitudes supporting behaviour change appear to be in place, this is not yet translating into action. Drawing on Social Practice Theory (SPT, Shove et al, 2012), we propose that this is to do with absence of salience (energy use is not the key focus of student activity), together with absence of licence (students appear not to feel they are permitted). We draw implications for future behaviour change work amongst the Indonesian student body centring on energy-saving AC use.",2015
316,John Halloran,Diagnosis of heart disease by using a radial basis function network classification technique on patients' medical records,https://pureportal.coventry.ac.uk/en/publications/diagnosis-of-heart-disease-by-using-a-radial-basis-function-netwo-2,"Heart disease is defined as any abnormal heart condition, and it is prevalent in people today. Considering human body as one big system, many factors play role on this disease. Examining the body provides quite lot of data in many different ways, though understanding the signs in collected data about heart disease requires experience, knowledge, and time from physicians. Computer based expert systems are designed to reduce the burden on physicians by automation. One of the important components of expert systems is data classifiers, and in this paper, I present the use of Radial Basis Function Networks (RBFN) with a Gaussian function as data classifier for heart disease classification. The proposed method in the paper makes use of same training data after they are used for training to reduce false classifications which makes this project unique in itself. For development and testing, I utilized patient records from Prince Sultan Cardiac Center-Qassim in Saudi Arabia. This paper discusses the use of RBFN for the classification of heart diseases, and it proposes a model system that forms data collection, processing, storage, and usage procedures.",2014
317,John Halloran,Supporting information exchange among software developers through the development of Collaborative Information Retrieval utilities,https://pureportal.coventry.ac.uk/en/publications/supporting-information-exchange-among-software-developers-through,"Software developers produce a significant amount of knowledge, everyday facing a significant amount of engineering challenges and resolving them using a significant number of information resources. Once the task that they are facing is complete and the results of their effort are embedded into the source code this knowledge is very rarely shared with the software development community. As a consequence other software developers when faced with the same or similar problem have to solve it by themselves wasting a significant amount of time and resources every day. This paper proposes a Collaborative Information Recommender (CIR) system which intends to address the problem outlined above and facilitate the exchange of information between software developers. The proposed CIR system not only supports a direct reuse of the code related information found by other developers but also supports the creation and management of very problem focused social and knowledge networks.",19 Sept 2013
318,John Halloran,Distributed information extraction from large-scale wireless sensor networks,https://pureportal.coventry.ac.uk/en/publications/distributed-information-extraction-from-large-scale-wireless-sens-2,,May 2012
319,John Halloran,In at the deep end: an activity-led introduction to first year creative computing,https://pureportal.coventry.ac.uk/en/publications/in-at-the-deep-end-an-activity-led-introduction-to-first-year-cre-2,,Sept 2012
320,John Halloran,Investigating the value of retention actions as a source of relevance information in the software development environment,https://pureportal.coventry.ac.uk/en/publications/investigating-the-value-of-retention-actions-as-a-source-of-relev,"Even though there exists a number of search solutions targetted at software engineers the literature suggests that they are not widely used by the people engaged in code delivery [26]. Moreover, current code focused information retrieval systems such as Google Code Search (discontinued), Codeplex or Koders produce results based on specific keywords and therefore they do not take into account user context such as location, browsing history, previous interaction patterns and domain expertise. In this paper we discuss the development of task-specific information retrieval systems for software engineers. We discuss how software engineers interact with information and information retrieval systems and investigate to what extent a domain-specific search and recommendation system can be developed in order to support their work related activities. We have conducted a user study: a questionnaire and an automated observation of user interactions with the browser and software development environment. We discuss factors that can be used as implicit feedback indicators for further collaborative filtering and discuss how these parameters can be analysed using Computational Intelligence based techniques.",2012
321,John Halloran,Sustainable future? Building and life-style assessment,https://pureportal.coventry.ac.uk/en/publications/sustainable-future-building-and-life-style-assessment,"Energy, both in terms of its production and its usage has occupied a prime place in research as well as politics and world economy for the past few years. The majority of nations are aiming to deliver severe carbon cuts in the next few years. However, achieving a carbon-free future needs more than infrastructure investment and novel efficient technologies for buildings, transportation and other large consumer domains. It needs a better understanding of people as consumers, as well as a better understanding of energy waste across the multitude of socio-techical systems around us. With regards to the built environment and particularly residential buildings, the authors propose that dual, quantitative and qualitative approaches to characterising, assessing and improving occupied buildings are necessary. Such approaches would synchronously cater for understanding i) buildings technical performance (fabric and building heating, cooling and ventilation systems) and ii) occupant's motivation, ability, knowledge and efficacy for adopting low carbon lifestyles. When deployed at scale, the above will enable cost effective, targeted interventions for both building fabric and systems improvement and towards empowering their occupants to live sustainably. The paper describes such a quantitative and qualitative approach and proposes assessment tools. Further, the authors comment on the potential benefits from monitoring campaigns when deployed at scale.",1 Dec 2012
322,John Halloran,Ethnographically informed agent based computational model for collaborative systems,https://pureportal.coventry.ac.uk/en/publications/ethnographically-informed-agent-based-computational-model-for-col,"This paper presents an agent based computational model in order to address the long acknowledged problem of translating ethnographic findings into system design. This model is based on an ethnographic framework consisting of three dimensions, distributed coordination, awareness of work and plans and procedures; and the BDI (belief, desire and intention) model of intelligent agents. The ethnographic framework is used to organise ethnographically derived information into the three dimensions; whereas the BDI model allows the information to be mapped onto the concepts of multi-agent systems. Focusing on a case study, the usefulness of the proposed model is demonstrated by showing that ethnographic accounts can systematically inform system design and development. Evaluation and generalisability of the model is discussed in the paper.",22 Nov 2010
323,John Halloran,Design challenges and solutions: review of the 4th international workshop on ubiquitous computing (iUBICOM 2009),https://pureportal.coventry.ac.uk/en/publications/design-challenges-and-solutions-review-of-the-4th-international-w-2,,2009
324,John Halloran,"It's talk, but not as we know it: using VoIP to communicate in war games",https://pureportal.coventry.ac.uk/en/publications/its-talk-but-not-as-we-know-it-using-voip-to-communicate-in-war-g-2,,2009
325,John Halloran,The value of values: resourcing co-design of ubiquitous computing,https://pureportal.coventry.ac.uk/en/publications/the-value-of-values-resourcing-co-design-of-ubiquitous-computing-2,,2009
326,Qamar Hayat,A novel approach for producing Mg-3Al-1Zn-0.2Mn alloy wire with a promising combination of strength and ductility using CoreFlowTM,https://pureportal.coventry.ac.uk/en/publications/a-novel-approach-for-producing-mg-3al-1zn-02mn-alloy-wire-with-a-,"Mg-3Al-1Zn-0.2Mn (wt.%, AZ31B) wires were successfully produced from commercial hot-rolled plates in one step using the CoreFlowTM process, a novel stationary shoulder friction stir extrusion manufacturing. CoreFlowed AZ31B wires exhibited fine grains with a heterogeneous grain size distribution of 6.5 ± 4.2 μm along the transverse direction (TD) compared with the as-received material. A weakened texture was also obtained in CoreFlowed AZ31B, with basal poles aligned parallel to TD shift toward extrusion direction (ED) from wire center to edge. Periodic needle-like regions with a distinctively different orientation from neighbouring regions were observed at the sample edge. The engineering ultimate tensile strength (UTS) and elongation (El) of the CoreFlowed sample was 258 ± 5 MPa and 22.3 ± 0.8%. The El was significantly increased by 58% with equivalent UTS compared to the as-received material. Such a good combination of strength and ductility is attributed to grain refinement with heterogeneity, texture weakening, and homogeneously redistributed second phase particles.",1 Apr 2023
327,Qamar Hayat,Cracking Behavior of Gd2Zr2O7/YSZ Multi-Layered Thermal Barrier Coatings Deposited by Suspension Plasma Spray,https://pureportal.coventry.ac.uk/en/publications/cracking-behavior-of-gd2zr2o7ysz-multi-layered-thermal-barrier-co,"A new multi-layered thermal barrier coating system (TBCs) containing gadolinium zirconate (GZ, Gd2Zr2O7) and yttria-stabilized zirconia (YSZ) was developed using suspension plasma spray (SPS) to improve the overall thermal cycling performance. This study focuses on the cracking behavior of the GZ/YSZ TBC after thermal exposure to find out the key factors that limit its lifetime. Different cracking behaviors were detected depending on the thermal treatment condition (i.e., horizontal cracks within the ceramic layer and at the thermally grown oxide (TGO)/YSZ interface) which can be related to stresses developed through thermal expansion mismatch and increased TGO thickness beyond a critical value, respectively. A reduction in hardness of bond coat (BC) was measured by nanoindentation and linked with the thermally activated grain growth mechanism. The hardness and elastic modulus of ceramic layers (GZ and YSZ) showed an increased trend after treatment that contributed to the interfacial cracks.",Jan 2023
328,Qamar Hayat,A Review on In Situ Mechanical Testing of Coatings,https://pureportal.coventry.ac.uk/en/publications/a-review-on-in-situ-mechanical-testing-of-coatings,"Real-time evaluation of materials’ mechanical response is crucial to further improve the performance of surfaces and coatings because the widely used post-processing evaluation techniques (e.g., fractography analysis) cannot provide deep insight into the deformation and damage mechanisms that occur and changes in coatings’ material corresponding to the dynamic thermomechanical loading conditions. The advanced in situ examination methods offer deep insight into mechanical behavior and material failure with remarkable range and resolution of length scales, microstructure, and loading conditions. This article presents a review on the in situ mechanical testing of coatings under tensile and bending examinations, highlighting the commonly used in situ monitoring techniques in coating testing and challenges related to such techniques.",23 Feb 2022
329,Qamar Hayat,"High-Entropy Coatings (HEC) for High-Temperature Applications: Materials, Processing, and Properties",https://pureportal.coventry.ac.uk/en/publications/high-entropy-coatings-hec-for-high-temperature-applications-mater,"High-entropy materials (HEM), including alloys, ceramics, and composites, are a novel class of materials that have gained enormous attention over the past two decades. These multi-component novel materials with unique structures always have exceptionally good mechanical properties and phase stability at all temperatures. Of particular interest for high-temperature applications, e.g., in the aerospace and nuclear sectors, is the new concept of high-entropy coatings (HEC) on low-cost metallic substrates, which has just emerged during the last few years. This exciting new virgin field awaits exploration by materials scientists and surface engineers who are often equipped with high-performance computational modelling tools, high-throughput coating deposition technologies and advanced materials testing/characterisation methods, all of which have greatly shortened the development cycle of a new coating from years to months/days. This review article reflects on research progress in the development and application of HEC focusing on high-temperature applications in the context of materials/composition type, coating process selection and desired functional properties. The importance of alloying addition is highlighted, resulting in suppressing oxidation as well as improving corrosion and diffusion resistance in a variety of coating types deposited via common deposition processes. This review provides an overview of this hot topic, highlighting the research challenges, identifying gaps, and suggesting future research activity for high temperature applications.",18 May 2022
330,Qamar Hayat,Multiscale modelling for fusion and fission materials: the M4F project,https://pureportal.coventry.ac.uk/en/publications/multiscale-modelling-for-fusion-and-fission-materials-the-m4f-pro,"The M4F project brings together the fusion and fission materials communities working on the prediction of radiation damage production and evolution and its effects on the mechanical behaviour of irradiated ferritic/martensitic (F/M) steels. It is a multidisciplinary project in which several different experimental and computational materials science tools are integrated to understand and model the complex phenomena associated with the formation and evolution of irradiation induced defects and their effects on the macroscopic behaviour of the target materials. In particular the project focuses on two specific aspects: (1) To develop physical understanding and predictive models of the origin and consequences of localised deformation under irradiation in F/M steels; (2) To develop good practices and possibly advance towards the definition of protocols for the use of ion irradiation as a tool to evaluate radiation effects on materials. Nineteen modelling codes across different scales are being used and developedand an experimental validation programme based on the examination of materials irradiated with neutrons and ions is being carried out. The project enters now its 4th year and is close to delivering high-quality results. This paper overviews the work performed so far within the project, highlighting its impact for fission and fusion materials science.",Dec 2021
331,Tjun Hoh,Correction of multiple-blinking artifacts in photoactivated localization microscopy,https://pureportal.coventry.ac.uk/en/publications/correction-of-multiple-blinking-artifacts-in-photoactivated-local,"Photoactivated localization microscopy (PALM) produces an array of localization coordinates by means of photoactivatable fluorescent proteins. However, observations are subject to fluorophore multiple blinking and each protein is included in the dataset an unknown number of times at different positions, due to localization error. This causes artificial clustering to be observed in the data. We present a 'model-based correction' (MBC) workflow using calibration-free estimation of blinking dynamics and model-based clustering to produce a corrected set of localization coordinates representing the true underlying fluorophore locations with enhanced localization precision, outperforming the state of the art. The corrected data can be reliably tested for spatial randomness or analyzed by other clustering approaches, and descriptors such as the absolute number of fluorophores per cluster are now quantifiable, which we validate with simulated data and experimental data with known ground truth. Using MBC, we confirm that the adapter protein, the linker for activation of T cells, is clustered at the T cell immunological synapse. [Abstract copyright: © 2022. The Author(s), under exclusive licence to Springer Nature America, Inc.]",May 2022
